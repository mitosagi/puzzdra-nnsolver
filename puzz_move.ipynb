{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "puzz.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfVYPQwNvfoCPWDnfZ8FQv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitosagi/puzzdra-nnsolver/blob/master/puzz_move.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrk7ju8ZSpq1"
      },
      "source": [
        "## 初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-syCb8S5ijR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049e29c4-a8a7-4788-9993-9f68ef8026c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MinijqIGMKzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d14fa48-069e-4011-c30b-604277e0c500"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/User/python/puzzdra-nnsolver /content/puzzdra-nnsolver\n",
        "%cd /content/puzzdra-nnsolver\n",
        "!pip install --log=pip_log -e .\n",
        "!pip install git+https://github.com/DLR-RM/stable-baselines3\n",
        "!pip install sbx-rl"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/puzzdra-nnsolver\n",
            "Obtaining file:///content/puzzdra-nnsolver\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: Puzzpy\n",
            "  Attempting uninstall: Puzzpy\n",
            "    Found existing installation: Puzzpy 1.0\n",
            "    Uninstalling Puzzpy-1.0:\n",
            "      Successfully uninstalled Puzzpy-1.0\n",
            "  Running setup.py develop for Puzzpy\n",
            "Successfully installed Puzzpy-1.0\n",
            "Collecting git+https://github.com/DLR-RM/stable-baselines3\n",
            "  Cloning https://github.com/DLR-RM/stable-baselines3 to /tmp/pip-req-build-l3hfy0dm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/stable-baselines3 /tmp/pip-req-build-l3hfy0dm\n",
            "  Resolved https://github.com/DLR-RM/stable-baselines3 to commit 69afefc91d408d352b4224ae5244ad2c32bb7634\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (2.1.0+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.0a9) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.0a9) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==2.2.0a9) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.2.0a9) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3==2.2.0a9) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3==2.2.0a9) (1.3.0)\n",
            "Collecting sbx-rl\n",
            "  Downloading sbx_rl-0.8.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m746.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: stable-baselines3>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (2.2.0a9)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (0.4.16)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (0.4.16+cuda11.cudnn86)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (0.7.4)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (0.1.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (4.66.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (13.6.0)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (0.22.0)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (2.1.0+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (3.7.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->sbx-rl) (1.0.7)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->sbx-rl) (0.4.1)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->sbx-rl) (0.1.45)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax->sbx-rl) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->sbx-rl) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->sbx-rl) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->sbx-rl) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax->sbx-rl) (1.11.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->sbx-rl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->sbx-rl) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->sbx-rl) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->sbx-rl) (0.1.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->sbx-rl) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->sbx-rl) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->sbx-rl) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->sbx-rl) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->sbx-rl) (0.12.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3>=2.1.0->sbx-rl) (0.0.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->sbx-rl) (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (2.8.2)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->sbx-rl) (1.5.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->sbx-rl) (1.5.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->sbx-rl) (3.20.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3>=2.1.0->sbx-rl) (2023.3.post1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->sbx-rl) (6.1.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->sbx-rl) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (1.3.0)\n",
            "Installing collected packages: sbx-rl\n",
            "Successfully installed sbx-rl-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdUISRWiX4kM"
      },
      "source": [
        "## 実際の処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI2D4A-cXnQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37fd9003-0c04-4b62-80c5-a1c3ccb496e7"
      },
      "source": [
        "import numpy as np\n",
        "import gymnasium\n",
        "from gymnasium import spaces\n",
        "from puzzpy import PuzzTable\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "import random\n",
        "\n",
        "drop_color = 3\n",
        "board_width = 6\n",
        "board_height = 5\n",
        "min_size = 6 # 36 if CNN, 6 if manual MLP or CNN\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "    BLACK = '\\033[30m'\n",
        "    RED = '\\033[31m'\n",
        "    GREEN = '\\033[32m'\n",
        "    YELLOW = '\\033[33m'\n",
        "    BLUE = '\\033[34m'\n",
        "    MAGENTA = '\\033[35m'\n",
        "    CYAN = '\\033[36m'\n",
        "\n",
        "class PuzzEnv(gymnasium.Env):\n",
        "  \"\"\"\n",
        "  パズドラの環境\n",
        "  \"\"\"\n",
        "  # ColabのためGUIを実装できない\n",
        "  metadata = {'render.modes': ['console']}\n",
        "\n",
        "  def __init__(self):\n",
        "    super(PuzzEnv, self).__init__()\n",
        "\n",
        "    self.action_space = spaces.Discrete(4) # 指を離す動作を含めると5\n",
        "    self.observation_space = spaces.Box(low=0, high=255, shape=(1+1+1+drop_color, max(min_size, board_height), max(min_size, board_width)), dtype=np.uint8) # 1 for turn num, +1 for finger position\n",
        "    self.action = 255\n",
        "    self.prev_action = 255\n",
        "    self.prev_finger_array = None\n",
        "    self.rew = 0\n",
        "\n",
        "  def retobs(self, table):\n",
        "    turn_array = [np.full((board_height, board_width), table.get_turn(), np.uint8)]\n",
        "    action_array = [np.full((board_height, board_width), self.action, np.uint8)]\n",
        "    finger_array = np.array([np.array(table.get_XY_as_table()).astype(np.uint8) * (2 ** 5)]).astype(np.uint8)\n",
        "    # if self.prev_finger_array is not None:\n",
        "    #   finger_array = finger_array + self.prev_finger_array // 2\n",
        "    # self.prev_finger_array = finger_array\n",
        "    table_array = np.array(table.get_table()).astype(np.uint8)\n",
        "    u = np.arange(table_array.max()+1)\n",
        "    table_array = (u[:,np.newaxis,np.newaxis]==table_array).astype(np.uint8)[1:] # ドロップをone-hotにする https://stackoverflow.com/questions/67249470/convert-a-2d-numpy-array-into-a-hot-encoded-3d-numpy-array-with-same-values-in\n",
        "    tmp_array = np.concatenate([turn_array, action_array, finger_array, table_array])\n",
        "    now_rew = table.eval_otoshi()\n",
        "    step_rew = now_rew - self.rew\n",
        "    self.rew = now_rew\n",
        "    return np.pad(tmp_array, [(0,0), (0, max(min_size - board_height, 0)), (0, max(min_size - board_width, 0))], mode='constant', constant_values=0), step_rew\n",
        "\n",
        "  def reset(self, seed = None, test_min = 30):\n",
        "    # test_min = random.randrange(10,30,1)\n",
        "    super().reset(seed=seed)\n",
        "    \"\"\"\n",
        "    【重要】観測はnumpy配列でなければならない\n",
        "    :return: (np.array)\n",
        "    \"\"\"\n",
        "    while True:\n",
        "      self.table = PuzzTable(\"\".join([str(random.randrange(drop_color)) for i in range(board_width*board_height)]), random.randrange(board_width), random.randrange(board_height), test_min) # n色陣　操作時間m秒\n",
        "      if self.table.eval_otoshi() == 0:\n",
        "        break\n",
        "    # self.table = PuzzTable(\"\".join([str(random.randrange(drop_color)) for i in range(board_width*board_height)]), random.randrange(board_width), random.randrange(board_height), test_min) # n色陣　操作時間m秒\n",
        "\n",
        "    return self.retobs(self.table)[0], {}\n",
        "\n",
        "  def step(self, action):\n",
        "    self.action = action\n",
        "    if action == 4: # 指を離す動作\n",
        "      return *(self.retobs(self.table)), True, False, {}\n",
        "\n",
        "    next_table = self.table.next_tables()[action]\n",
        "\n",
        "    if abs(action - self.prev_action) == 2: # 元の方向に戻る 0と2 1と3が該当\n",
        "      # next_table = self.table\n",
        "      return self.retobs(self.table)[0], -1, True, False, {}\n",
        "    self.prev_action = action\n",
        "\n",
        "    if next_table.get_table()[0][0] == 127: # 壁に移動\n",
        "      # next_table = self.table\n",
        "      return self.retobs(self.table)[0], -1, True, False, {}\n",
        "\n",
        "    self.table = next_table\n",
        "\n",
        "    if self.table.get_turn() <= 0: # 時間切れ\n",
        "      return *(self.retobs(self.table)), True, False, {}\n",
        "\n",
        "    return *(self.retobs(self.table)), False, False, {}\n",
        "\n",
        "  def render(self, mode='console', close=False):\n",
        "    if mode != 'console':\n",
        "      raise NotImplementedError()\n",
        "\n",
        "    tcolor = [bcolors.RED, bcolors.BLUE, bcolors.GREEN, bcolors.MAGENTA, bcolors.YELLOW, bcolors.BLACK]\n",
        "    start = self.table.get_XY_as_table()\n",
        "    table = self.table.get_table()\n",
        "    for i in range(board_height):\n",
        "      for j in range(board_width):\n",
        "        if start[i][j] == 1:\n",
        "          print(tcolor[table[i][j]-1]  +  bcolors.UNDERLINE + \"●\" + bcolors.ENDC, end='')\n",
        "        else:\n",
        "          print(tcolor[table[i][j]-1]  + \"●\" + bcolors.ENDC, end='')\n",
        "\n",
        "      print('')\n",
        "\n",
        "check_env(PuzzEnv())"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:51: UserWarning: The minimal resolution for an image is 36x36 for the default `CnnPolicy`. You might need to use a custom features extractor cf. https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Z9SliEfKci",
        "outputId": "c0d60737-433b-405d-a65d-7863c310e12d"
      },
      "source": [
        "env = PuzzEnv()\n",
        "\n",
        "obs = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  obs, reward, done, _, info = env.step(env.action_space.sample())\n",
        "  print('obs=', obs.shape, 'reward=', reward, 'done=', done)\n",
        "  with np.printoptions(threshold=np.inf):\n",
        "    print(obs)\n",
        "  env.render()\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Box(0, 255, (6, 5, 6), uint8)\n",
            "Discrete(4)\n",
            "1\n",
            "Step 1\n",
            "obs= (6, 5, 6) reward= 0 done= False\n",
            "[[[29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]]\n",
            "\n",
            " [[ 3  3  3  3  3  3]\n",
            "  [ 3  3  3  3  3  3]\n",
            "  [ 3  3  3  3  3  3]\n",
            "  [ 3  3  3  3  3  3]\n",
            "  [ 3  3  3  3  3  3]]\n",
            "\n",
            " [[ 0  0 32  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  1  0  0  0  0]\n",
            "  [ 1  0  0  0  0  1]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 1  0  1  1  0  0]\n",
            "  [ 0  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  0  1  0  0  1]\n",
            "  [ 0  0  1  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  1  0  0  1  0]]\n",
            "\n",
            " [[ 0  0  0  1  1  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  1  0  0  1  0]\n",
            "  [ 1  0  0  1  0  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 2\n",
            "obs= (6, 5, 6) reward= 0 done= False\n",
            "[[[28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]]\n",
            "\n",
            " [[ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0 32  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  1  0  0  0  0]\n",
            "  [ 1  0  0  0  0  1]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 1  0  1  1  0  0]\n",
            "  [ 0  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  0  1  0  0  1]\n",
            "  [ 0  0  1  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  1  0  0  1  0]]\n",
            "\n",
            " [[ 0  0  0  1  1  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  1  0  0  1  0]\n",
            "  [ 1  0  0  1  0  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 3\n",
            "obs= (6, 5, 6) reward= 0 done= False\n",
            "[[[27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]]\n",
            "\n",
            " [[ 1  1  1  1  1  1]\n",
            "  [ 1  1  1  1  1  1]\n",
            "  [ 1  1  1  1  1  1]\n",
            "  [ 1  1  1  1  1  1]\n",
            "  [ 1  1  1  1  1  1]]\n",
            "\n",
            " [[ 0  0 32  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  1  0  0  0  0]\n",
            "  [ 1  0  0  0  0  1]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 1  0  1  1  0  0]\n",
            "  [ 0  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  0  1  0  0  1]\n",
            "  [ 0  0  1  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  1  0  0  1  0]]\n",
            "\n",
            " [[ 0  0  0  1  1  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  1  0  0  1  0]\n",
            "  [ 1  0  0  1  0  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 4\n",
            "obs= (6, 5, 6) reward= 0 done= False\n",
            "[[[26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0 32  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 1  0  0  0  0  1]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 1  0  1  1  0  0]\n",
            "  [ 0  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  0  1]\n",
            "  [ 0  0  1  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  1  0  0  1  0]]\n",
            "\n",
            " [[ 0  0  0  1  1  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  1  0  0  1  0]\n",
            "  [ 1  0  0  1  0  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 5\n",
            "obs= (6, 5, 6) reward= -1 done= True\n",
            "[[[26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]]\n",
            "\n",
            " [[ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]]\n",
            "\n",
            " [[ 0 32  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 1  0  0  0  0  1]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 1  0  1  1  0  0]\n",
            "  [ 0  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  0  1]\n",
            "  [ 0  0  1  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  1  0  0  1  0]]\n",
            "\n",
            " [[ 0  0  0  1  1  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  1  0  0  1  0]\n",
            "  [ 1  0  0  1  0  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Goal reached! reward= -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "id": "Ubsd-1EVqANb",
        "outputId": "c8551847-fe2b-49c0-d668-806925ba2410"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "# %tensorboard --logdir puzzdra_tensorboard\n",
        "%tensorboard --logdir puzzdra_tensorboard --host=127.0.0.1 --port=6006 --load_fast=false\n",
        "from google.colab import output\n",
        "output.serve_kernel_port_as_window(6006, path=\"\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/output/_util.py:114: DeprecationWarning: This has been deprecated due to changes in browser security. Use `serve_kernel_port_as_iframe` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(6006, \"\", \"https://localhost:6006\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h_qAMMmQnTtw",
        "outputId": "cb11e089-d7ac-4bc0-ce60-6d0b23b875a3"
      },
      "source": [
        "# 実行前にログ名を設定すること!!!\n",
        "log_name='PPO gamma no turn no prev'\n",
        "\n",
        "from stable_baselines3 import PPO, SAC\n",
        "# from sbx import TQC, DroQ, SAC, PPO, DQN, TD3, DDPG\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
        "from stable_baselines3.common.envs.multi_input_envs import SimpleMultiObsEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from statistics import mean\n",
        "\n",
        "log_name='PPO gamma'\n",
        "\n",
        "# 環境の生成\n",
        "env = PuzzEnv()\n",
        "\n",
        "# 環境のラップ\n",
        "# monienv = Monitor(env, filename=None, allow_early_resets=True)\n",
        "monienv = VecMonitor(DummyVecEnv([lambda: PuzzEnv() for i in range(4)]), filename=None)\n",
        "\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "\n",
        "\n",
        "class CustomCNN(BaseFeaturesExtractor):\n",
        "    \"\"\"\n",
        "    :param observation_space: (gym.Space)\n",
        "    :param features_dim: (int) Number of features extracted.\n",
        "        This corresponds to the number of unit for the last layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, observation_space: spaces.Box, features_dim: int = 256):\n",
        "        super().__init__(observation_space, features_dim)\n",
        "        # We assume CxHxW images (channels first)\n",
        "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
        "        n_input_channels = observation_space.shape[0]\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 8, kernel_size=3, stride=1, padding='valid'),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        # Compute shape by doing one forward pass\n",
        "        with th.no_grad():\n",
        "            n_flatten = self.cnn(\n",
        "                th.as_tensor(observation_space.sample()[None]).float()\n",
        "            ).shape[1]\n",
        "\n",
        "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
        "\n",
        "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
        "        return self.linear(self.cnn(observations))\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class=CustomCNN,\n",
        "    features_extractor_kwargs=dict(features_dim=32),\n",
        "    # share_features_extractor=False\n",
        ")\n",
        "\n",
        "# エージェントの訓練\n",
        "model = PPO('MlpPolicy', monienv, verbose=1, policy_kwargs=policy_kwargs, tensorboard_log=\"./puzzdra_tensorboard/\")\n",
        "# model = PPO('MlpPolicy', monienv, verbose=1, policy_kwargs=dict(net_arch=[64,64]), tensorboard_log=\"./puzzdra_tensorboard/\")\n",
        "print(model.policy)\n",
        "\n",
        "class TensorboardCallback(BaseCallback):\n",
        "  \"\"\"\n",
        "  Custom callback for plotting additional values in tensorboard.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, verbose=0):\n",
        "    super(TensorboardCallback, self).__init__(verbose)\n",
        "    self.check_freq = 100_000//4\n",
        "\n",
        "  def _on_step(self) -> bool:\n",
        "    if self.n_calls % self.check_freq == 0:\n",
        "\n",
        "      env = PuzzEnv()\n",
        "      rew_array = []\n",
        "\n",
        "      for test in range(100):\n",
        "        obs, _info = env.reset()\n",
        "        n_steps = 100\n",
        "        for step in range(n_steps):\n",
        "          action, _ = model.predict(obs, deterministic=True)\n",
        "          obs, reward, done, _, info = env.step(action)\n",
        "          if done:\n",
        "            rew_array.append(reward)\n",
        "            break\n",
        "\n",
        "      self.logger.record('combo', mean(rew_array) if len(rew_array) > 0 else 0)\n",
        "    return True\n",
        "\n",
        "model = model.learn(500_000, tb_log_name=log_name, callback=TensorboardCallback()) # 1_500_000 = 1 hour"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "ActorCriticPolicy(\n",
            "  (features_extractor): CustomCNN(\n",
            "    (cnn): Sequential(\n",
            "      (0): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (3): ReLU()\n",
            "      (4): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (linear): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=32, bias=True)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (pi_features_extractor): CustomCNN(\n",
            "    (cnn): Sequential(\n",
            "      (0): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (3): ReLU()\n",
            "      (4): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (linear): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=32, bias=True)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (vf_features_extractor): CustomCNN(\n",
            "    (cnn): Sequential(\n",
            "      (0): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (3): ReLU()\n",
            "      (4): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (linear): Sequential(\n",
            "      (0): Linear(in_features=128, out_features=32, bias=True)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (mlp_extractor): MlpExtractor(\n",
            "    (policy_net): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (3): Tanh()\n",
            "    )\n",
            "    (value_net): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (3): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (action_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "Logging to ./puzzdra_tensorboard/PPO gamma_38\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.7      |\n",
            "|    ep_rew_mean     | -0.7     |\n",
            "| time/              |          |\n",
            "|    fps             | 772      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 10       |\n",
            "|    total_timesteps | 8192     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.78        |\n",
            "|    ep_rew_mean          | -0.58       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 430         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010702185 |\n",
            "|    clip_fraction        | 0.0712      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | -0.00142    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.401       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00701    |\n",
            "|    value_loss           | 0.792       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.39        |\n",
            "|    ep_rew_mean          | -0.54       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 374         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 65          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013644766 |\n",
            "|    clip_fraction        | 0.225       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.0121      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.142       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0186     |\n",
            "|    value_loss           | 0.739       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.25        |\n",
            "|    ep_rew_mean          | -0.36       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 352         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 93          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013979455 |\n",
            "|    clip_fraction        | 0.224       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.31       |\n",
            "|    explained_variance   | 0.0225      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.637       |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0163     |\n",
            "|    value_loss           | 0.914       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.15        |\n",
            "|    ep_rew_mean          | -0.37       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 333         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 122         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015013793 |\n",
            "|    clip_fraction        | 0.22        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.25       |\n",
            "|    explained_variance   | 0.0246      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.401       |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0145     |\n",
            "|    value_loss           | 0.993       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 3.83       |\n",
            "|    ep_rew_mean          | -0.37      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 329        |\n",
            "|    iterations           | 6          |\n",
            "|    time_elapsed         | 149        |\n",
            "|    total_timesteps      | 49152      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01497986 |\n",
            "|    clip_fraction        | 0.224      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.16      |\n",
            "|    explained_variance   | 0.0269     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.171      |\n",
            "|    n_updates            | 50         |\n",
            "|    policy_gradient_loss | -0.0129    |\n",
            "|    value_loss           | 1.09       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.71        |\n",
            "|    ep_rew_mean          | -0.27       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 329         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 173         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018375557 |\n",
            "|    clip_fraction        | 0.213       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.08       |\n",
            "|    explained_variance   | 0.0389      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.338       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0134     |\n",
            "|    value_loss           | 1.14        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.63        |\n",
            "|    ep_rew_mean          | -0.14       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 328         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 199         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016474728 |\n",
            "|    clip_fraction        | 0.204       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.042       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.62        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0114     |\n",
            "|    value_loss           | 1.36        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.61        |\n",
            "|    ep_rew_mean          | -0.04       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 327         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 225         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017407509 |\n",
            "|    clip_fraction        | 0.179       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.936      |\n",
            "|    explained_variance   | 0.0554      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.755       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00688    |\n",
            "|    value_loss           | 1.32        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 7.03       |\n",
            "|    ep_rew_mean          | 0.11       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 328        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 249        |\n",
            "|    total_timesteps      | 81920      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01362448 |\n",
            "|    clip_fraction        | 0.161      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.893     |\n",
            "|    explained_variance   | 0.0769     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.646      |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.00545   |\n",
            "|    value_loss           | 1.43       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 7.94       |\n",
            "|    ep_rew_mean          | 0.22       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 328        |\n",
            "|    iterations           | 11         |\n",
            "|    time_elapsed         | 273        |\n",
            "|    total_timesteps      | 90112      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01564375 |\n",
            "|    clip_fraction        | 0.171      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.816     |\n",
            "|    explained_variance   | 0.0575     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.59       |\n",
            "|    n_updates            | 100        |\n",
            "|    policy_gradient_loss | -0.00589   |\n",
            "|    value_loss           | 1.39       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.09        |\n",
            "|    ep_rew_mean          | 0.14        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 328         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 298         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012959896 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.777      |\n",
            "|    explained_variance   | 0.0772      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.423       |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00525    |\n",
            "|    value_loss           | 1.45        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| combo                   | -0.47        |\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 9.24         |\n",
            "|    ep_rew_mean          | 0.02         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 327          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 325          |\n",
            "|    total_timesteps      | 106496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0123187285 |\n",
            "|    clip_fraction        | 0.15         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.725       |\n",
            "|    explained_variance   | 0.0789       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.627        |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00285     |\n",
            "|    value_loss           | 1.44         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 10.7       |\n",
            "|    ep_rew_mean          | 0.3        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 328        |\n",
            "|    iterations           | 14         |\n",
            "|    time_elapsed         | 349        |\n",
            "|    total_timesteps      | 114688     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01325227 |\n",
            "|    clip_fraction        | 0.137      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.686     |\n",
            "|    explained_variance   | 0.0774     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.642      |\n",
            "|    n_updates            | 130        |\n",
            "|    policy_gradient_loss | -0.00181   |\n",
            "|    value_loss           | 1.43       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 13.8        |\n",
            "|    ep_rew_mean          | 0.39        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 328         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 373         |\n",
            "|    total_timesteps      | 122880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013388901 |\n",
            "|    clip_fraction        | 0.149       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.644      |\n",
            "|    explained_variance   | 0.0605      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.718       |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00454    |\n",
            "|    value_loss           | 1.52        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 12.4      |\n",
            "|    ep_rew_mean          | 0.38      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 330       |\n",
            "|    iterations           | 16        |\n",
            "|    time_elapsed         | 396       |\n",
            "|    total_timesteps      | 131072    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0138991 |\n",
            "|    clip_fraction        | 0.137     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.606    |\n",
            "|    explained_variance   | 0.0421    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.792     |\n",
            "|    n_updates            | 150       |\n",
            "|    policy_gradient_loss | -0.00224  |\n",
            "|    value_loss           | 1.59      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 14.7        |\n",
            "|    ep_rew_mean          | 0.5         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 331         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 420         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016359784 |\n",
            "|    clip_fraction        | 0.144       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.547      |\n",
            "|    explained_variance   | 0.0358      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.669       |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00461    |\n",
            "|    value_loss           | 1.66        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 17.6        |\n",
            "|    ep_rew_mean          | 0.54        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 332         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 444         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014628383 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.485      |\n",
            "|    explained_variance   | 0.0341      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.863       |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00298    |\n",
            "|    value_loss           | 1.69        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 20.7        |\n",
            "|    ep_rew_mean          | 1.03        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 333         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 467         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010056801 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.448      |\n",
            "|    explained_variance   | 0.0549      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.677       |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.000386   |\n",
            "|    value_loss           | 1.62        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.4        |\n",
            "|    ep_rew_mean          | 0.93        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 333         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 491         |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012856499 |\n",
            "|    clip_fraction        | 0.112       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.43       |\n",
            "|    explained_variance   | 0.0466      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.906       |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.00119    |\n",
            "|    value_loss           | 1.64        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 19.7       |\n",
            "|    ep_rew_mean          | 0.89       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 335        |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 513        |\n",
            "|    total_timesteps      | 172032     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00899405 |\n",
            "|    clip_fraction        | 0.0994     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.387     |\n",
            "|    explained_variance   | 0.0652     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.801      |\n",
            "|    n_updates            | 200        |\n",
            "|    policy_gradient_loss | 0.000832   |\n",
            "|    value_loss           | 1.61       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 21.2        |\n",
            "|    ep_rew_mean          | 1.19        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 335         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 537         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009302758 |\n",
            "|    clip_fraction        | 0.0881      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.358      |\n",
            "|    explained_variance   | 0.067       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.85        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | 8.43e-05    |\n",
            "|    value_loss           | 1.62        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 19.6        |\n",
            "|    ep_rew_mean          | 1.01        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 336         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 559         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009867024 |\n",
            "|    clip_fraction        | 0.0877      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.349      |\n",
            "|    explained_variance   | 0.0587      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.728       |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | 0.00132     |\n",
            "|    value_loss           | 1.71        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.2        |\n",
            "|    ep_rew_mean          | 1.3         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 336         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 583         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009849452 |\n",
            "|    clip_fraction        | 0.0872      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.33       |\n",
            "|    explained_variance   | 0.0997      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.967       |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | 0.000185    |\n",
            "|    value_loss           | 1.58        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | -0.28       |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.9        |\n",
            "|    ep_rew_mean          | 1.43        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 335         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 610         |\n",
            "|    total_timesteps      | 204800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012194995 |\n",
            "|    clip_fraction        | 0.0811      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.313      |\n",
            "|    explained_variance   | 0.0942      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.28        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -3.05e-05   |\n",
            "|    value_loss           | 1.68        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.3        |\n",
            "|    ep_rew_mean          | 1.33        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 336         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 633         |\n",
            "|    total_timesteps      | 212992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010376887 |\n",
            "|    clip_fraction        | 0.0772      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.304      |\n",
            "|    explained_variance   | 0.103       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.06        |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | 0.00188     |\n",
            "|    value_loss           | 1.44        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 20.8        |\n",
            "|    ep_rew_mean          | 1.17        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 336         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 657         |\n",
            "|    total_timesteps      | 221184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008091873 |\n",
            "|    clip_fraction        | 0.0748      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.307      |\n",
            "|    explained_variance   | 0.117       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.45        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | 0.000562    |\n",
            "|    value_loss           | 1.58        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.4        |\n",
            "|    ep_rew_mean          | 1.44        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 337         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 680         |\n",
            "|    total_timesteps      | 229376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009581009 |\n",
            "|    clip_fraction        | 0.0769      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.307      |\n",
            "|    explained_variance   | 0.115       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.835       |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | 0.00036     |\n",
            "|    value_loss           | 1.57        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 24.3       |\n",
            "|    ep_rew_mean          | 1.39       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 337        |\n",
            "|    iterations           | 29         |\n",
            "|    time_elapsed         | 703        |\n",
            "|    total_timesteps      | 237568     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01083207 |\n",
            "|    clip_fraction        | 0.078      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.324     |\n",
            "|    explained_variance   | 0.107      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.9        |\n",
            "|    n_updates            | 280        |\n",
            "|    policy_gradient_loss | 0.00166    |\n",
            "|    value_loss           | 1.54       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 24.9        |\n",
            "|    ep_rew_mean          | 1.63        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 337         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 727         |\n",
            "|    total_timesteps      | 245760      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010203817 |\n",
            "|    clip_fraction        | 0.0817      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.327      |\n",
            "|    explained_variance   | 0.105       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.603       |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | 0.000215    |\n",
            "|    value_loss           | 1.55        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.6        |\n",
            "|    ep_rew_mean          | 1.2         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 338         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 750         |\n",
            "|    total_timesteps      | 253952      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015651885 |\n",
            "|    clip_fraction        | 0.0859      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.32       |\n",
            "|    explained_variance   | 0.109       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.18        |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | 0.00155     |\n",
            "|    value_loss           | 1.53        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 23.7       |\n",
            "|    ep_rew_mean          | 1.45       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 338        |\n",
            "|    iterations           | 32         |\n",
            "|    time_elapsed         | 774        |\n",
            "|    total_timesteps      | 262144     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01102331 |\n",
            "|    clip_fraction        | 0.0814     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.326     |\n",
            "|    explained_variance   | 0.127      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.515      |\n",
            "|    n_updates            | 310        |\n",
            "|    policy_gradient_loss | -0.00101   |\n",
            "|    value_loss           | 1.48       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 21.4        |\n",
            "|    ep_rew_mean          | 1.34        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 796         |\n",
            "|    total_timesteps      | 270336      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008800589 |\n",
            "|    clip_fraction        | 0.0833      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.318      |\n",
            "|    explained_variance   | 0.11        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.753       |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | 0.00113     |\n",
            "|    value_loss           | 1.62        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23          |\n",
            "|    ep_rew_mean          | 1.4         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 820         |\n",
            "|    total_timesteps      | 278528      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010376068 |\n",
            "|    clip_fraction        | 0.0846      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.296      |\n",
            "|    explained_variance   | 0.11        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.91        |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | 0.000235    |\n",
            "|    value_loss           | 1.6         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.5        |\n",
            "|    ep_rew_mean          | 1.65        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 842         |\n",
            "|    total_timesteps      | 286720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008875037 |\n",
            "|    clip_fraction        | 0.0697      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.284      |\n",
            "|    explained_variance   | 0.118       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.542       |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.000384   |\n",
            "|    value_loss           | 1.66        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.2        |\n",
            "|    ep_rew_mean          | 1.72        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 866         |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008304207 |\n",
            "|    clip_fraction        | 0.0639      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.266      |\n",
            "|    explained_variance   | 0.0985      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.993       |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | 1.86e-05    |\n",
            "|    value_loss           | 1.77        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | -0.19       |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.7        |\n",
            "|    ep_rew_mean          | 1.38        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 893         |\n",
            "|    total_timesteps      | 303104      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008573499 |\n",
            "|    clip_fraction        | 0.0734      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.282      |\n",
            "|    explained_variance   | 0.119       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.729       |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | 0.00206     |\n",
            "|    value_loss           | 1.66        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.6        |\n",
            "|    ep_rew_mean          | 1.41        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 915         |\n",
            "|    total_timesteps      | 311296      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009596604 |\n",
            "|    clip_fraction        | 0.0744      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.276      |\n",
            "|    explained_variance   | 0.126       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.627       |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | 0.00168     |\n",
            "|    value_loss           | 1.52        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.8        |\n",
            "|    ep_rew_mean          | 1.69        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 939         |\n",
            "|    total_timesteps      | 319488      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012920185 |\n",
            "|    clip_fraction        | 0.074       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.274      |\n",
            "|    explained_variance   | 0.115       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.888       |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | 0.0012      |\n",
            "|    value_loss           | 1.6         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.4        |\n",
            "|    ep_rew_mean          | 1.36        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 962         |\n",
            "|    total_timesteps      | 327680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010127477 |\n",
            "|    clip_fraction        | 0.0764      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.291      |\n",
            "|    explained_variance   | 0.105       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.715       |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | 0.00103     |\n",
            "|    value_loss           | 1.51        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.5        |\n",
            "|    ep_rew_mean          | 1.59        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 988         |\n",
            "|    total_timesteps      | 335872      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008428543 |\n",
            "|    clip_fraction        | 0.0669      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.291      |\n",
            "|    explained_variance   | 0.125       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.973       |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | 0.001       |\n",
            "|    value_loss           | 1.57        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.8        |\n",
            "|    ep_rew_mean          | 1.69        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 1012        |\n",
            "|    total_timesteps      | 344064      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008378914 |\n",
            "|    clip_fraction        | 0.0731      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.293      |\n",
            "|    explained_variance   | 0.133       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.939       |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | 0.000672    |\n",
            "|    value_loss           | 1.52        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 27.8        |\n",
            "|    ep_rew_mean          | 2.07        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 1034        |\n",
            "|    total_timesteps      | 352256      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011725437 |\n",
            "|    clip_fraction        | 0.0764      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.28       |\n",
            "|    explained_variance   | 0.118       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.759       |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.000444   |\n",
            "|    value_loss           | 1.62        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-5bf3222fb443>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1_500_000 = 1 hour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 315\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# Normalize advantage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mevaluate_actions\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mlatent_vf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvf_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_action_dist_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msupport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "env = PuzzEnv()\n",
        "\n",
        "obs, _info = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "n_steps = 30\n",
        "for step in range(n_steps):\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  action, _states = model.predict(obs)\n",
        "  obs, reward, done, _, info = env.step(action)\n",
        "  # print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render()\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNaQQfU-Zi_z",
        "outputId": "4e40ea83-4ca6-40b8-a5de-ef1d94cdf3a7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Box(0, 255, (6, 6, 6), uint8)\n",
            "Discrete(4)\n",
            "0\n",
            "Step 1\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "Step 2\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 3\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 4\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 5\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 6\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 7\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 8\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 9\n",
            "\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 10\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 11\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 12\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 13\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 14\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 15\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 16\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 17\n",
            "\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 18\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 19\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 20\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 21\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 22\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 23\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 24\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 25\n",
            "\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 26\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 27\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 28\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 29\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Step 30\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "Goal reached! reward= 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a245ytFhwGg3"
      },
      "source": [
        "model.save('puzzdra_nn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q85IqDNWZvS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eecc81ff-5ced-448a-9890-7b92d0d723de"
      },
      "source": [
        "print(model.policy)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ActorCriticPolicy(\n",
            "  (features_extractor): FlattenExtractor(\n",
            "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (pi_features_extractor): FlattenExtractor(\n",
            "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (vf_features_extractor): FlattenExtractor(\n",
            "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (mlp_extractor): MlpExtractor(\n",
            "    (policy_net): Sequential(\n",
            "      (0): Linear(in_features=216, out_features=32, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (3): Tanh()\n",
            "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (5): Tanh()\n",
            "    )\n",
            "    (value_net): Sequential(\n",
            "      (0): Linear(in_features=216, out_features=32, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (3): Tanh()\n",
            "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (5): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (action_net): Linear(in_features=32, out_features=4, bias=True)\n",
            "  (value_net): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tXh-sdQYzfHT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}