{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "puzz.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPj/1NWFAlyKZJqlmNEdjQf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitosagi/puzzdra-nnsolver/blob/master/puzz_move.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrk7ju8ZSpq1"
      },
      "source": [
        "## 初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-syCb8S5ijR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0ec37a-2bbc-47ac-a925-7b0c6234f256"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MinijqIGMKzp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aeab927e-dd85-4147-eda6-8e7ea1090c6f"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/User/python/puzzdra-nnsolver /content/puzzdra-nnsolver\n",
        "%cd /content/puzzdra-nnsolver\n",
        "!pip install --log=pip_log -e .\n",
        "!pip install git+https://github.com/DLR-RM/stable-baselines3"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/puzzdra-nnsolver\n",
            "Obtaining file:///content/puzzdra-nnsolver\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: Puzzpy\n",
            "  Attempting uninstall: Puzzpy\n",
            "    Found existing installation: Puzzpy 1.0\n",
            "    Uninstalling Puzzpy-1.0:\n",
            "      Successfully uninstalled Puzzpy-1.0\n",
            "  Running setup.py develop for Puzzpy\n",
            "Successfully installed Puzzpy-1.0\n",
            "Collecting git+https://github.com/DLR-RM/stable-baselines3\n",
            "  Cloning https://github.com/DLR-RM/stable-baselines3 to /tmp/pip-req-build-2eddgafv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/stable-baselines3 /tmp/pip-req-build-2eddgafv\n",
            "  Resolved https://github.com/DLR-RM/stable-baselines3 to commit 69afefc91d408d352b4224ae5244ad2c32bb7634\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (1.26.1)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (2.1.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.0a9) (4.8.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.0a9) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.13.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3==2.2.0a9) (12.3.52)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==2.2.0a9) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==2.2.0a9) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.2.0a9) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3==2.2.0a9) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3==2.2.0a9) (1.3.0)\n",
            "Building wheels for collected packages: stable-baselines3\n",
            "  Building wheel for stable-baselines3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stable-baselines3: filename=stable_baselines3-2.2.0a9-py3-none-any.whl size=180895 sha256=021b8a108e8de49c5156f9e25f5a71192b8b8578ee4fd50d6ca39f296c20a1c9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eiih2sxx/wheels/3b/24/65/bc2794face336930a72bdbe36faf5aad6e2352b3d1dec310ca\n",
            "Successfully built stable-baselines3\n",
            "Installing collected packages: stable-baselines3\n",
            "  Attempting uninstall: stable-baselines3\n",
            "    Found existing installation: stable-baselines3 2.1.0\n",
            "    Uninstalling stable-baselines3-2.1.0:\n",
            "      Successfully uninstalled stable-baselines3-2.1.0\n",
            "Successfully installed stable-baselines3-2.2.0a9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "stable_baselines3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdUISRWiX4kM"
      },
      "source": [
        "## 実際の処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI2D4A-cXnQI"
      },
      "source": [
        "import numpy as np\n",
        "import gymnasium\n",
        "from gymnasium import spaces\n",
        "from puzzpy import PuzzTable\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "import random\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "\n",
        "class PuzzEnv(gymnasium.Env):\n",
        "  \"\"\"\n",
        "  パズドラの環境\n",
        "  \"\"\"\n",
        "  # ColabのためGUIを実装できない\n",
        "  metadata = {'render.modes': ['console']}\n",
        "\n",
        "  def __init__(self):\n",
        "    super(PuzzEnv, self).__init__()\n",
        "\n",
        "    self.action_space = spaces.Discrete(4) # 指を離す動作を含めると5\n",
        "    self.observation_space = spaces.Box(low=0, high=255, shape=(1,(5+1)*6,6*6), dtype=np.uint8) # +1 for metadata\n",
        "\n",
        "  def retobs(self, table):\n",
        "    metadata_array = np.zeros((1, 6), np.uint8)\n",
        "    metadata_array[0][0] = table.get_turn()\n",
        "    table_array = np.array(table.get_table()).astype(np.uint8) + 10 * np.array(table.get_XY_as_table()).astype(np.uint8)\n",
        "    tmp_array = np.stack([np.vstack([metadata_array, table_array])])\n",
        "    rew = table.eval_otoshi()\n",
        "    return np.repeat(np.repeat(tmp_array, 6, axis=2), 6, axis=1), rew, True, False, {}\n",
        "\n",
        "  def reset(self, seed = None, test_min = 10):\n",
        "    super().reset(seed=seed)\n",
        "    \"\"\"\n",
        "    【重要】観測はnumpy配列でなければならない\n",
        "    :return: (np.array)\n",
        "    \"\"\"\n",
        "    while True:\n",
        "      self.table = PuzzTable(\"\".join([str(random.randrange(3)) for i in range(5*6)]), random.randrange(6), random.randrange(5), test_min) # n色陣　操作時間m秒\n",
        "      if self.table.eval_otoshi() == 0:\n",
        "        break\n",
        "\n",
        "    return self.retobs(self.table)[0], {}\n",
        "\n",
        "  def step(self, action):\n",
        "    if action == 4: # 指を離す動作\n",
        "      return self.retobs(self.table)\n",
        "\n",
        "    next_table = self.table.next_tables()[action]\n",
        "\n",
        "    if next_table.get_table()[0][0] == 127: # 壁に移動\n",
        "      return self.retobs(self.table)[0], 0, True, False, {}\n",
        "\n",
        "    # if next_table.get_XY_as_table() == self.table.get_XY_as_table(): # 千日手\n",
        "    #   return self.retobs(self.table)[0], 0, True, False, {}\n",
        "\n",
        "    self.table = next_table\n",
        "\n",
        "    if self.table.get_turn() <= 0: # 時間切れ\n",
        "      return self.retobs(self.table)\n",
        "\n",
        "    return self.retobs(self.table)[0], 0, False, False, {}\n",
        "\n",
        "  def render(self, mode='console', close=False):\n",
        "    if mode != 'console':\n",
        "      raise NotImplementedError()\n",
        "\n",
        "    start = self.table.get_XY_as_table()\n",
        "    table = self.table.get_table()\n",
        "    for i in range(5):\n",
        "      for j in range(6):\n",
        "        if start[i][j] == 1:\n",
        "          print(bcolors.FAIL + str(table[i][j]) + bcolors.ENDC, end='')\n",
        "        else:\n",
        "          print(table[i][j], end='')\n",
        "\n",
        "      print('')\n",
        "\n",
        "check_env(PuzzEnv())"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Z9SliEfKci",
        "outputId": "dfd8bb05-23a0-442d-e0ed-4ef1f5f65e79"
      },
      "source": [
        "env = PuzzEnv()\n",
        "\n",
        "obs = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  obs, reward, done, _, info = env.step(env.action_space.sample())\n",
        "  print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render()\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "223231\n",
            "113123\n",
            "2311\u001b[91m3\u001b[0m1\n",
            "311223\n",
            "113132\n",
            "Box(0, 255, (1, 36, 36), uint8)\n",
            "Discrete(4)\n",
            "3\n",
            "Step 1\n",
            "obs= [[[9 9 9 ... 0 0 0]\n",
            "  [9 9 9 ... 0 0 0]\n",
            "  [9 9 9 ... 0 0 0]\n",
            "  ...\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]]] reward= 0 done= False\n",
            "223231\n",
            "113123\n",
            "23111\u001b[91m3\u001b[0m\n",
            "311223\n",
            "113132\n",
            "Step 2\n",
            "obs= [[[8 8 8 ... 0 0 0]\n",
            "  [8 8 8 ... 0 0 0]\n",
            "  [8 8 8 ... 0 0 0]\n",
            "  ...\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]]] reward= 0 done= False\n",
            "223231\n",
            "11312\u001b[91m3\u001b[0m\n",
            "231113\n",
            "311223\n",
            "113132\n",
            "Step 3\n",
            "obs= [[[7 7 7 ... 0 0 0]\n",
            "  [7 7 7 ... 0 0 0]\n",
            "  [7 7 7 ... 0 0 0]\n",
            "  ...\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]]] reward= 0 done= False\n",
            "223231\n",
            "1131\u001b[91m3\u001b[0m2\n",
            "231113\n",
            "311223\n",
            "113132\n",
            "Step 4\n",
            "obs= [[[6 6 6 ... 0 0 0]\n",
            "  [6 6 6 ... 0 0 0]\n",
            "  [6 6 6 ... 0 0 0]\n",
            "  ...\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]]] reward= 0 done= False\n",
            "223231\n",
            "113112\n",
            "2311\u001b[91m3\u001b[0m3\n",
            "311223\n",
            "113132\n",
            "Step 5\n",
            "obs= [[[5 5 5 ... 0 0 0]\n",
            "  [5 5 5 ... 0 0 0]\n",
            "  [5 5 5 ... 0 0 0]\n",
            "  ...\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]]] reward= 0 done= False\n",
            "223231\n",
            "1131\u001b[91m3\u001b[0m2\n",
            "231113\n",
            "311223\n",
            "113132\n",
            "Step 6\n",
            "obs= [[[4 4 4 ... 0 0 0]\n",
            "  [4 4 4 ... 0 0 0]\n",
            "  [4 4 4 ... 0 0 0]\n",
            "  ...\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]]] reward= 0 done= False\n",
            "223231\n",
            "11312\u001b[91m3\u001b[0m\n",
            "231113\n",
            "311223\n",
            "113132\n",
            "Step 7\n",
            "obs= [[[3 3 3 ... 0 0 0]\n",
            "  [3 3 3 ... 0 0 0]\n",
            "  [3 3 3 ... 0 0 0]\n",
            "  ...\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]]] reward= 0 done= False\n",
            "223231\n",
            "113123\n",
            "23111\u001b[91m3\u001b[0m\n",
            "311223\n",
            "113132\n",
            "Step 8\n",
            "obs= [[[2 2 2 ... 0 0 0]\n",
            "  [2 2 2 ... 0 0 0]\n",
            "  [2 2 2 ... 0 0 0]\n",
            "  ...\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]]] reward= 0 done= False\n",
            "223231\n",
            "11312\u001b[91m3\u001b[0m\n",
            "231113\n",
            "311223\n",
            "113132\n",
            "Step 9\n",
            "obs= [[[1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  ...\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]]] reward= 0 done= False\n",
            "223231\n",
            "1131\u001b[91m3\u001b[0m2\n",
            "231113\n",
            "311223\n",
            "113132\n",
            "Step 10\n",
            "obs= [[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]\n",
            "  [1 1 1 ... 2 2 2]]] reward= 1 done= True\n",
            "2232\u001b[91m3\u001b[0m1\n",
            "113132\n",
            "231113\n",
            "311223\n",
            "113132\n",
            "Goal reached! reward= 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "Ubsd-1EVqANb",
        "outputId": "46232cc3-9c6b-4b7c-a6e0-d10af82a16d4"
      },
      "source": [
        "%load_ext tensorboard\n",
        "# %tensorboard --logdir puzzdra_tensorboard\n",
        "%tensorboard --logdi puzzdra_tensorboard --host=127.0.0.1 --port=6006 --load_fast=false\n",
        "from google.colab import output\n",
        "output.serve_kernel_port_as_window(6006, path=\"\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 2).\n",
              "Contents of stderr:\n",
              "2023-10-28 13:31:50.570273: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
              "2023-10-28 13:31:50.570355: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
              "2023-10-28 13:31:50.570395: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
              "2023-10-28 13:31:52.182255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
              "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC] [--host ADDR]\n",
              "                   [--bind_all] [--port PORT] [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
              "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
              "                   [--grpc_creds_type {local,ssl,ssl_dev}] [--grpc_data_provider PORT]\n",
              "                   [--purge_orphaned_data BOOL] [--db URI] [--db_import] [--inspect]\n",
              "                   [--version_tb] [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
              "                   [--window_title TEXT] [--max_reload_threads COUNT] [--reload_interval SECONDS]\n",
              "                   [--reload_task TYPE] [--reload_multifile BOOL]\n",
              "                   [--reload_multifile_inactive_secs SECONDS] [--generic_data TYPE]\n",
              "                   [--samples_per_plugin SAMPLES_PER_PLUGIN] [--detect_file_replacement BOOL]\n",
              "                   {serve,dev} ...\n",
              "tensorboard: error: ambiguous option: --logdi could match --logdir, --logdir_spec"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/output/_util.py:114: DeprecationWarning: This has been deprecated due to changes in browser security. Use `serve_kernel_port_as_iframe` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(6006, \"\", \"https://localhost:6006\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_qAMMmQnTtw",
        "outputId": "fec2fb16-2b53-4633-e838-8b17b59ac9a5"
      },
      "source": [
        "# 実行前にログ名を設定すること!!!\n",
        "log_name='PPO gamma no turn no prev'\n",
        "\n",
        "from stable_baselines3 import PPO, SAC\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.envs.multi_input_envs import SimpleMultiObsEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from statistics import mean\n",
        "\n",
        "class TensorboardCallback(BaseCallback):\n",
        "  \"\"\"\n",
        "  Custom callback for plotting additional values in tensorboard.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, verbose=0):\n",
        "    super(TensorboardCallback, self).__init__(verbose)\n",
        "    self.check_freq = 1000\n",
        "\n",
        "  def _on_step(self) -> bool:\n",
        "    if self.n_calls % self.check_freq == 0:\n",
        "\n",
        "      env = PuzzEnv()\n",
        "      rew_array = []\n",
        "\n",
        "      for test in range(100):\n",
        "        obs, _info = env.reset()\n",
        "        n_steps = 100\n",
        "        for step in range(n_steps):\n",
        "          action, _ = model.predict(obs, deterministic=True)\n",
        "          obs, reward, done, _, info = env.step(action)\n",
        "          if done:\n",
        "            rew_array.append(reward)\n",
        "            break\n",
        "\n",
        "      self.logger.record('combo', mean(rew_array))\n",
        "    return True\n",
        "\n",
        "# for i in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
        "for i in [1.0]:\n",
        "  log_name='PPO gamma ' + str(i)\n",
        "\n",
        "  # 環境の生成\n",
        "  env = PuzzEnv()\n",
        "\n",
        "  # 環境のラップ\n",
        "  monienv = Monitor(env, filename=None, allow_early_resets=True)\n",
        "\n",
        "  # エージェントの訓練\n",
        "  model = PPO('CnnPolicy', monienv, verbose=1, tensorboard_log=\"./puzzdra_tensorboard/\").learn(70000, tb_log_name=log_name, callback=TensorboardCallback()) # 1500000 = 1 hour"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Logging to ./puzzdra_tensorboard/PPO gamma 1.0_6\n",
            "---------------------------------\n",
            "| combo              | 1.54     |\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5.58     |\n",
            "|    ep_rew_mean     | 0.3      |\n",
            "| time/              |          |\n",
            "|    fps             | 267      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 7        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.3         |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.77        |\n",
            "|    ep_rew_mean          | 0.32        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 221         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009536381 |\n",
            "|    clip_fraction        | 0.0489      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 5.75e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.249       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00588    |\n",
            "|    value_loss           | 0.737       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.42        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.79        |\n",
            "|    ep_rew_mean          | 0.42        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 215         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 28          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010926407 |\n",
            "|    clip_fraction        | 0.0852      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | 0.16        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.231       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0166     |\n",
            "|    value_loss           | 0.568       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.47        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.81        |\n",
            "|    ep_rew_mean          | 0.85        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 209         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017511668 |\n",
            "|    clip_fraction        | 0.285       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | 0.116       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.241       |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0349     |\n",
            "|    value_loss           | 0.614       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.46        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.08        |\n",
            "|    ep_rew_mean          | 1.06        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 208         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 49          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013658203 |\n",
            "|    clip_fraction        | 0.188       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.27       |\n",
            "|    explained_variance   | 0.0892      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.486       |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0233     |\n",
            "|    value_loss           | 1.02        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| combo                   | 1.55         |\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 8.85         |\n",
            "|    ep_rew_mean          | 1.12         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 208          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0152816195 |\n",
            "|    clip_fraction        | 0.189        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.22        |\n",
            "|    explained_variance   | -0.136       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.285        |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.0199      |\n",
            "|    value_loss           | 0.911        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.74        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.28        |\n",
            "|    ep_rew_mean          | 1.12        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 206         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 69          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011430861 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.17       |\n",
            "|    explained_variance   | -0.0296     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.322       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0137     |\n",
            "|    value_loss           | 0.922       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.43        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.18        |\n",
            "|    ep_rew_mean          | 1.14        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 206         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 79          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013765333 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.14       |\n",
            "|    explained_variance   | -0.0492     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.372       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    value_loss           | 0.858       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.59        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.38        |\n",
            "|    ep_rew_mean          | 1.34        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 204         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 90          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010632927 |\n",
            "|    clip_fraction        | 0.128       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.11       |\n",
            "|    explained_variance   | -0.043      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.464       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0104     |\n",
            "|    value_loss           | 0.925       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.59        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.91        |\n",
            "|    ep_rew_mean          | 1.26        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 204         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013228821 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.1        |\n",
            "|    explained_variance   | -0.0947     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.451       |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0103     |\n",
            "|    value_loss           | 0.954       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.68        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.84        |\n",
            "|    ep_rew_mean          | 1.35        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 202         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 111         |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012374421 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.13       |\n",
            "|    explained_variance   | -0.0791     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.542       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00619    |\n",
            "|    value_loss           | 0.935       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| combo                   | 1.38         |\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 9.86         |\n",
            "|    ep_rew_mean          | 1.48         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 203          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 120          |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0097649805 |\n",
            "|    clip_fraction        | 0.106        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.1         |\n",
            "|    explained_variance   | -0.0741      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.433        |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00843     |\n",
            "|    value_loss           | 0.909        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.33        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.73        |\n",
            "|    ep_rew_mean          | 1.17        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 201         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 132         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011557169 |\n",
            "|    clip_fraction        | 0.134       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | -0.0544     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.471       |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    value_loss           | 1.09        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.44        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.61        |\n",
            "|    ep_rew_mean          | 1.38        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 202         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 141         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012321849 |\n",
            "|    clip_fraction        | 0.155       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.04       |\n",
            "|    explained_variance   | -0.128      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.233       |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0143     |\n",
            "|    value_loss           | 0.842       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.47        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 10          |\n",
            "|    ep_rew_mean          | 1.63        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 200         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 153         |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012297293 |\n",
            "|    clip_fraction        | 0.179       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | -0.195      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.43        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0126     |\n",
            "|    value_loss           | 0.878       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.71        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.83        |\n",
            "|    ep_rew_mean          | 1.43        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 201         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 162         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010367612 |\n",
            "|    clip_fraction        | 0.119       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.975      |\n",
            "|    explained_variance   | -0.069      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.32        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00937    |\n",
            "|    value_loss           | 0.824       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.59        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 10          |\n",
            "|    ep_rew_mean          | 1.85        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 200         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 173         |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012912698 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.972      |\n",
            "|    explained_variance   | -0.127      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.351       |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0132     |\n",
            "|    value_loss           | 0.994       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| combo                   | 1.57         |\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 9.95         |\n",
            "|    ep_rew_mean          | 1.6          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 201          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 182          |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0135568455 |\n",
            "|    clip_fraction        | 0.125        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.939       |\n",
            "|    explained_variance   | -0.107       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.288        |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00789     |\n",
            "|    value_loss           | 0.914        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.63        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.86        |\n",
            "|    ep_rew_mean          | 1.69        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 199         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 194         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017035708 |\n",
            "|    clip_fraction        | 0.178       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.853      |\n",
            "|    explained_variance   | -0.159      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.239       |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    value_loss           | 0.735       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.62        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.91        |\n",
            "|    ep_rew_mean          | 1.51        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 201         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 203         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013128231 |\n",
            "|    clip_fraction        | 0.146       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.858      |\n",
            "|    explained_variance   | -0.204      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.252       |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0113     |\n",
            "|    value_loss           | 0.833       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.52        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 10          |\n",
            "|    ep_rew_mean          | 1.94        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 196         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 219         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011995796 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.853      |\n",
            "|    explained_variance   | -0.247      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.189       |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0153     |\n",
            "|    value_loss           | 0.565       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.53        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.91        |\n",
            "|    ep_rew_mean          | 1.68        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 194         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 232         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011450786 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.854      |\n",
            "|    explained_variance   | -0.112      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.445       |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0104     |\n",
            "|    value_loss           | 0.898       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| combo                   | 1.56         |\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 9.92         |\n",
            "|    ep_rew_mean          | 1.91         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 194          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 241          |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0134896245 |\n",
            "|    clip_fraction        | 0.138        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.823       |\n",
            "|    explained_variance   | -0.164       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.233        |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.0118      |\n",
            "|    value_loss           | 0.805        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.39        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.91        |\n",
            "|    ep_rew_mean          | 1.74        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 194         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 252         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015028932 |\n",
            "|    clip_fraction        | 0.181       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.802      |\n",
            "|    explained_variance   | -0.225      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.288       |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0148     |\n",
            "|    value_loss           | 0.786       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.56        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.88        |\n",
            "|    ep_rew_mean          | 1.85        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 194         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 262         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012993141 |\n",
            "|    clip_fraction        | 0.133       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.828      |\n",
            "|    explained_variance   | -0.151      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.281       |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 0.808       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.61        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.87        |\n",
            "|    ep_rew_mean          | 1.77        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 194         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 273         |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014434541 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.812      |\n",
            "|    explained_variance   | -0.0886     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.181       |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0132     |\n",
            "|    value_loss           | 0.854       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| combo                   | 1.49       |\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 10         |\n",
            "|    ep_rew_mean          | 1.89       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 192        |\n",
            "|    iterations           | 27         |\n",
            "|    time_elapsed         | 286        |\n",
            "|    total_timesteps      | 55296      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01269727 |\n",
            "|    clip_fraction        | 0.146      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.804     |\n",
            "|    explained_variance   | -0.119     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.262      |\n",
            "|    n_updates            | 260        |\n",
            "|    policy_gradient_loss | -0.0118    |\n",
            "|    value_loss           | 0.798      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.33        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.68        |\n",
            "|    ep_rew_mean          | 1.57        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 191         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 299         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015819475 |\n",
            "|    clip_fraction        | 0.153       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.773      |\n",
            "|    explained_variance   | -0.172      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.193       |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.018      |\n",
            "|    value_loss           | 0.728       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.39        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.93        |\n",
            "|    ep_rew_mean          | 1.76        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 192         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 308         |\n",
            "|    total_timesteps      | 59392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014598266 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.765      |\n",
            "|    explained_variance   | -0.221      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.462       |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 1.01        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.49        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.91        |\n",
            "|    ep_rew_mean          | 1.75        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 191         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 320         |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015520406 |\n",
            "|    clip_fraction        | 0.16        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.736      |\n",
            "|    explained_variance   | -0.353      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.264       |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.0138     |\n",
            "|    value_loss           | 0.819       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.55        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.86        |\n",
            "|    ep_rew_mean          | 1.72        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 192         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 329         |\n",
            "|    total_timesteps      | 63488       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012741936 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.715      |\n",
            "|    explained_variance   | -0.137      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.208       |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.0139     |\n",
            "|    value_loss           | 0.838       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.42        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.89        |\n",
            "|    ep_rew_mean          | 1.71        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 192         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 340         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010719854 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.708      |\n",
            "|    explained_variance   | -0.186      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.249       |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.00949    |\n",
            "|    value_loss           | 0.871       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| combo                   | 1.49         |\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 9.8          |\n",
            "|    ep_rew_mean          | 1.88         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 192          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 350          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0136903385 |\n",
            "|    clip_fraction        | 0.13         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.69        |\n",
            "|    explained_variance   | -0.204       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.16         |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.0133      |\n",
            "|    value_loss           | 0.789        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.35        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.87        |\n",
            "|    ep_rew_mean          | 1.63        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 192         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 361         |\n",
            "|    total_timesteps      | 69632       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015632387 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.686      |\n",
            "|    explained_variance   | -0.213      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.271       |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.0116     |\n",
            "|    value_loss           | 0.694       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.48        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.84        |\n",
            "|    ep_rew_mean          | 1.83        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 193         |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 371         |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016512983 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.674      |\n",
            "|    explained_variance   | -0.283      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.265       |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.0117     |\n",
            "|    value_loss           | 0.711       |\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "env = PuzzEnv()\n",
        "\n",
        "obs, _info = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  action, _states = model.predict(obs)\n",
        "  obs, reward, done, _, info = env.step(action)\n",
        "  # print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render()\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNaQQfU-Zi_z",
        "outputId": "dfa9fda9-285b-45fa-86e7-fd5630e3f46c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231123\n",
            "121132\n",
            "123322\n",
            "31322\u001b[91m3\u001b[0m\n",
            "221131\n",
            "Box(0, 255, (1, 36, 36), uint8)\n",
            "Discrete(4)\n",
            "0\n",
            "Step 1\n",
            "231123\n",
            "121132\n",
            "123322\n",
            "3132\u001b[91m3\u001b[0m2\n",
            "221131\n",
            "Step 2\n",
            "231123\n",
            "121132\n",
            "123322\n",
            "313\u001b[91m3\u001b[0m22\n",
            "221131\n",
            "Step 3\n",
            "231123\n",
            "121132\n",
            "123322\n",
            "31\u001b[91m3\u001b[0m322\n",
            "221131\n",
            "Step 4\n",
            "231123\n",
            "121132\n",
            "12\u001b[91m3\u001b[0m322\n",
            "313322\n",
            "221131\n",
            "Step 5\n",
            "231123\n",
            "121132\n",
            "1\u001b[91m3\u001b[0m2322\n",
            "313322\n",
            "221131\n",
            "Step 6\n",
            "231123\n",
            "121132\n",
            "12\u001b[91m3\u001b[0m322\n",
            "313322\n",
            "221131\n",
            "Step 7\n",
            "231123\n",
            "121132\n",
            "123322\n",
            "31\u001b[91m3\u001b[0m322\n",
            "221131\n",
            "Step 8\n",
            "231123\n",
            "121132\n",
            "123322\n",
            "3\u001b[91m3\u001b[0m1322\n",
            "221131\n",
            "Step 9\n",
            "231123\n",
            "121132\n",
            "123322\n",
            "31\u001b[91m3\u001b[0m322\n",
            "221131\n",
            "Step 10\n",
            "231123\n",
            "121132\n",
            "12\u001b[91m3\u001b[0m322\n",
            "313322\n",
            "221131\n",
            "Goal reached! reward= 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a245ytFhwGg3"
      },
      "source": [
        "model.save('puzzdra_nn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q85IqDNWZvS-"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}