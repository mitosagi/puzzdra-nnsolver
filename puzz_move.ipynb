{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "puzz.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+BEjg1T2umbSvG02Iit9Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitosagi/puzzdra-nnsolver/blob/master/puzz_move.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrk7ju8ZSpq1"
      },
      "source": [
        "## 初期化"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "docker run -p 9000:8080 -p 6006:6006 asia-docker.pkg.dev/colab-images/public/runtime"
      ],
      "metadata": {
        "id": "sIUxSuc1nPHd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MinijqIGMKzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c6e5f7c-e13c-40cb-c85b-6ad1686a81b3"
      },
      "source": [
        "%cd /content/\n",
        "!git clone --recursive https://github.com/mitosagi/puzzdra-nnsolver\n",
        "%cd /content/puzzdra-nnsolver\n",
        "!pip install --log=pip_log -e .\n",
        "!pip install git+https://github.com/DLR-RM/stable-baselines3\n",
        "# !pip install sbx-rl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'puzzdra-nnsolver'...\n",
            "remote: Enumerating objects: 278, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 278 (delta 19), reused 0 (delta 0), pack-reused 245\u001b[K\n",
            "Receiving objects: 100% (278/278), 8.28 MiB | 25.17 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n",
            "Submodule 'extern/pybind11' (https://github.com/pybind/pybind11) registered for path 'extern/pybind11'\n",
            "Cloning into '/content/puzzdra-nnsolver/extern/pybind11'...\n",
            "remote: Enumerating objects: 27212, done.        \n",
            "remote: Counting objects: 100% (1131/1131), done.        \n",
            "remote: Compressing objects: 100% (395/395), done.        \n",
            "remote: Total 27212 (delta 749), reused 956 (delta 659), pack-reused 26081        \n",
            "Receiving objects: 100% (27212/27212), 10.56 MiB | 20.68 MiB/s, done.\n",
            "Resolving deltas: 100% (19069/19069), done.\n",
            "Submodule path 'extern/pybind11': checked out '8de7772cc72daca8e947b79b83fea46214931604'\n",
            "/content/puzzdra-nnsolver\n",
            "Obtaining file:///content/puzzdra-nnsolver\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: Puzzpy\n",
            "  Running setup.py develop for Puzzpy\n",
            "Successfully installed Puzzpy-1.0\n",
            "Collecting git+https://github.com/DLR-RM/stable-baselines3\n",
            "  Cloning https://github.com/DLR-RM/stable-baselines3 to /tmp/pip-req-build-lmenwymf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/stable-baselines3 /tmp/pip-req-build-lmenwymf\n",
            "  Resolved https://github.com/DLR-RM/stable-baselines3 to commit 69afefc91d408d352b4224ae5244ad2c32bb7634\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gymnasium<0.30,>=0.28.1 (from stable-baselines3==2.2.0a9)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (2.0.1+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.0a9) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.0a9)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->stable-baselines3==2.2.0a9) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->stable-baselines3==2.2.0a9) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==2.2.0a9) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.2.0a9) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3==2.2.0a9) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3==2.2.0a9) (1.3.0)\n",
            "Building wheels for collected packages: stable-baselines3\n",
            "  Building wheel for stable-baselines3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stable-baselines3: filename=stable_baselines3-2.2.0a9-py3-none-any.whl size=180895 sha256=3edd34efcd2ec7bba8f0cb528bcd239274d532c4d8aa89878c8743ab43397285\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qysid37e/wheels/3b/24/65/bc2794face336930a72bdbe36faf5aad6e2352b3d1dec310ca\n",
            "Successfully built stable-baselines3\n",
            "Installing collected packages: farama-notifications, gymnasium, stable-baselines3\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 stable-baselines3-2.2.0a9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdUISRWiX4kM"
      },
      "source": [
        "## 実際の処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI2D4A-cXnQI",
        "outputId": "ca222d04-69e2-4b95-b785-40c65e66e35a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import gymnasium\n",
        "from gymnasium import spaces\n",
        "from puzzpy import PuzzTable\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "import random\n",
        "\n",
        "drop_color = 3\n",
        "board_width = 6\n",
        "board_height = 5\n",
        "min_width = 6 # 36 if CNN, 6 if manual MLP or CNN\n",
        "min_height = 5\n",
        "buffer = 2 # num of previous observation\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "    BLACK = '\\033[30m'\n",
        "    RED = '\\033[31m'\n",
        "    GREEN = '\\033[32m'\n",
        "    YELLOW = '\\033[33m'\n",
        "    BLUE = '\\033[34m'\n",
        "    MAGENTA = '\\033[35m'\n",
        "    CYAN = '\\033[36m'\n",
        "\n",
        "class PuzzEnv(gymnasium.Env):\n",
        "  \"\"\"\n",
        "  パズドラの環境\n",
        "  \"\"\"\n",
        "  # ColabのためGUIを実装できない\n",
        "  metadata = {'render.modes': ['console']}\n",
        "\n",
        "  def __init__(self):\n",
        "    super(PuzzEnv, self).__init__()\n",
        "\n",
        "    self.action_space = spaces.Discrete(4) # 指を離す動作を含めると5\n",
        "    self.observation_space = spaces.Box(low=0, high=255, shape=(1+1+drop_color, max(min_height, board_height) * buffer, max(min_width, board_width)), dtype=np.uint8) # 1 for turn num, +1 for finger position\n",
        "    self.buffer_tmp_array = None\n",
        "    self.rew = 0\n",
        "\n",
        "  def retobs(self, table):\n",
        "    turn_array = [np.full((board_height, board_width), table.get_turn(), np.uint8)]\n",
        "    finger_array = np.array([np.array(table.get_XY_as_table()).astype(np.uint8)]).astype(np.uint8)\n",
        "    table_array = np.array(table.get_table()).astype(np.uint8)\n",
        "    u = np.arange(table_array.max()+1)\n",
        "    table_array = (u[:,np.newaxis,np.newaxis]==table_array).astype(np.uint8)[1:] # ドロップをone-hotにする https://stackoverflow.com/questions/67249470/convert-a-2d-numpy-array-into-a-hot-encoded-3d-numpy-array-with-same-values-in\n",
        "    tmp_array = np.pad(np.concatenate([turn_array, finger_array, table_array]), [(0,0), (0, max(min_height - board_height, 0)), (0, max(min_width - board_width, 0))], mode='constant', constant_values=0)\n",
        "    if self.buffer_tmp_array is None:\n",
        "       self.buffer_tmp_array = np.concatenate([tmp_array for i in range(buffer)], 1)\n",
        "    tmp_array = np.concatenate([tmp_array, self.buffer_tmp_array[:, :- tmp_array.shape[1]]], 1)\n",
        "    self.buffer_tmp_array = tmp_array\n",
        "    now_rew = table.eval_otoshi()\n",
        "    step_rew = now_rew - self.rew\n",
        "    self.rew = now_rew\n",
        "    return tmp_array, step_rew\n",
        "\n",
        "  def reset(self, seed = None, test_min = 30):\n",
        "    self.buffer_tmp_array = None\n",
        "    self.rew = 0\n",
        "\n",
        "    super().reset(seed=seed)\n",
        "    \"\"\"\n",
        "    【重要】観測はnumpy配列でなければならない\n",
        "    :return: (np.array)\n",
        "    \"\"\"\n",
        "    while True:\n",
        "      self.table = PuzzTable(\"\".join([str(random.randrange(drop_color)) for i in range(board_width*board_height)]), random.randrange(board_width), random.randrange(board_height), test_min) # n色陣　操作時間m秒\n",
        "      if self.table.eval_otoshi() == 0:\n",
        "        break\n",
        "\n",
        "    return self.retobs(self.table)[0], {}\n",
        "\n",
        "  def step(self, action):\n",
        "    if action == 4: # 指を離す動作\n",
        "      return *(self.retobs(self.table)), True, False, {}\n",
        "\n",
        "    next_table = self.table.next_tables()[action]\n",
        "\n",
        "    if next_table.get_table()[0][0] == 127: # 壁に移動\n",
        "      self.table.set_turn(self.table.get_turn() - 1)\n",
        "      next_table = self.table\n",
        "\n",
        "    self.table = next_table\n",
        "\n",
        "    if self.table.get_turn() <= 0: # 時間切れ\n",
        "      return *(self.retobs(self.table)), True, False, {}\n",
        "\n",
        "    return *(self.retobs(self.table)), False, False, {}\n",
        "\n",
        "  def render(self, mode='console', close=False):\n",
        "    if mode != 'console':\n",
        "      raise NotImplementedError()\n",
        "\n",
        "    tcolor = [bcolors.RED, bcolors.BLUE, bcolors.GREEN, bcolors.MAGENTA, bcolors.YELLOW, bcolors.BLACK]\n",
        "    start = self.table.get_XY_as_table()\n",
        "    table = self.table.get_table()\n",
        "    for i in range(board_height):\n",
        "      for j in range(board_width):\n",
        "        if start[i][j] == 1:\n",
        "          print(tcolor[table[i][j]-1]  +  bcolors.UNDERLINE + \"●\" + bcolors.ENDC, end='')\n",
        "        else:\n",
        "          print(tcolor[table[i][j]-1]  + \"●\" + bcolors.ENDC, end='')\n",
        "\n",
        "      print('')\n",
        "\n",
        "check_env(PuzzEnv())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:51: UserWarning: The minimal resolution for an image is 36x36 for the default `CnnPolicy`. You might need to use a custom features extractor cf. https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Z9SliEfKci",
        "outputId": "9b74f8c4-afdb-41cd-c2ef-9592459bf2bf"
      },
      "source": [
        "env = PuzzEnv()\n",
        "\n",
        "obs = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  obs, reward, done, _, info = env.step(env.action_space.sample())\n",
        "  print('obs=', obs.shape, 'reward=', reward, 'done=', done)\n",
        "  with np.printoptions(threshold=np.inf):\n",
        "    print(obs)\n",
        "  env.render()\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "Box(0, 255, (5, 10, 6), uint8)\n",
            "Discrete(4)\n",
            "3\n",
            "Step 1\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [30 30 30 30 30 30]\n",
            "  [30 30 30 30 30 30]\n",
            "  [30 30 30 30 30 30]\n",
            "  [30 30 30 30 30 30]\n",
            "  [30 30 30 30 30 30]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  1  0]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  1]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "Step 2\n",
            "obs= (5, 10, 6) reward= 1 done= False\n",
            "[[[28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  1  0]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  1  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  1]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 3\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  1  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  1  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 4\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]\n",
            "  [27 27 27 27 27 27]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  1  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  1  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  1  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 5\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[25 25 25 25 25 25]\n",
            "  [25 25 25 25 25 25]\n",
            "  [25 25 25 25 25 25]\n",
            "  [25 25 25 25 25 25]\n",
            "  [25 25 25 25 25 25]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]\n",
            "  [26 26 26 26 26 26]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  1  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  1  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 6\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[24 24 24 24 24 24]\n",
            "  [24 24 24 24 24 24]\n",
            "  [24 24 24 24 24 24]\n",
            "  [24 24 24 24 24 24]\n",
            "  [24 24 24 24 24 24]\n",
            "  [25 25 25 25 25 25]\n",
            "  [25 25 25 25 25 25]\n",
            "  [25 25 25 25 25 25]\n",
            "  [25 25 25 25 25 25]\n",
            "  [25 25 25 25 25 25]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  1]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  1  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 7\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[23 23 23 23 23 23]\n",
            "  [23 23 23 23 23 23]\n",
            "  [23 23 23 23 23 23]\n",
            "  [23 23 23 23 23 23]\n",
            "  [23 23 23 23 23 23]\n",
            "  [24 24 24 24 24 24]\n",
            "  [24 24 24 24 24 24]\n",
            "  [24 24 24 24 24 24]\n",
            "  [24 24 24 24 24 24]\n",
            "  [24 24 24 24 24 24]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  0]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  0]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  1]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 8\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[22 22 22 22 22 22]\n",
            "  [22 22 22 22 22 22]\n",
            "  [22 22 22 22 22 22]\n",
            "  [22 22 22 22 22 22]\n",
            "  [22 22 22 22 22 22]\n",
            "  [23 23 23 23 23 23]\n",
            "  [23 23 23 23 23 23]\n",
            "  [23 23 23 23 23 23]\n",
            "  [23 23 23 23 23 23]\n",
            "  [23 23 23 23 23 23]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  0  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  1  0]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 9\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[21 21 21 21 21 21]\n",
            "  [21 21 21 21 21 21]\n",
            "  [21 21 21 21 21 21]\n",
            "  [21 21 21 21 21 21]\n",
            "  [21 21 21 21 21 21]\n",
            "  [22 22 22 22 22 22]\n",
            "  [22 22 22 22 22 22]\n",
            "  [22 22 22 22 22 22]\n",
            "  [22 22 22 22 22 22]\n",
            "  [22 22 22 22 22 22]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  1  0  0  0  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 10\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[20 20 20 20 20 20]\n",
            "  [20 20 20 20 20 20]\n",
            "  [20 20 20 20 20 20]\n",
            "  [20 20 20 20 20 20]\n",
            "  [20 20 20 20 20 20]\n",
            "  [21 21 21 21 21 21]\n",
            "  [21 21 21 21 21 21]\n",
            "  [21 21 21 21 21 21]\n",
            "  [21 21 21 21 21 21]\n",
            "  [21 21 21 21 21 21]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 11\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[19 19 19 19 19 19]\n",
            "  [19 19 19 19 19 19]\n",
            "  [19 19 19 19 19 19]\n",
            "  [19 19 19 19 19 19]\n",
            "  [19 19 19 19 19 19]\n",
            "  [20 20 20 20 20 20]\n",
            "  [20 20 20 20 20 20]\n",
            "  [20 20 20 20 20 20]\n",
            "  [20 20 20 20 20 20]\n",
            "  [20 20 20 20 20 20]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 12\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[18 18 18 18 18 18]\n",
            "  [18 18 18 18 18 18]\n",
            "  [18 18 18 18 18 18]\n",
            "  [18 18 18 18 18 18]\n",
            "  [18 18 18 18 18 18]\n",
            "  [19 19 19 19 19 19]\n",
            "  [19 19 19 19 19 19]\n",
            "  [19 19 19 19 19 19]\n",
            "  [19 19 19 19 19 19]\n",
            "  [19 19 19 19 19 19]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  1  0]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 13\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[17 17 17 17 17 17]\n",
            "  [17 17 17 17 17 17]\n",
            "  [17 17 17 17 17 17]\n",
            "  [17 17 17 17 17 17]\n",
            "  [17 17 17 17 17 17]\n",
            "  [18 18 18 18 18 18]\n",
            "  [18 18 18 18 18 18]\n",
            "  [18 18 18 18 18 18]\n",
            "  [18 18 18 18 18 18]\n",
            "  [18 18 18 18 18 18]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  1  0]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 14\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[16 16 16 16 16 16]\n",
            "  [16 16 16 16 16 16]\n",
            "  [16 16 16 16 16 16]\n",
            "  [16 16 16 16 16 16]\n",
            "  [16 16 16 16 16 16]\n",
            "  [17 17 17 17 17 17]\n",
            "  [17 17 17 17 17 17]\n",
            "  [17 17 17 17 17 17]\n",
            "  [17 17 17 17 17 17]\n",
            "  [17 17 17 17 17 17]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 15\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[15 15 15 15 15 15]\n",
            "  [15 15 15 15 15 15]\n",
            "  [15 15 15 15 15 15]\n",
            "  [15 15 15 15 15 15]\n",
            "  [15 15 15 15 15 15]\n",
            "  [16 16 16 16 16 16]\n",
            "  [16 16 16 16 16 16]\n",
            "  [16 16 16 16 16 16]\n",
            "  [16 16 16 16 16 16]\n",
            "  [16 16 16 16 16 16]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  1  0]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 16\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[14 14 14 14 14 14]\n",
            "  [14 14 14 14 14 14]\n",
            "  [14 14 14 14 14 14]\n",
            "  [14 14 14 14 14 14]\n",
            "  [14 14 14 14 14 14]\n",
            "  [15 15 15 15 15 15]\n",
            "  [15 15 15 15 15 15]\n",
            "  [15 15 15 15 15 15]\n",
            "  [15 15 15 15 15 15]\n",
            "  [15 15 15 15 15 15]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  0  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  1  0]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 17\n",
            "obs= (5, 10, 6) reward= 2 done= False\n",
            "[[[13 13 13 13 13 13]\n",
            "  [13 13 13 13 13 13]\n",
            "  [13 13 13 13 13 13]\n",
            "  [13 13 13 13 13 13]\n",
            "  [13 13 13 13 13 13]\n",
            "  [14 14 14 14 14 14]\n",
            "  [14 14 14 14 14 14]\n",
            "  [14 14 14 14 14 14]\n",
            "  [14 14 14 14 14 14]\n",
            "  [14 14 14 14 14 14]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  0  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  0  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  0  1  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 18\n",
            "obs= (5, 10, 6) reward= -2 done= False\n",
            "[[[12 12 12 12 12 12]\n",
            "  [12 12 12 12 12 12]\n",
            "  [12 12 12 12 12 12]\n",
            "  [12 12 12 12 12 12]\n",
            "  [12 12 12 12 12 12]\n",
            "  [13 13 13 13 13 13]\n",
            "  [13 13 13 13 13 13]\n",
            "  [13 13 13 13 13 13]\n",
            "  [13 13 13 13 13 13]\n",
            "  [13 13 13 13 13 13]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  0  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  0  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  0  1  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 19\n",
            "obs= (5, 10, 6) reward= 0 done= False\n",
            "[[[11 11 11 11 11 11]\n",
            "  [11 11 11 11 11 11]\n",
            "  [11 11 11 11 11 11]\n",
            "  [11 11 11 11 11 11]\n",
            "  [11 11 11 11 11 11]\n",
            "  [12 12 12 12 12 12]\n",
            "  [12 12 12 12 12 12]\n",
            "  [12 12 12 12 12 12]\n",
            "  [12 12 12 12 12 12]\n",
            "  [12 12 12 12 12 12]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  0  1]\n",
            "  [ 0  1  0  1  1  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  1  0]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  1  0  0  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 20\n",
            "obs= (5, 10, 6) reward= -1 done= False\n",
            "[[[10 10 10 10 10 10]\n",
            "  [10 10 10 10 10 10]\n",
            "  [10 10 10 10 10 10]\n",
            "  [10 10 10 10 10 10]\n",
            "  [10 10 10 10 10 10]\n",
            "  [11 11 11 11 11 11]\n",
            "  [11 11 11 11 11 11]\n",
            "  [11 11 11 11 11 11]\n",
            "  [11 11 11 11 11 11]\n",
            "  [11 11 11 11 11 11]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  1  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 1  0  1  0  0  0]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 1  1  0  0  1  1]\n",
            "  [ 0  1  0  1  0  1]\n",
            "  [ 1  0  1  0  0  1]]\n",
            "\n",
            " [[ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  0  1]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  1  0  0  1  1]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  1  0  1  0]\n",
            "  [ 0  1  0  1  0  0]]\n",
            "\n",
            " [[ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]\n",
            "  [ 0  0  0  1  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  1  1  0  0]\n",
            "  [ 1  0  0  0  0  0]\n",
            "  [ 0  0  0  0  1  0]]]\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m\u001b[4m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "Ubsd-1EVqANb",
        "outputId": "eaf0e505-cb4f-4a4f-c13c-61323aa1c3aa"
      },
      "source": [
        "# %load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "# %tensorboard --logdir puzzdra_tensorboard --load_fast=false\n",
        "%tensorboard --logdir puzzdra_tensorboard --host=127.0.0.1 --port=6008 #--load_fast=false\n",
        "from google.colab import output\n",
        "output.serve_kernel_port_as_window(6008, path=\"\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6008 (pid 874), started 0:00:10 ago. (Use '!kill 874' to kill it.)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6008, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(6008, \"\", \"https://localhost:6008\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h_qAMMmQnTtw",
        "outputId": "5ea29796-a0d1-459b-95c1-1d1ae11283a1"
      },
      "source": [
        "# 実行前にログ名を設定すること!!!\n",
        "log_name='PPO gamma'\n",
        "\n",
        "from stable_baselines3 import PPO, SAC\n",
        "# from sbx import TQC, DroQ, SAC, PPO, DQN, TD3, DDPG\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
        "from stable_baselines3.common.envs.multi_input_envs import SimpleMultiObsEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from statistics import mean\n",
        "\n",
        "\n",
        "# 環境の生成\n",
        "\n",
        "# 環境のラップ\n",
        "# monienv = Monitor(env, filename=None, allow_early_resets=True)\n",
        "monienv = VecMonitor(DummyVecEnv([lambda: PuzzEnv() for i in range(5)]), filename=None)\n",
        "\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "\n",
        "def conv3x3(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv2d(\n",
        "        in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "    )\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, num_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv3x3(num_channels, num_channels, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.conv2 = conv3x3(num_channels, num_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = nn.functional.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += x\n",
        "        out = nn.functional.relu(out)\n",
        "        return out\n",
        "\n",
        "class CustomCNN(BaseFeaturesExtractor):\n",
        "    \"\"\"\n",
        "    :param observation_space: (gym.Space)\n",
        "    :param features_dim: (int) Number of features extracted.\n",
        "        This corresponds to the number of unit for the last layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, observation_space: spaces.Box, features_dim: int = 256):\n",
        "        super().__init__(observation_space, features_dim)\n",
        "        # We assume CxHxW images (channels first)\n",
        "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
        "        n_input_channels = observation_space.shape[0]\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=1, padding='valid'),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding='valid'),\n",
        "            nn.ReLU(),\n",
        "            ResidualBlock(16),\n",
        "            ResidualBlock(16),\n",
        "            # ResidualBlock(16),\n",
        "            # ResidualBlock(16),\n",
        "            # ResidualBlock(16),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        # Compute shape by doing one forward pass\n",
        "        with th.no_grad():\n",
        "            n_flatten = self.cnn(\n",
        "                th.as_tensor(observation_space.sample()[None]).float()\n",
        "            ).shape[1]\n",
        "\n",
        "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
        "\n",
        "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
        "        return self.linear(self.cnn(observations))\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class=CustomCNN,\n",
        "    features_extractor_kwargs=dict(features_dim=32),\n",
        "    # share_features_extractor=False\n",
        ")\n",
        "\n",
        "# エージェントの訓練\n",
        "model = PPO('CnnPolicy', monienv, verbose=1, policy_kwargs=policy_kwargs, tensorboard_log=\"./puzzdra_tensorboard/\")\n",
        "# model = PPO('CnnPolicy', monienv, verbose=1, tensorboard_log=\"./puzzdra_tensorboard/\")\n",
        "print(model.policy)\n",
        "\n",
        "class TensorboardCallback(BaseCallback):\n",
        "  \"\"\"\n",
        "  Custom callback for plotting additional values in tensorboard.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, verbose=0):\n",
        "    super(TensorboardCallback, self).__init__(verbose)\n",
        "    self.check_freq = 50_000//5\n",
        "\n",
        "  def _on_step(self) -> bool:\n",
        "    if self.n_calls % self.check_freq == 0:\n",
        "\n",
        "      env = PuzzEnv()\n",
        "      rew_array = []\n",
        "\n",
        "      for test in range(100):\n",
        "        obs, _info = env.reset()\n",
        "        rew_current = 0\n",
        "        n_steps = 100\n",
        "        for step in range(n_steps):\n",
        "          action, _ = model.predict(obs, deterministic=True)\n",
        "          obs, reward, done, _, info = env.step(action)\n",
        "          rew_current += reward\n",
        "          if done:\n",
        "            rew_array.append(rew_current)\n",
        "            break\n",
        "\n",
        "      self.logger.record('combo', mean(rew_array) if len(rew_array) > 0 else 0)\n",
        "    return True\n",
        "\n",
        "model = model.learn(1_000_000, tb_log_name=log_name, callback=TensorboardCallback()) # 1_500_000 = 1 hour"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "ActorCriticCnnPolicy(\n",
            "  (features_extractor): CustomCNN(\n",
            "    (cnn): Sequential(\n",
            "      (0): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (3): ReLU()\n",
            "      (4): ResidualBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): ResidualBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (linear): Sequential(\n",
            "      (0): Linear(in_features=192, out_features=32, bias=True)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (pi_features_extractor): CustomCNN(\n",
            "    (cnn): Sequential(\n",
            "      (0): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (3): ReLU()\n",
            "      (4): ResidualBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): ResidualBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (linear): Sequential(\n",
            "      (0): Linear(in_features=192, out_features=32, bias=True)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (vf_features_extractor): CustomCNN(\n",
            "    (cnn): Sequential(\n",
            "      (0): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (3): ReLU()\n",
            "      (4): ResidualBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): ResidualBlock(\n",
            "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (linear): Sequential(\n",
            "      (0): Linear(in_features=192, out_features=32, bias=True)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (mlp_extractor): MlpExtractor(\n",
            "    (policy_net): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (3): Tanh()\n",
            "    )\n",
            "    (value_net): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (3): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (action_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "Logging to ./puzzdra_tensorboard/PPO gamma_11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 30       |\n",
            "|    ep_rew_mean     | 1.39     |\n",
            "| time/              |          |\n",
            "|    fps             | 1898     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 10240    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.67        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1034        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008247961 |\n",
            "|    clip_fraction        | 0.0256      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | -0.00119    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.561       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00209    |\n",
            "|    value_loss           | 1.03        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30           |\n",
            "|    ep_rew_mean          | 1.73         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 887          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 34           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071973605 |\n",
            "|    clip_fraction        | 0.0613       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 0.0129       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.221        |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00535     |\n",
            "|    value_loss           | 0.861        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 30         |\n",
            "|    ep_rew_mean          | 1.65       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 835        |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 49         |\n",
            "|    total_timesteps      | 40960      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00897061 |\n",
            "|    clip_fraction        | 0.0887     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.38      |\n",
            "|    explained_variance   | -0.00121   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.299      |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.00654   |\n",
            "|    value_loss           | 0.825      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.14        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 2.02        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 761         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 67          |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009680124 |\n",
            "|    clip_fraction        | 0.113       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | -0.065      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.29        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00513    |\n",
            "|    value_loss           | 0.747       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.64        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 757         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 81          |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010588241 |\n",
            "|    clip_fraction        | 0.128       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | -0.0312     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.233       |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00547    |\n",
            "|    value_loss           | 0.737       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.73        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 755         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 94          |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011617986 |\n",
            "|    clip_fraction        | 0.144       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | -0.0565     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.174       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00709    |\n",
            "|    value_loss           | 0.666       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.72        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 751         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 108         |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013567323 |\n",
            "|    clip_fraction        | 0.166       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | -0.0191     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.426       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00685    |\n",
            "|    value_loss           | 0.721       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.72        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 746         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 123         |\n",
            "|    total_timesteps      | 92160       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013273927 |\n",
            "|    clip_fraction        | 0.164       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | -0.0862     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.222       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00723    |\n",
            "|    value_loss           | 0.64        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.03        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.72        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 727         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 140         |\n",
            "|    total_timesteps      | 102400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013276776 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.0456     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.184       |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00491    |\n",
            "|    value_loss           | 0.668       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.73        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 729         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 154         |\n",
            "|    total_timesteps      | 112640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013262028 |\n",
            "|    clip_fraction        | 0.17        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.092      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.241       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00472    |\n",
            "|    value_loss           | 0.661       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.56        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 731         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 168         |\n",
            "|    total_timesteps      | 122880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013316555 |\n",
            "|    clip_fraction        | 0.172       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | -0.0974     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.112       |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00716    |\n",
            "|    value_loss           | 0.633       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 30         |\n",
            "|    ep_rew_mean          | 1.74       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 731        |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 181        |\n",
            "|    total_timesteps      | 133120     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01345365 |\n",
            "|    clip_fraction        | 0.175      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.35      |\n",
            "|    explained_variance   | -0.07      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.14       |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.00516   |\n",
            "|    value_loss           | 0.639      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.55        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 730         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 196         |\n",
            "|    total_timesteps      | 143360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013443614 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.00726    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.181       |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00667    |\n",
            "|    value_loss           | 0.657       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 0.85        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.71        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 717         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 214         |\n",
            "|    total_timesteps      | 153600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013177076 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.134      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.157       |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00645    |\n",
            "|    value_loss           | 0.589       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.66        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 716         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 228         |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012505238 |\n",
            "|    clip_fraction        | 0.153       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.0414     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.147       |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00394    |\n",
            "|    value_loss           | 0.648       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.4         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 717         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 242         |\n",
            "|    total_timesteps      | 174080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013332275 |\n",
            "|    clip_fraction        | 0.171       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.114      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.22        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00809    |\n",
            "|    value_loss           | 0.59        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.71        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 717         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 256         |\n",
            "|    total_timesteps      | 184320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013930979 |\n",
            "|    clip_fraction        | 0.172       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.0227      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.184       |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00623    |\n",
            "|    value_loss           | 0.58        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 30        |\n",
            "|    ep_rew_mean          | 1.77      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 716       |\n",
            "|    iterations           | 19        |\n",
            "|    time_elapsed         | 271       |\n",
            "|    total_timesteps      | 194560    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0138569 |\n",
            "|    clip_fraction        | 0.186     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.35     |\n",
            "|    explained_variance   | -0.139    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.124     |\n",
            "|    n_updates            | 180       |\n",
            "|    policy_gradient_loss | -0.00765  |\n",
            "|    value_loss           | 0.56      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 0.72        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.85        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 709         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 288         |\n",
            "|    total_timesteps      | 204800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014151934 |\n",
            "|    clip_fraction        | 0.184       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.0883     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.107       |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.00577    |\n",
            "|    value_loss           | 0.591       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.59        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 711         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 302         |\n",
            "|    total_timesteps      | 215040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015338747 |\n",
            "|    clip_fraction        | 0.2         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.101      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.414       |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00613    |\n",
            "|    value_loss           | 0.635       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.7         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 712         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 316         |\n",
            "|    total_timesteps      | 225280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015295781 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.0803     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.241       |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0067     |\n",
            "|    value_loss           | 0.603       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.7         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 713         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 330         |\n",
            "|    total_timesteps      | 235520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015655447 |\n",
            "|    clip_fraction        | 0.204       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.116      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.158       |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.00779    |\n",
            "|    value_loss           | 0.61        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.77        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 712         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 345         |\n",
            "|    total_timesteps      | 245760      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016689694 |\n",
            "|    clip_fraction        | 0.208       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.164      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.26        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00546    |\n",
            "|    value_loss           | 0.624       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.03        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.54        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 707         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 361         |\n",
            "|    total_timesteps      | 256000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014290976 |\n",
            "|    clip_fraction        | 0.176       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.0773     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.227       |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.00559    |\n",
            "|    value_loss           | 0.644       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.52        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 709         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 375         |\n",
            "|    total_timesteps      | 266240      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014777152 |\n",
            "|    clip_fraction        | 0.187       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.151      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.294       |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.00387    |\n",
            "|    value_loss           | 0.643       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30           |\n",
            "|    ep_rew_mean          | 1.48         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 709          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 389          |\n",
            "|    total_timesteps      | 276480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0144997295 |\n",
            "|    clip_fraction        | 0.179        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | -0.0659      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.279        |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.00318     |\n",
            "|    value_loss           | 0.643        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.7         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 710         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 403         |\n",
            "|    total_timesteps      | 286720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014491585 |\n",
            "|    clip_fraction        | 0.191       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | -0.12       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.198       |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.00319    |\n",
            "|    value_loss           | 0.601       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.44        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 712         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 416         |\n",
            "|    total_timesteps      | 296960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013976164 |\n",
            "|    clip_fraction        | 0.174       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | -0.0984     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.164       |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.00414    |\n",
            "|    value_loss           | 0.666       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| combo                   | 0.86       |\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 30         |\n",
            "|    ep_rew_mean          | 1.58       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 707        |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 434        |\n",
            "|    total_timesteps      | 307200     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01643838 |\n",
            "|    clip_fraction        | 0.201      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.33      |\n",
            "|    explained_variance   | -0.144     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.173      |\n",
            "|    n_updates            | 290        |\n",
            "|    policy_gradient_loss | -0.00399   |\n",
            "|    value_loss           | 0.589      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.41        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 707         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 448         |\n",
            "|    total_timesteps      | 317440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015885571 |\n",
            "|    clip_fraction        | 0.21        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.32       |\n",
            "|    explained_variance   | -0.0464     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.24        |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.00238    |\n",
            "|    value_loss           | 0.531       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.73        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 707         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 462         |\n",
            "|    total_timesteps      | 327680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016747193 |\n",
            "|    clip_fraction        | 0.224       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | -0.106      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.186       |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.00293    |\n",
            "|    value_loss           | 0.678       |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-872288f81d07>\u001b[0m in \u001b[0;36m<cell line: 124>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1_000_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1_500_000 = 1 hour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 315\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mterminal_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             rollout_buffer.add(\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/buffers.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, obs, action, reward, episode_start, value, log_prob)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_starts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 追加学習\n",
        "model = model.learn(200_000, tb_log_name=log_name, callback=TensorboardCallback()) # 1_500_000 = 1 hour"
      ],
      "metadata": {
        "id": "Y0NshiyFSm7t",
        "outputId": "4bbecfee-032d-4591-e19f-fbfbfe2833c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to ./puzzdra_tensorboard/PPO gamma_10\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 30       |\n",
            "|    ep_rew_mean     | 1.61     |\n",
            "| time/              |          |\n",
            "|    fps             | 2918     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 10240    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.7         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1623        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 12          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007823391 |\n",
            "|    clip_fraction        | 0.0598      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.25       |\n",
            "|    explained_variance   | 0.116       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.506       |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.00213    |\n",
            "|    value_loss           | 1.13        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.74        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1420        |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007743161 |\n",
            "|    clip_fraction        | 0.0542      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.25       |\n",
            "|    explained_variance   | 0.104       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.366       |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.00179    |\n",
            "|    value_loss           | 1.11        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.68        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1310        |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008227428 |\n",
            "|    clip_fraction        | 0.0408      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.25       |\n",
            "|    explained_variance   | 0.109       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.404       |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.000778   |\n",
            "|    value_loss           | 1.1         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| combo                   | 1.16         |\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30           |\n",
            "|    ep_rew_mean          | 1.81         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1212         |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041420343 |\n",
            "|    clip_fraction        | 0.0306       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.26        |\n",
            "|    explained_variance   | 0.103        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.548        |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.000328    |\n",
            "|    value_loss           | 1.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30           |\n",
            "|    ep_rew_mean          | 2.02         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1201         |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 51           |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058031473 |\n",
            "|    clip_fraction        | 0.0364       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.26        |\n",
            "|    explained_variance   | 0.133        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.379        |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.000206    |\n",
            "|    value_loss           | 1.1          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 2.03        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1187        |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 60          |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004523701 |\n",
            "|    clip_fraction        | 0.0281      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | 0.123       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.526       |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | 0.00026     |\n",
            "|    value_loss           | 1.06        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.94        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1177        |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 69          |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004586084 |\n",
            "|    clip_fraction        | 0.0312      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | 0.138       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.578       |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.000583   |\n",
            "|    value_loss           | 1.05        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30           |\n",
            "|    ep_rew_mean          | 1.95         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1167         |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 78           |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051793694 |\n",
            "|    clip_fraction        | 0.0412       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.2         |\n",
            "|    explained_variance   | 0.136        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.288        |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.000843    |\n",
            "|    value_loss           | 1.09         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.59        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 2.11        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1131        |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 90          |\n",
            "|    total_timesteps      | 102400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005594953 |\n",
            "|    clip_fraction        | 0.0341      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.19       |\n",
            "|    explained_variance   | 0.138       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.498       |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.000585   |\n",
            "|    value_loss           | 0.988       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 2.05        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1127        |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 99          |\n",
            "|    total_timesteps      | 112640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006664532 |\n",
            "|    clip_fraction        | 0.0502      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.16       |\n",
            "|    explained_variance   | 0.131       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.7         |\n",
            "|    n_updates            | 500         |\n",
            "|    policy_gradient_loss | -0.00063    |\n",
            "|    value_loss           | 1.02        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.76        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1126        |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 109         |\n",
            "|    total_timesteps      | 122880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008677308 |\n",
            "|    clip_fraction        | 0.0584      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.16       |\n",
            "|    explained_variance   | 0.112       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.517       |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.00101    |\n",
            "|    value_loss           | 1.2         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30           |\n",
            "|    ep_rew_mean          | 1.67         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1126         |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 118          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053032213 |\n",
            "|    clip_fraction        | 0.0358       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.15        |\n",
            "|    explained_variance   | 0.116        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.526        |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | -4.03e-06    |\n",
            "|    value_loss           | 1.08         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 2.06        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1124        |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 127         |\n",
            "|    total_timesteps      | 143360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005499872 |\n",
            "|    clip_fraction        | 0.0634      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.17       |\n",
            "|    explained_variance   | 0.108       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.445       |\n",
            "|    n_updates            | 530         |\n",
            "|    policy_gradient_loss | -0.00114    |\n",
            "|    value_loss           | 1.02        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| combo                   | 0.94         |\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30           |\n",
            "|    ep_rew_mean          | 1.73         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1100         |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 139          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0096144425 |\n",
            "|    clip_fraction        | 0.0592       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.114        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.472        |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00165     |\n",
            "|    value_loss           | 1.17         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30           |\n",
            "|    ep_rew_mean          | 1.97         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1096         |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 149          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050902786 |\n",
            "|    clip_fraction        | 0.0397       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.13        |\n",
            "|    explained_variance   | 0.136        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.499        |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.000859    |\n",
            "|    value_loss           | 1.14         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.9         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1096        |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 158         |\n",
            "|    total_timesteps      | 174080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008143574 |\n",
            "|    clip_fraction        | 0.0609      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.117       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.354       |\n",
            "|    n_updates            | 560         |\n",
            "|    policy_gradient_loss | -0.000803   |\n",
            "|    value_loss           | 1.12        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30           |\n",
            "|    ep_rew_mean          | 1.93         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1097         |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 167          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056852526 |\n",
            "|    clip_fraction        | 0.0471       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.103        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.527        |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -6.13e-05    |\n",
            "|    value_loss           | 1.2          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30           |\n",
            "|    ep_rew_mean          | 1.71         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1098         |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 177          |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037993495 |\n",
            "|    clip_fraction        | 0.0401       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.13        |\n",
            "|    explained_variance   | 0.117        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.569        |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | 0.000507     |\n",
            "|    value_loss           | 1.07         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | 1.27        |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | 1.75        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1087        |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 188         |\n",
            "|    total_timesteps      | 204800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008205795 |\n",
            "|    clip_fraction        | 0.0659      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.12       |\n",
            "|    explained_variance   | 0.108       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.08        |\n",
            "|    n_updates            | 590         |\n",
            "|    policy_gradient_loss | -0.00103    |\n",
            "|    value_loss           | 1.11        |\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "env = PuzzEnv()\n",
        "\n",
        "obs, _info = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "n_steps = 30\n",
        "for step in range(n_steps):\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  action, _states = model.predict(obs)\n",
        "  obs, reward, done, _, info = env.step(action)\n",
        "  # print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render()\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "metadata": {
        "id": "VNaQQfU-Zi_z",
        "outputId": "ecc6f4f8-14ec-4e60-ed22-6f38d486d575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Box(0, 255, (5, 10, 6), uint8)\n",
            "Discrete(4)\n",
            "0\n",
            "Step 1\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\n",
            "Step 2\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\n",
            "Step 3\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 4\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 5\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 6\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 7\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 8\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 9\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 10\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 11\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 12\n",
            "\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 13\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 14\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 15\n",
            "\u001b[32m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 16\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 17\n",
            "\u001b[32m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 18\n",
            "\u001b[32m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 19\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 20\n",
            "\u001b[32m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 21\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 22\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 23\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 24\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 25\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 26\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 27\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 28\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 29\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Step 30\n",
            "\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "Goal reached! reward= 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a245ytFhwGg3"
      },
      "source": [
        "model.save('puzzdra_nn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q85IqDNWZvS-"
      },
      "source": [
        "print(model.policy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6_GY038P2tIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}