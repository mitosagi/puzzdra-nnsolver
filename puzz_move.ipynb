{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "puzz.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMPcot0FWW+lm75l0AjlQsd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitosagi/puzzdra-nnsolver/blob/master/puzz_move.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrk7ju8ZSpq1"
      },
      "source": [
        "## 初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MinijqIGMKzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f11704-a7aa-4c4e-f174-84f5603d4dfe"
      },
      "source": [
        "!git clone --recursive https://github.com/mitosagi/puzzdra-nnsolver\n",
        "%cd /content/puzzdra-nnsolver\n",
        "!pip install --log=pip_log -e .\n",
        "!pip install git+https://github.com/DLR-RM/stable-baselines3\n",
        "!pip install sbx-rl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'puzzdra-nnsolver'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 269 (delta 14), reused 0 (delta 0), pack-reused 245\u001b[K\n",
            "Receiving objects: 100% (269/269), 8.26 MiB | 13.18 MiB/s, done.\n",
            "Resolving deltas: 100% (156/156), done.\n",
            "Submodule 'extern/pybind11' (https://github.com/pybind/pybind11) registered for path 'extern/pybind11'\n",
            "Cloning into '/content/puzzdra-nnsolver/extern/pybind11'...\n",
            "remote: Enumerating objects: 27212, done.        \n",
            "remote: Counting objects: 100% (7883/7883), done.        \n",
            "remote: Compressing objects: 100% (589/589), done.        \n",
            "remote: Total 27212 (delta 7521), reused 7333 (delta 7282), pack-reused 19329        \n",
            "Receiving objects: 100% (27212/27212), 10.01 MiB | 23.29 MiB/s, done.\n",
            "Resolving deltas: 100% (19415/19415), done.\n",
            "Submodule path 'extern/pybind11': checked out '8de7772cc72daca8e947b79b83fea46214931604'\n",
            "/content/puzzdra-nnsolver\n",
            "Obtaining file:///content/puzzdra-nnsolver\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: Puzzpy\n",
            "  Running setup.py develop for Puzzpy\n",
            "Successfully installed Puzzpy-1.0\n",
            "Collecting git+https://github.com/DLR-RM/stable-baselines3\n",
            "  Cloning https://github.com/DLR-RM/stable-baselines3 to /tmp/pip-req-build-g7afzky6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/stable-baselines3 /tmp/pip-req-build-g7afzky6\n",
            "  Resolved https://github.com/DLR-RM/stable-baselines3 to commit 69afefc91d408d352b4224ae5244ad2c32bb7634\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gymnasium<0.30,>=0.28.1 (from stable-baselines3==2.2.0a9)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (2.0.1+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.0a9) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.0a9) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.2.0a9)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3==2.2.0a9) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->stable-baselines3==2.2.0a9) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->stable-baselines3==2.2.0a9) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.0a9) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==2.2.0a9) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.2.0a9) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3==2.2.0a9) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3==2.2.0a9) (1.3.0)\n",
            "Building wheels for collected packages: stable-baselines3\n",
            "  Building wheel for stable-baselines3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stable-baselines3: filename=stable_baselines3-2.2.0a9-py3-none-any.whl size=180895 sha256=5798331d8da8a65ed88eee6a6781da2990028aadad110f57ce878b70dad375f8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-82wk94n7/wheels/3b/24/65/bc2794face336930a72bdbe36faf5aad6e2352b3d1dec310ca\n",
            "Successfully built stable-baselines3\n",
            "Installing collected packages: farama-notifications, gymnasium, stable-baselines3\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 stable-baselines3-2.2.0a9\n",
            "Collecting sbx-rl\n",
            "  Downloading sbx_rl-0.8.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: stable-baselines3>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (2.2.0a9)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (0.4.14)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (0.4.14+cuda11.cudnn86)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (0.7.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (0.1.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (4.66.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (13.5.2)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (from sbx-rl) (0.20.1)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (2.0.1+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.1.0->sbx-rl) (3.7.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->sbx-rl) (1.0.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->sbx-rl) (0.3.5)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->sbx-rl) (0.1.41)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from flax->sbx-rl) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax->sbx-rl) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->sbx-rl) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->sbx-rl) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax->sbx-rl) (1.11.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->sbx-rl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->sbx-rl) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->sbx-rl) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->sbx-rl) (0.1.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->sbx-rl) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->sbx-rl) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->sbx-rl) (0.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability->sbx-rl) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->sbx-rl) (0.12.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3>=2.1.0->sbx-rl) (0.0.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->sbx-rl) (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.1.0->sbx-rl) (2.8.2)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->sbx-rl) (1.4.1)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->sbx-rl) (1.5.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->sbx-rl) (3.20.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3>=2.1.0->sbx-rl) (2023.3.post1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->sbx-rl) (6.0.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->sbx-rl) (3.16.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3>=2.1.0->sbx-rl) (1.3.0)\n",
            "Installing collected packages: sbx-rl\n",
            "Successfully installed sbx-rl-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdUISRWiX4kM"
      },
      "source": [
        "## 実際の処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI2D4A-cXnQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed951701-24c7-4021-d9e3-7ebe102ecc98"
      },
      "source": [
        "import numpy as np\n",
        "import gymnasium\n",
        "from gymnasium import spaces\n",
        "from puzzpy import PuzzTable\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "import random\n",
        "\n",
        "drop_color = 3\n",
        "board_width = 6\n",
        "board_height = 5\n",
        "min_size = 6 # 36 if CNN, 6 if manual MLP or CNN\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "    BLACK = '\\033[30m'\n",
        "    RED = '\\033[31m'\n",
        "    GREEN = '\\033[32m'\n",
        "    YELLOW = '\\033[33m'\n",
        "    BLUE = '\\033[34m'\n",
        "    MAGENTA = '\\033[35m'\n",
        "    CYAN = '\\033[36m'\n",
        "\n",
        "class PuzzEnv(gymnasium.Env):\n",
        "  \"\"\"\n",
        "  パズドラの環境\n",
        "  \"\"\"\n",
        "  # ColabのためGUIを実装できない\n",
        "  metadata = {'render.modes': ['console']}\n",
        "\n",
        "  def __init__(self):\n",
        "    super(PuzzEnv, self).__init__()\n",
        "\n",
        "    self.action_space = spaces.Discrete(4) # 指を離す動作を含めると5\n",
        "    self.observation_space = spaces.Box(low=0, high=255, shape=(1+1+1+drop_color, max(min_size, board_height), max(min_size, board_width)), dtype=np.uint8) # 1 for turn num, +1 for finger position\n",
        "    self.action = 255\n",
        "    self.prev_action = 255\n",
        "    self.prev_finger_array = None\n",
        "    self.rew = 0\n",
        "\n",
        "  def retobs(self, table):\n",
        "    turn_array = [np.full((board_height, board_width), table.get_turn(), np.uint8)]\n",
        "    action_array = [np.full((board_height, board_width), self.action, np.uint8)]\n",
        "    finger_array = np.array([np.array(table.get_XY_as_table()).astype(np.uint8) * (2 ** 5)]).astype(np.uint8)\n",
        "    # if self.prev_finger_array is not None:\n",
        "    #   finger_array = finger_array + self.prev_finger_array // 2\n",
        "    # self.prev_finger_array = finger_array\n",
        "    table_array = np.array(table.get_table()).astype(np.uint8)\n",
        "    u = np.arange(table_array.max()+1)\n",
        "    table_array = (u[:,np.newaxis,np.newaxis]==table_array).astype(np.uint8)[1:] # ドロップをone-hotにする https://stackoverflow.com/questions/67249470/convert-a-2d-numpy-array-into-a-hot-encoded-3d-numpy-array-with-same-values-in\n",
        "    tmp_array = np.concatenate([turn_array, action_array, finger_array, table_array])\n",
        "    now_rew = table.eval_otoshi()\n",
        "    step_rew = now_rew - self.rew\n",
        "    self.rew = now_rew\n",
        "    return np.pad(tmp_array, [(0,0), (0, max(min_size - board_height, 0)), (0, max(min_size - board_width, 0))], mode='constant', constant_values=0), step_rew\n",
        "\n",
        "  def reset(self, seed = None, test_min = 30):\n",
        "    # test_min = random.randrange(10,30,1)\n",
        "    super().reset(seed=seed)\n",
        "    \"\"\"\n",
        "    【重要】観測はnumpy配列でなければならない\n",
        "    :return: (np.array)\n",
        "    \"\"\"\n",
        "    while True:\n",
        "      self.table = PuzzTable(\"\".join([str(random.randrange(drop_color)) for i in range(board_width*board_height)]), random.randrange(board_width), random.randrange(board_height), test_min) # n色陣　操作時間m秒\n",
        "      if self.table.eval_otoshi() == 0:\n",
        "        break\n",
        "    # self.table = PuzzTable(\"\".join([str(random.randrange(drop_color)) for i in range(board_width*board_height)]), random.randrange(board_width), random.randrange(board_height), test_min) # n色陣　操作時間m秒\n",
        "\n",
        "    return self.retobs(self.table)[0], {}\n",
        "\n",
        "  def step(self, action):\n",
        "    self.action = action\n",
        "    if action == 4: # 指を離す動作\n",
        "      return *(self.retobs(self.table)), True, False, {}\n",
        "\n",
        "    next_table = self.table.next_tables()[action]\n",
        "\n",
        "    if abs(action - self.prev_action) == 2: # 元の方向に戻る 0と2 1と3が該当\n",
        "      # next_table = self.table\n",
        "      return self.retobs(self.table)[0], -1, True, False, {}\n",
        "    self.prev_action = action\n",
        "\n",
        "    if next_table.get_table()[0][0] == 127: # 壁に移動\n",
        "      # next_table = self.table\n",
        "      return self.retobs(self.table)[0], -1, True, False, {}\n",
        "\n",
        "    self.table = next_table\n",
        "\n",
        "    if self.table.get_turn() <= 0: # 時間切れ\n",
        "      return *(self.retobs(self.table)), True, False, {}\n",
        "\n",
        "    return *(self.retobs(self.table)), False, False, {}\n",
        "\n",
        "  def render(self, mode='console', close=False):\n",
        "    if mode != 'console':\n",
        "      raise NotImplementedError()\n",
        "\n",
        "    tcolor = [bcolors.RED, bcolors.BLUE, bcolors.GREEN, bcolors.MAGENTA, bcolors.YELLOW, bcolors.BLACK]\n",
        "    start = self.table.get_XY_as_table()\n",
        "    table = self.table.get_table()\n",
        "    for i in range(board_height):\n",
        "      for j in range(board_width):\n",
        "        if start[i][j] == 1:\n",
        "          print(tcolor[table[i][j]-1]  +  bcolors.UNDERLINE + \"●\" + bcolors.ENDC, end='')\n",
        "        else:\n",
        "          print(tcolor[table[i][j]-1]  + \"●\" + bcolors.ENDC, end='')\n",
        "\n",
        "      print('')\n",
        "\n",
        "check_env(PuzzEnv())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:51: UserWarning: The minimal resolution for an image is 36x36 for the default `CnnPolicy`. You might need to use a custom features extractor cf. https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Z9SliEfKci",
        "outputId": "6216d2fc-27dc-4fd1-f825-c89e21337ab2"
      },
      "source": [
        "env = PuzzEnv()\n",
        "\n",
        "obs = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  obs, reward, done, _, info = env.step(env.action_space.sample())\n",
        "  print('obs=', obs.shape, 'reward=', reward, 'done=', done)\n",
        "  with np.printoptions(threshold=np.inf):\n",
        "    print(obs)\n",
        "  env.render()\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "Box(0, 255, (6, 6, 6), uint8)\n",
            "Discrete(4)\n",
            "1\n",
            "Step 1\n",
            "obs= (6, 6, 6) reward= 1 done= False\n",
            "[[[29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [29 29 29 29 29 29]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  1  1  1  1  1]\n",
            "  [ 1  1  1  1  1  1]\n",
            "  [ 1  1  1  1  1  1]\n",
            "  [ 1  1  1  1  1  1]\n",
            "  [ 1  1  1  1  1  1]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0 32  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  1  0  0  1  0]\n",
            "  [ 0  1  1  0  0  0]\n",
            "  [ 1  0  0  0  0  1]\n",
            "  [ 0  0  1  1  0  1]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  0  1  0  1]\n",
            "  [ 1  0  0  0  0  1]\n",
            "  [ 0  0  1  1  1  0]\n",
            "  [ 1  0  0  0  1  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]]]\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "Step 2\n",
            "obs= (6, 6, 6) reward= -1 done= False\n",
            "[[[28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]\n",
            "  [ 2  2  2  2  2  2]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0 32  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  1  0  0  1  0]\n",
            "  [ 0  1  1  0  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  0  1  0  1]\n",
            "  [ 1  0  0  0  0  1]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]]]\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "Step 3\n",
            "obs= (6, 6, 6) reward= -1 done= True\n",
            "[[[28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [28 28 28 28 28 28]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0 32  0  0  0]\n",
            "  [ 0  0  0  0  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  1  0  0  1  0]\n",
            "  [ 0  1  1  0  0  0]\n",
            "  [ 1  0  1  0  0  1]\n",
            "  [ 0  0  0  1  0  1]\n",
            "  [ 0  1  0  1  0  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 0  0  1  0  0  0]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 0  1  0  0  0  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  0  0  0  0]]\n",
            "\n",
            " [[ 1  0  0  1  0  1]\n",
            "  [ 1  0  0  0  0  1]\n",
            "  [ 0  0  0  1  1  0]\n",
            "  [ 1  0  1  0  1  0]\n",
            "  [ 0  0  0  0  0  1]\n",
            "  [ 0  0  0  0  0  0]]]\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "Goal reached! reward= -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893
        },
        "id": "Ubsd-1EVqANb",
        "outputId": "443c6105-faa5-43f5-9c50-5d0537432c98"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "# %tensorboard --logdir puzzdra_tensorboard\n",
        "%tensorboard --logdir puzzdra_tensorboard --host=127.0.0.1 --port=6006 --load_fast=false\n",
        "from google.colab import output\n",
        "output.serve_kernel_port_as_window(6006, path=\"\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/output/_util.py:114: DeprecationWarning: This has been deprecated due to changes in browser security. Use `serve_kernel_port_as_iframe` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(6006, \"\", \"https://localhost:6006\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_qAMMmQnTtw",
        "outputId": "8eba14a4-cd5f-46d9-f09d-b165c213a505"
      },
      "source": [
        "# 実行前にログ名を設定すること!!!\n",
        "log_name='PPO gamma'\n",
        "\n",
        "from stable_baselines3 import PPO, SAC\n",
        "# from sbx import TQC, DroQ, SAC, PPO, DQN, TD3, DDPG\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
        "from stable_baselines3.common.envs.multi_input_envs import SimpleMultiObsEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from statistics import mean\n",
        "\n",
        "\n",
        "# 環境の生成\n",
        "env = PuzzEnv()\n",
        "\n",
        "# 環境のラップ\n",
        "# monienv = Monitor(env, filename=None, allow_early_resets=True)\n",
        "monienv = VecMonitor(DummyVecEnv([lambda: PuzzEnv() for i in range(6)]), filename=None)\n",
        "\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "\n",
        "\n",
        "class CustomCNN(BaseFeaturesExtractor):\n",
        "    \"\"\"\n",
        "    :param observation_space: (gym.Space)\n",
        "    :param features_dim: (int) Number of features extracted.\n",
        "        This corresponds to the number of unit for the last layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, observation_space: spaces.Box, features_dim: int = 256):\n",
        "        super().__init__(observation_space, features_dim)\n",
        "        # We assume CxHxW images (channels first)\n",
        "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
        "        n_input_channels = observation_space.shape[0]\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=1, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding='valid'),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 8, kernel_size=3, stride=1, padding='valid'),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        # Compute shape by doing one forward pass\n",
        "        with th.no_grad():\n",
        "            n_flatten = self.cnn(\n",
        "                th.as_tensor(observation_space.sample()[None]).float()\n",
        "            ).shape[1]\n",
        "\n",
        "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
        "\n",
        "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
        "        return self.linear(self.cnn(observations))\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class=CustomCNN,\n",
        "    features_extractor_kwargs=dict(features_dim=32),\n",
        "    # share_features_extractor=False\n",
        ")\n",
        "\n",
        "# エージェントの訓練\n",
        "model = PPO('MlpPolicy', monienv, verbose=1, policy_kwargs=policy_kwargs, tensorboard_log=\"./puzzdra_tensorboard/\")\n",
        "# model = PPO('MlpPolicy', monienv, verbose=1, policy_kwargs=dict(net_arch=[64,64]), tensorboard_log=\"./puzzdra_tensorboard/\")\n",
        "print(model.policy)\n",
        "\n",
        "class TensorboardCallback(BaseCallback):\n",
        "  \"\"\"\n",
        "  Custom callback for plotting additional values in tensorboard.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, verbose=0):\n",
        "    super(TensorboardCallback, self).__init__(verbose)\n",
        "    self.check_freq = 100_000//4\n",
        "\n",
        "  def _on_step(self) -> bool:\n",
        "    if self.n_calls % self.check_freq == 0:\n",
        "\n",
        "      env = PuzzEnv()\n",
        "      rew_array = []\n",
        "\n",
        "      for test in range(100):\n",
        "        obs, _info = env.reset()\n",
        "        n_steps = 100\n",
        "        for step in range(n_steps):\n",
        "          action, _ = model.predict(obs, deterministic=True)\n",
        "          obs, reward, done, _, info = env.step(action)\n",
        "          if done:\n",
        "            rew_array.append(reward)\n",
        "            break\n",
        "\n",
        "      self.logger.record('combo', mean(rew_array) if len(rew_array) > 0 else 0)\n",
        "    return True\n",
        "\n",
        "model = model.learn(500_000, tb_log_name=log_name, callback=TensorboardCallback()) # 1_500_000 = 1 hour"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "ActorCriticPolicy(\n",
            "  (features_extractor): CustomCNN(\n",
            "    (cnn): Sequential(\n",
            "      (0): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (3): ReLU()\n",
            "      (4): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (5): ReLU()\n",
            "      (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (linear): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (pi_features_extractor): CustomCNN(\n",
            "    (cnn): Sequential(\n",
            "      (0): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (3): ReLU()\n",
            "      (4): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (5): ReLU()\n",
            "      (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (linear): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (vf_features_extractor): CustomCNN(\n",
            "    (cnn): Sequential(\n",
            "      (0): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (3): ReLU()\n",
            "      (4): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
            "      (5): ReLU()\n",
            "      (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (linear): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (mlp_extractor): MlpExtractor(\n",
            "    (policy_net): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (3): Tanh()\n",
            "    )\n",
            "    (value_net): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "      (3): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (action_net): Linear(in_features=64, out_features=4, bias=True)\n",
            "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "Logging to ./puzzdra_tensorboard/PPO gamma_5\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.91     |\n",
            "|    ep_rew_mean     | -0.61    |\n",
            "| time/              |          |\n",
            "|    fps             | 1340     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 9        |\n",
            "|    total_timesteps | 12288    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.75        |\n",
            "|    ep_rew_mean          | -0.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 964         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 25          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010483774 |\n",
            "|    clip_fraction        | 0.0507      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | -0.00279    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.403       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00513    |\n",
            "|    value_loss           | 0.683       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.19        |\n",
            "|    ep_rew_mean          | -0.34       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 885         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012480207 |\n",
            "|    clip_fraction        | 0.176       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.0228      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.299       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.012      |\n",
            "|    value_loss           | 0.808       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.65        |\n",
            "|    ep_rew_mean          | -0.49       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 866         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 56          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015048926 |\n",
            "|    clip_fraction        | 0.218       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.31       |\n",
            "|    explained_variance   | 0.0245      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.302       |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0145     |\n",
            "|    value_loss           | 0.894       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 4.22       |\n",
            "|    ep_rew_mean          | -0.31      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 863        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 71         |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01580962 |\n",
            "|    clip_fraction        | 0.242      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.27      |\n",
            "|    explained_variance   | 0.0209     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.351      |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.0152    |\n",
            "|    value_loss           | 0.938      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.26        |\n",
            "|    ep_rew_mean          | -0.33       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 864         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 85          |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017942498 |\n",
            "|    clip_fraction        | 0.254       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.0292      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.599       |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0157     |\n",
            "|    value_loss           | 1.05        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.21        |\n",
            "|    ep_rew_mean          | 0.01        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 867         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 99          |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019184021 |\n",
            "|    clip_fraction        | 0.244       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.13       |\n",
            "|    explained_variance   | 0.0451      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.308       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0122     |\n",
            "|    value_loss           | 1.07        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.96        |\n",
            "|    ep_rew_mean          | -0.06       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 867         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 113         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021290185 |\n",
            "|    clip_fraction        | 0.249       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.08       |\n",
            "|    explained_variance   | 0.0548      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.445       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0101     |\n",
            "|    value_loss           | 1.14        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.62        |\n",
            "|    ep_rew_mean          | -0.16       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 868         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 127         |\n",
            "|    total_timesteps      | 110592      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023295717 |\n",
            "|    clip_fraction        | 0.245       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.0894      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.517       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0071     |\n",
            "|    value_loss           | 1.04        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6.26        |\n",
            "|    ep_rew_mean          | -0.02       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 876         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 140         |\n",
            "|    total_timesteps      | 122880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023855532 |\n",
            "|    clip_fraction        | 0.24        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.966      |\n",
            "|    explained_variance   | 0.0972      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.353       |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00555    |\n",
            "|    value_loss           | 1.17        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 7.13       |\n",
            "|    ep_rew_mean          | 0.25       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 879        |\n",
            "|    iterations           | 11         |\n",
            "|    time_elapsed         | 153        |\n",
            "|    total_timesteps      | 135168     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02209025 |\n",
            "|    clip_fraction        | 0.215      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.899     |\n",
            "|    explained_variance   | 0.104      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.731      |\n",
            "|    n_updates            | 100        |\n",
            "|    policy_gradient_loss | -0.0053    |\n",
            "|    value_loss           | 1.15       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 7.09        |\n",
            "|    ep_rew_mean          | 0.21        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 882         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 167         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021188326 |\n",
            "|    clip_fraction        | 0.2         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.849      |\n",
            "|    explained_variance   | 0.123       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.651       |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.000354   |\n",
            "|    value_loss           | 1.23        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | -1          |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 7.38        |\n",
            "|    ep_rew_mean          | 0.27        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 881         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 181         |\n",
            "|    total_timesteps      | 159744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020338697 |\n",
            "|    clip_fraction        | 0.196       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.813      |\n",
            "|    explained_variance   | 0.135       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.01        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | 0.000228    |\n",
            "|    value_loss           | 1.26        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.8         |\n",
            "|    ep_rew_mean          | 0.38        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 886         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 194         |\n",
            "|    total_timesteps      | 172032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024607545 |\n",
            "|    clip_fraction        | 0.201       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.767      |\n",
            "|    explained_variance   | 0.133       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.64        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00137    |\n",
            "|    value_loss           | 1.23        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.44        |\n",
            "|    ep_rew_mean          | 0.19        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 894         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 206         |\n",
            "|    total_timesteps      | 184320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024016032 |\n",
            "|    clip_fraction        | 0.205       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.755      |\n",
            "|    explained_variance   | 0.124       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.5         |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00012    |\n",
            "|    value_loss           | 1.33        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.9         |\n",
            "|    ep_rew_mean          | 0.19        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 902         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 217         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018937534 |\n",
            "|    clip_fraction        | 0.186       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.772      |\n",
            "|    explained_variance   | 0.123       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.626       |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | 0.00398     |\n",
            "|    value_loss           | 1.42        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 8.38       |\n",
            "|    ep_rew_mean          | 0.38       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 907        |\n",
            "|    iterations           | 17         |\n",
            "|    time_elapsed         | 230        |\n",
            "|    total_timesteps      | 208896     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02446956 |\n",
            "|    clip_fraction        | 0.205      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.705     |\n",
            "|    explained_variance   | 0.121      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.712      |\n",
            "|    n_updates            | 160        |\n",
            "|    policy_gradient_loss | 0.000835   |\n",
            "|    value_loss           | 1.3        |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 10.2        |\n",
            "|    ep_rew_mean          | 0.32        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 912         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 242         |\n",
            "|    total_timesteps      | 221184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022373423 |\n",
            "|    clip_fraction        | 0.188       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.695      |\n",
            "|    explained_variance   | 0.129       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.603       |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | 0.00167     |\n",
            "|    value_loss           | 1.4         |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 10.8       |\n",
            "|    ep_rew_mean          | 0.49       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 915        |\n",
            "|    iterations           | 19         |\n",
            "|    time_elapsed         | 255        |\n",
            "|    total_timesteps      | 233472     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02458922 |\n",
            "|    clip_fraction        | 0.204      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.661     |\n",
            "|    explained_variance   | 0.121      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.875      |\n",
            "|    n_updates            | 180        |\n",
            "|    policy_gradient_loss | 0.000839   |\n",
            "|    value_loss           | 1.35       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 12.1       |\n",
            "|    ep_rew_mean          | 0.49       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 921        |\n",
            "|    iterations           | 20         |\n",
            "|    time_elapsed         | 266        |\n",
            "|    total_timesteps      | 245760     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02301965 |\n",
            "|    clip_fraction        | 0.186      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.649     |\n",
            "|    explained_variance   | 0.138      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.968      |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | 0.00204    |\n",
            "|    value_loss           | 1.41       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 12.6        |\n",
            "|    ep_rew_mean          | 0.5         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 921         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 279         |\n",
            "|    total_timesteps      | 258048      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022050181 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.657      |\n",
            "|    explained_variance   | 0.115       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.778       |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | 0.00225     |\n",
            "|    value_loss           | 1.48        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 14.1        |\n",
            "|    ep_rew_mean          | 0.47        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 922         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 293         |\n",
            "|    total_timesteps      | 270336      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020676788 |\n",
            "|    clip_fraction        | 0.187       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.628      |\n",
            "|    explained_variance   | 0.111       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.85        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | 0.00132     |\n",
            "|    value_loss           | 1.37        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 14.4       |\n",
            "|    ep_rew_mean          | 0.71       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 927        |\n",
            "|    iterations           | 23         |\n",
            "|    time_elapsed         | 304        |\n",
            "|    total_timesteps      | 282624     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02536924 |\n",
            "|    clip_fraction        | 0.18       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.609     |\n",
            "|    explained_variance   | 0.114      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.834      |\n",
            "|    n_updates            | 220        |\n",
            "|    policy_gradient_loss | 0.00172    |\n",
            "|    value_loss           | 1.49       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 17.5      |\n",
            "|    ep_rew_mean          | 0.86      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 932       |\n",
            "|    iterations           | 24        |\n",
            "|    time_elapsed         | 316       |\n",
            "|    total_timesteps      | 294912    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0254407 |\n",
            "|    clip_fraction        | 0.19      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.568    |\n",
            "|    explained_variance   | 0.0958    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.931     |\n",
            "|    n_updates            | 230       |\n",
            "|    policy_gradient_loss | 0.00118   |\n",
            "|    value_loss           | 1.5       |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | -0.25       |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 16.9        |\n",
            "|    ep_rew_mean          | 0.79        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 928         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 330         |\n",
            "|    total_timesteps      | 307200      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022100994 |\n",
            "|    clip_fraction        | 0.169       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.562      |\n",
            "|    explained_variance   | 0.114       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.708       |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | 0.00148     |\n",
            "|    value_loss           | 1.4         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 20.6        |\n",
            "|    ep_rew_mean          | 0.97        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 933         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 342         |\n",
            "|    total_timesteps      | 319488      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022492245 |\n",
            "|    clip_fraction        | 0.169       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.543      |\n",
            "|    explained_variance   | 0.111       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.589       |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | 0.00157     |\n",
            "|    value_loss           | 1.44        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.4        |\n",
            "|    ep_rew_mean          | 1.04        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 938         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 353         |\n",
            "|    total_timesteps      | 331776      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020693066 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.508      |\n",
            "|    explained_variance   | 0.111       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.628       |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | 0.00182     |\n",
            "|    value_loss           | 1.34        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 21.7       |\n",
            "|    ep_rew_mean          | 1.16       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 944        |\n",
            "|    iterations           | 28         |\n",
            "|    time_elapsed         | 364        |\n",
            "|    total_timesteps      | 344064     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02179567 |\n",
            "|    clip_fraction        | 0.16       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.494     |\n",
            "|    explained_variance   | 0.112      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.744      |\n",
            "|    n_updates            | 270        |\n",
            "|    policy_gradient_loss | 0.00402    |\n",
            "|    value_loss           | 1.41       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.7        |\n",
            "|    ep_rew_mean          | 1.37        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 949         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 375         |\n",
            "|    total_timesteps      | 356352      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025612986 |\n",
            "|    clip_fraction        | 0.161       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.467      |\n",
            "|    explained_variance   | 0.0887      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.749       |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | 0.00205     |\n",
            "|    value_loss           | 1.53        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 24.5        |\n",
            "|    ep_rew_mean          | 1.55        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 954         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 386         |\n",
            "|    total_timesteps      | 368640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018963793 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.431      |\n",
            "|    explained_variance   | 0.113       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.741       |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | 0.00332     |\n",
            "|    value_loss           | 1.43        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.8        |\n",
            "|    ep_rew_mean          | 1.96        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 958         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 397         |\n",
            "|    total_timesteps      | 380928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024493994 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.424      |\n",
            "|    explained_variance   | 0.11        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.584       |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | 0.00237     |\n",
            "|    value_loss           | 1.38        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 24.9       |\n",
            "|    ep_rew_mean          | 1.58       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 963        |\n",
            "|    iterations           | 32         |\n",
            "|    time_elapsed         | 408        |\n",
            "|    total_timesteps      | 393216     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02150621 |\n",
            "|    clip_fraction        | 0.142      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.41      |\n",
            "|    explained_variance   | 0.116      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.639      |\n",
            "|    n_updates            | 310        |\n",
            "|    policy_gradient_loss | 0.00371    |\n",
            "|    value_loss           | 1.39       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 27.1        |\n",
            "|    ep_rew_mean          | 1.95        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 967         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 419         |\n",
            "|    total_timesteps      | 405504      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019915668 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.401      |\n",
            "|    explained_variance   | 0.138       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.561       |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | 0.00221     |\n",
            "|    value_loss           | 1.32        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 26.7       |\n",
            "|    ep_rew_mean          | 2.13       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 971        |\n",
            "|    iterations           | 34         |\n",
            "|    time_elapsed         | 429        |\n",
            "|    total_timesteps      | 417792     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02280885 |\n",
            "|    clip_fraction        | 0.135      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.386     |\n",
            "|    explained_variance   | 0.143      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.671      |\n",
            "|    n_updates            | 330        |\n",
            "|    policy_gradient_loss | 0.00369    |\n",
            "|    value_loss           | 1.33       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 27.7        |\n",
            "|    ep_rew_mean          | 2.05        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 975         |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 440         |\n",
            "|    total_timesteps      | 430080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018697662 |\n",
            "|    clip_fraction        | 0.127       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.373      |\n",
            "|    explained_variance   | 0.154       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.572       |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | 0.00392     |\n",
            "|    value_loss           | 1.27        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 27.7        |\n",
            "|    ep_rew_mean          | 1.93        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 979         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 451         |\n",
            "|    total_timesteps      | 442368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019951263 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.349      |\n",
            "|    explained_variance   | 0.189       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.788       |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | 0.00155     |\n",
            "|    value_loss           | 1.29        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| combo                   | -0.21       |\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.4        |\n",
            "|    ep_rew_mean          | 2.05        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 979         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 464         |\n",
            "|    total_timesteps      | 454656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016998298 |\n",
            "|    clip_fraction        | 0.118       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.333      |\n",
            "|    explained_variance   | 0.153       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.759       |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | 0.00352     |\n",
            "|    value_loss           | 1.35        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.3        |\n",
            "|    ep_rew_mean          | 1.79        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 980         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 475         |\n",
            "|    total_timesteps      | 466944      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019909522 |\n",
            "|    clip_fraction        | 0.122       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.336      |\n",
            "|    explained_variance   | 0.15        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.902       |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | 0.00214     |\n",
            "|    value_loss           | 1.3         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 27.6        |\n",
            "|    ep_rew_mean          | 1.91        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 984         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 486         |\n",
            "|    total_timesteps      | 479232      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015876962 |\n",
            "|    clip_fraction        | 0.112       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.32       |\n",
            "|    explained_variance   | 0.131       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.364       |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | 0.00362     |\n",
            "|    value_loss           | 1.42        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.5        |\n",
            "|    ep_rew_mean          | 2.23        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 986         |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 498         |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016784294 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.298      |\n",
            "|    explained_variance   | 0.161       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.697       |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | 0.00184     |\n",
            "|    value_loss           | 1.34        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.1        |\n",
            "|    ep_rew_mean          | 1.92        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 989         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 509         |\n",
            "|    total_timesteps      | 503808      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018872753 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.291      |\n",
            "|    explained_variance   | 0.168       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.467       |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | 0.00372     |\n",
            "|    value_loss           | 1.29        |\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "env = PuzzEnv()\n",
        "\n",
        "obs, _info = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "n_steps = 30\n",
        "for step in range(n_steps):\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  action, _states = model.predict(obs)\n",
        "  obs, reward, done, _, info = env.step(action)\n",
        "  # print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render()\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "metadata": {
        "id": "VNaQQfU-Zi_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a245ytFhwGg3"
      },
      "source": [
        "model.save('puzzdra_nn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q85IqDNWZvS-"
      },
      "source": [
        "print(model.policy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tXh-sdQYzfHT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}