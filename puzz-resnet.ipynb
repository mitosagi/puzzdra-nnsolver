{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "docker run -p 9000:8080 -p 6006:6006 asia-docker.pkg.dev/colab-images/public/runtime"
      ],
      "metadata": {
        "id": "dFK9SV8FkPcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "!git clone --recursive https://github.com/mitosagi/puzzdra-nnsolver\n",
        "# %cd /kaggle/working/puzzdra-nnsolver\n",
        "%cd /content/puzzdra-nnsolver\n",
        "!pip install --log=pip_log -e .\n",
        "!pip install torchsummary"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-11-03T23:35:15.022060Z",
          "iopub.execute_input": "2023-11-03T23:35:15.022612Z",
          "iopub.status.idle": "2023-11-03T23:35:47.933363Z",
          "shell.execute_reply.started": "2023-11-03T23:35:15.022573Z",
          "shell.execute_reply": "2023-11-03T23:35:47.932265Z"
        },
        "trusted": true,
        "id": "84RFF9fTkEev",
        "outputId": "26a3c409-01f6-4ab6-f28f-63148d74d839",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'puzzdra-nnsolver'...\n",
            "remote: Enumerating objects: 299, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 299 (delta 31), reused 0 (delta 0), pack-reused 245\u001b[K\n",
            "Receiving objects: 100% (299/299), 8.31 MiB | 24.74 MiB/s, done.\n",
            "Resolving deltas: 100% (173/173), done.\n",
            "Submodule 'extern/pybind11' (https://github.com/pybind/pybind11) registered for path 'extern/pybind11'\n",
            "Cloning into '/content/puzzdra-nnsolver/extern/pybind11'...\n",
            "remote: Enumerating objects: 27236, done.        \n",
            "remote: Counting objects: 100% (8/8), done.        \n",
            "remote: Compressing objects: 100% (6/6), done.        \n",
            "remote: Total 27236 (delta 1), reused 4 (delta 1), pack-reused 27228        \n",
            "Receiving objects: 100% (27236/27236), 10.39 MiB | 18.15 MiB/s, done.\n",
            "Resolving deltas: 100% (19162/19162), done.\n",
            "Submodule path 'extern/pybind11': checked out '8de7772cc72daca8e947b79b83fea46214931604'\n",
            "/content/puzzdra-nnsolver\n",
            "Obtaining file:///content/puzzdra-nnsolver\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: Puzzpy\n",
            "  Running setup.py develop for Puzzpy\n",
            "Successfully installed Puzzpy-1.0\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from puzzpy import PuzzTable\n",
        "\n",
        "drop_color = 3\n",
        "board_width = 6\n",
        "board_height = 5\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "    BLACK = '\\033[30m'\n",
        "    RED = '\\033[31m'\n",
        "    GREEN = '\\033[32m'\n",
        "    YELLOW = '\\033[33m'\n",
        "    BLUE = '\\033[34m'\n",
        "    MAGENTA = '\\033[35m'\n",
        "    CYAN = '\\033[36m'\n",
        "\n",
        "def npUint8(array):\n",
        "    return np.array(array, dtype=np.uint8)\n",
        "\n",
        "class PuzzBoard():\n",
        "    def reset(self):\n",
        "        self.prev_action = 255\n",
        "\n",
        "        while True:\n",
        "            self.table = PuzzTable(\"\".join([str(random.randrange(drop_color)) for i in range(board_width*board_height)]), random.randrange(board_width), random.randrange(board_height), 50) # n色陣　操作時間m秒\n",
        "            if self.table.eval_otoshi() == 0:\n",
        "                break\n",
        "\n",
        "        return npUint8(self.table.get_table())\n",
        "\n",
        "    def step(self):\n",
        "        next_tables = self.table.next_tables()\n",
        "        valid_actions = [action for action, table in enumerate(next_tables) if table.get_table()[0][0] != 127 and abs(action - self.prev_action) != 2]\n",
        "        self.prev_action = random.choice(valid_actions)\n",
        "        self.table = next_tables[self.prev_action]\n",
        "\n",
        "        return self.prev_action, npUint8([(npUint8(table.get_table()) if action in valid_actions else np.zeros_like(npUint8(table.get_table()))) for action, table in enumerate(next_tables)])\n",
        "    def render(self):\n",
        "        tcolor = [bcolors.RED, bcolors.BLUE, bcolors.GREEN, bcolors.MAGENTA, bcolors.YELLOW, bcolors.BLACK]\n",
        "        start = self.table.get_XY_as_table()\n",
        "        table = self.table.get_table()\n",
        "        for i in range(board_height):\n",
        "            for j in range(board_width):\n",
        "                if start[i][j] == 1:\n",
        "                    print(tcolor[table[i][j]-1]  +  bcolors.UNDERLINE + \"●\" + bcolors.ENDC, end='')\n",
        "                else:\n",
        "                    print(tcolor[table[i][j]-1]  + \"●\" + bcolors.ENDC, end='')\n",
        "            print('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-03T23:35:47.935829Z",
          "iopub.execute_input": "2023-11-03T23:35:47.936217Z",
          "iopub.status.idle": "2023-11-03T23:35:47.957993Z",
          "shell.execute_reply.started": "2023-11-03T23:35:47.936183Z",
          "shell.execute_reply": "2023-11-03T23:35:47.956964Z"
        },
        "trusted": true,
        "id": "8nSDWSShkEex"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = PuzzBoard()\n",
        "obs = env.reset()\n",
        "env.render()\n",
        "\n",
        "n_steps = 3\n",
        "\n",
        "for step in range(n_steps):\n",
        "    print(\"Step {}\".format(step + 1))\n",
        "    action, obs = env.step()\n",
        "    with np.printoptions(threshold=np.inf):\n",
        "        print(\"action: \", action)\n",
        "#         print(obs)\n",
        "        env.render()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-03T23:35:47.959282Z",
          "iopub.execute_input": "2023-11-03T23:35:47.959622Z",
          "iopub.status.idle": "2023-11-03T23:35:47.978109Z",
          "shell.execute_reply.started": "2023-11-03T23:35:47.959595Z",
          "shell.execute_reply": "2023-11-03T23:35:47.977219Z"
        },
        "trusted": true,
        "id": "j-LdMczrkEex",
        "outputId": "a70b54c3-159b-4cf0-8236-7dbe780189dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "Step 1\n",
            "action:  3\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "Step 2\n",
            "action:  3\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "Step 3\n",
            "action:  3\n",
            "\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n",
            "\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n",
            "\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_data(num_step, env):\n",
        "    start = env.reset()\n",
        "\n",
        "    sample_step = random.randrange(1, num_step + 1)\n",
        "\n",
        "    for i in range(sample_step):\n",
        "        answer, obs = env.step()\n",
        "    sample_obs = obs\n",
        "\n",
        "    for i in range(num_step - sample_step):\n",
        "        answer, obs = env.step()\n",
        "    end = obs[answer]\n",
        "\n",
        "    return np.concatenate([npUint8([start]),sample_obs,npUint8([end])]), answer\n",
        "def make_data_fast(length):\n",
        "    env = PuzzBoard()\n",
        "    return [make_data(50, env) for i in range(length)]\n",
        "\n",
        "from multiprocessing import Pool\n",
        "process = 10\n",
        "p = Pool(process)\n",
        "%time result = p.map(make_data_fast, [1_000_000 // process  for i in range(process)]) # 100万データ生成に5分22秒かかる\n",
        "\n",
        "import itertools\n",
        "sample_data = npUint8([sample[0] for sample in itertools.chain(*result)])\n",
        "sample_labels = npUint8([sample[1] for sample in itertools.chain(*result)])\n",
        "np.save('sample_data_50', sample_data)\n",
        "np.save('sample_labels_50', sample_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-03T23:37:02.385538Z",
          "iopub.execute_input": "2023-11-03T23:37:02.385894Z"
        },
        "trusted": true,
        "id": "HO8nP6WCkEex",
        "outputId": "8e9dff77-fea4-43cf-d966-6450a970f28f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.03 s, sys: 627 ms, total: 3.65 s\n",
            "Wall time: 5min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = np.load('/kaggle/input/puzz-dataset/sample_data.npy')\n",
        "sample_labels = np.load('/kaggle/input/puzz-dataset/sample_labels.npy')\n",
        "from torch.utils.data import Dataset\n",
        "class PuzzDataSet(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.data = np.array(x, dtype=np.float32)\n",
        "        self.labels = np.array(np.identity(4)[y], dtype=np.float32) # 4 for actions\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "dataset = PuzzDataSet(sample_data[0:len(sample_data) - 1_000],sample_labels[0:len(sample_labels) - 1_000])\n",
        "print(\"dataset: \", dataset.__len__())\n",
        "print(\"dataset: \", dataset.__getitem__(1))\n",
        "testset = PuzzDataSet(sample_data[len(sample_data) - 1_000:],sample_labels[len(sample_labels) - 1_000:])\n",
        "print(\"testset: \", testset.__len__())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-03T23:03:07.459748Z",
          "iopub.execute_input": "2023-11-03T23:03:07.460095Z",
          "iopub.status.idle": "2023-11-03T23:03:12.360190Z",
          "shell.execute_reply.started": "2023-11-03T23:03:07.460063Z",
          "shell.execute_reply": "2023-11-03T23:03:12.359091Z"
        },
        "trusted": true,
        "id": "d1V18BD9kEey",
        "outputId": "4796543f-1d39-40df-9bfd-7b5a887a408a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "dataset:  999000\ndataset:  (array([[[1., 3., 1., 3., 2., 1.],\n        [1., 3., 3., 1., 3., 2.],\n        [2., 1., 1., 3., 1., 3.],\n        [1., 1., 2., 3., 2., 2.],\n        [3., 2., 3., 1., 2., 3.]],\n\n       [[0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.]],\n\n       [[1., 3., 1., 3., 2., 1.],\n        [1., 3., 3., 1., 3., 2.],\n        [2., 1., 1., 3., 1., 3.],\n        [1., 1., 2., 3., 2., 2.],\n        [3., 2., 3., 1., 3., 2.]],\n\n       [[1., 3., 1., 3., 2., 1.],\n        [1., 3., 3., 1., 3., 2.],\n        [2., 1., 1., 3., 1., 3.],\n        [1., 1., 2., 3., 2., 3.],\n        [3., 2., 3., 1., 2., 2.]],\n\n       [[1., 3., 1., 3., 2., 1.],\n        [1., 3., 3., 1., 3., 2.],\n        [1., 2., 1., 3., 1., 3.],\n        [1., 2., 1., 2., 2., 2.],\n        [3., 3., 3., 3., 1., 2.]]], dtype=float32), array([0., 1., 0., 0.], dtype=float32))\ntestset:  1000\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        num_input_channel = 6\n",
        "        num_classes = 4\n",
        "        resnet = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "        resnet.conv1 = nn.Conv2d(num_input_channel, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
        "        resnet.fc = nn.Linear(512, num_classes)\n",
        "        self.resnet = resnet\n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, size=None, scale_factor=2, mode='nearest')\n",
        "        x = self.resnet(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "for i, param in enumerate(model.parameters()):\n",
        "#     param.requires_grad = False if len(param) != 512 and len(param) != 4 else True\n",
        "    param.requires_grad = True if i >= 45 + 15 else False\n",
        "    print(len(param), param.requires_grad)\n",
        "\n",
        "# model = CNN()\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(\"device: \", device)\n",
        "model = model.to(device)\n",
        "print(summary(model, (6, 5, 6)))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=200, shuffle=True)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0005)\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "\n",
        "import datetime\n",
        "\n",
        "def train(epoch):\n",
        "    total_loss = 0\n",
        "    total_size = 0\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "#         print(output)\n",
        "#         output = torch.flatten(output)\n",
        "        loss = criterion(output, target)\n",
        "        total_loss += loss.item()\n",
        "        total_size += data.size(0)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            now = datetime.datetime.now()\n",
        "            print('[{}] Train Epoch: {} [{}/{} ({:.0f}%)]\\tAverage loss: {:.6f}'.format(\n",
        "                now,\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), total_loss / total_size))\n",
        "            writer.add_scalar('Loss/train', total_loss / total_size, epoch)\n",
        "            test(epoch)\n",
        "def test(epoch):\n",
        "    total_loss = 0\n",
        "    total_size = 0\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "#         output = torch.flatten(output)\n",
        "        loss = criterion(output, target)\n",
        "        total_loss += loss.item()\n",
        "        total_size += data.size(0)\n",
        "        if batch_idx % 100 == 0:\n",
        "            now = datetime.datetime.now()\n",
        "            print('[{}] Test Epoch: {} [{}/{} ({:.0f}%)]\\tAverage loss: {:.6f}'.format(\n",
        "                now,\n",
        "                epoch, batch_idx * len(data), len(test_loader.dataset),\n",
        "                100. * batch_idx / len(test_loader), total_loss / total_size))\n",
        "            writer.add_scalar('Loss/test', total_loss / total_size, epoch)\n",
        "            break\n",
        "\n",
        "for epoch in range(1, 1 + 1):\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-03T23:33:21.000039Z",
          "iopub.execute_input": "2023-11-03T23:33:21.000424Z",
          "iopub.status.idle": "2023-11-03T23:34:00.191547Z",
          "shell.execute_reply.started": "2023-11-03T23:33:21.000390Z",
          "shell.execute_reply": "2023-11-03T23:34:00.189929Z"
        },
        "trusted": true,
        "id": "JyXo_fAOkEey",
        "outputId": "f789fc07-ffbb-4cdf-89ba-bc38d386830d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "64 False\n64 False\n64 False\n64 False\n64 False\n64 False\n64 False\n64 False\n64 False\n64 False\n64 False\n64 False\n64 False\n64 False\n64 False\n128 False\n128 False\n128 False\n128 False\n128 False\n128 False\n128 False\n128 False\n128 False\n128 False\n128 False\n128 False\n128 False\n128 False\n128 False\n256 False\n256 False\n256 False\n256 False\n256 False\n256 False\n256 False\n256 False\n256 False\n256 False\n256 False\n256 False\n256 False\n256 False\n256 False\n512 False\n512 False\n512 False\n512 False\n512 False\n512 False\n512 False\n512 False\n512 False\n512 False\n512 False\n512 False\n512 True\n512 True\n512 True\n4 True\n4 True\ndevice:  cuda\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1             [-1, 64, 5, 6]          18,816\n       BatchNorm2d-2             [-1, 64, 5, 6]             128\n              ReLU-3             [-1, 64, 5, 6]               0\n         MaxPool2d-4             [-1, 64, 3, 3]               0\n            Conv2d-5             [-1, 64, 3, 3]          36,864\n       BatchNorm2d-6             [-1, 64, 3, 3]             128\n              ReLU-7             [-1, 64, 3, 3]               0\n            Conv2d-8             [-1, 64, 3, 3]          36,864\n       BatchNorm2d-9             [-1, 64, 3, 3]             128\n             ReLU-10             [-1, 64, 3, 3]               0\n       BasicBlock-11             [-1, 64, 3, 3]               0\n           Conv2d-12             [-1, 64, 3, 3]          36,864\n      BatchNorm2d-13             [-1, 64, 3, 3]             128\n             ReLU-14             [-1, 64, 3, 3]               0\n           Conv2d-15             [-1, 64, 3, 3]          36,864\n      BatchNorm2d-16             [-1, 64, 3, 3]             128\n             ReLU-17             [-1, 64, 3, 3]               0\n       BasicBlock-18             [-1, 64, 3, 3]               0\n           Conv2d-19            [-1, 128, 2, 2]          73,728\n      BatchNorm2d-20            [-1, 128, 2, 2]             256\n             ReLU-21            [-1, 128, 2, 2]               0\n           Conv2d-22            [-1, 128, 2, 2]         147,456\n      BatchNorm2d-23            [-1, 128, 2, 2]             256\n           Conv2d-24            [-1, 128, 2, 2]           8,192\n      BatchNorm2d-25            [-1, 128, 2, 2]             256\n             ReLU-26            [-1, 128, 2, 2]               0\n       BasicBlock-27            [-1, 128, 2, 2]               0\n           Conv2d-28            [-1, 128, 2, 2]         147,456\n      BatchNorm2d-29            [-1, 128, 2, 2]             256\n             ReLU-30            [-1, 128, 2, 2]               0\n           Conv2d-31            [-1, 128, 2, 2]         147,456\n      BatchNorm2d-32            [-1, 128, 2, 2]             256\n             ReLU-33            [-1, 128, 2, 2]               0\n       BasicBlock-34            [-1, 128, 2, 2]               0\n           Conv2d-35            [-1, 256, 1, 1]         294,912\n      BatchNorm2d-36            [-1, 256, 1, 1]             512\n             ReLU-37            [-1, 256, 1, 1]               0\n           Conv2d-38            [-1, 256, 1, 1]         589,824\n      BatchNorm2d-39            [-1, 256, 1, 1]             512\n           Conv2d-40            [-1, 256, 1, 1]          32,768\n      BatchNorm2d-41            [-1, 256, 1, 1]             512\n             ReLU-42            [-1, 256, 1, 1]               0\n       BasicBlock-43            [-1, 256, 1, 1]               0\n           Conv2d-44            [-1, 256, 1, 1]         589,824\n      BatchNorm2d-45            [-1, 256, 1, 1]             512\n             ReLU-46            [-1, 256, 1, 1]               0\n           Conv2d-47            [-1, 256, 1, 1]         589,824\n      BatchNorm2d-48            [-1, 256, 1, 1]             512\n             ReLU-49            [-1, 256, 1, 1]               0\n       BasicBlock-50            [-1, 256, 1, 1]               0\n           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n             ReLU-53            [-1, 512, 1, 1]               0\n           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n           Conv2d-56            [-1, 512, 1, 1]         131,072\n      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n             ReLU-58            [-1, 512, 1, 1]               0\n       BasicBlock-59            [-1, 512, 1, 1]               0\n           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n             ReLU-62            [-1, 512, 1, 1]               0\n           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n             ReLU-65            [-1, 512, 1, 1]               0\n       BasicBlock-66            [-1, 512, 1, 1]               0\nAdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n           Linear-68                    [-1, 4]           2,052\n           ResNet-69                    [-1, 4]               0\n================================================================\nTotal params: 11,187,972\nTrainable params: 2,362,372\nNon-trainable params: 8,825,600\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.27\nParams size (MB): 42.68\nEstimated Total Size (MB): 42.95\n----------------------------------------------------------------\nNone\n[2023-11-03 23:33:21.330225] Train Epoch: 1 [0/999000 (0%)]\tAverage loss: 0.006676\n[2023-11-03 23:33:21.344745] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.001346\n[2023-11-03 23:33:22.019890] Train Epoch: 1 [10000/999000 (1%)]\tAverage loss: 0.001992\n[2023-11-03 23:33:22.028212] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000947\n[2023-11-03 23:33:22.593293] Train Epoch: 1 [20000/999000 (2%)]\tAverage loss: 0.001942\n[2023-11-03 23:33:22.601453] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000941\n[2023-11-03 23:33:23.195230] Train Epoch: 1 [30000/999000 (3%)]\tAverage loss: 0.001925\n[2023-11-03 23:33:23.203701] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000942\n[2023-11-03 23:33:23.773383] Train Epoch: 1 [40000/999000 (4%)]\tAverage loss: 0.001916\n[2023-11-03 23:33:23.781838] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000943\n[2023-11-03 23:33:24.389272] Train Epoch: 1 [50000/999000 (5%)]\tAverage loss: 0.001910\n[2023-11-03 23:33:24.397441] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000942\n[2023-11-03 23:33:24.960704] Train Epoch: 1 [60000/999000 (6%)]\tAverage loss: 0.001905\n[2023-11-03 23:33:24.970272] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000945\n[2023-11-03 23:33:25.544918] Train Epoch: 1 [70000/999000 (7%)]\tAverage loss: 0.001902\n[2023-11-03 23:33:25.553059] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000942\n[2023-11-03 23:33:26.122030] Train Epoch: 1 [80000/999000 (8%)]\tAverage loss: 0.001899\n[2023-11-03 23:33:26.130630] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000953\n[2023-11-03 23:33:26.711898] Train Epoch: 1 [90000/999000 (9%)]\tAverage loss: 0.001896\n[2023-11-03 23:33:26.720543] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000943\n[2023-11-03 23:33:27.293556] Train Epoch: 1 [100000/999000 (10%)]\tAverage loss: 0.001895\n[2023-11-03 23:33:27.301852] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000940\n[2023-11-03 23:33:27.873982] Train Epoch: 1 [110000/999000 (11%)]\tAverage loss: 0.001893\n[2023-11-03 23:33:27.882270] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000939\n[2023-11-03 23:33:28.444197] Train Epoch: 1 [120000/999000 (12%)]\tAverage loss: 0.001892\n[2023-11-03 23:33:28.452826] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000941\n[2023-11-03 23:33:29.016460] Train Epoch: 1 [130000/999000 (13%)]\tAverage loss: 0.001890\n[2023-11-03 23:33:29.024710] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000928\n[2023-11-03 23:33:29.588233] Train Epoch: 1 [140000/999000 (14%)]\tAverage loss: 0.001889\n[2023-11-03 23:33:29.596822] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000936\n[2023-11-03 23:33:30.158297] Train Epoch: 1 [150000/999000 (15%)]\tAverage loss: 0.001888\n[2023-11-03 23:33:30.166362] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000945\n[2023-11-03 23:33:30.729309] Train Epoch: 1 [160000/999000 (16%)]\tAverage loss: 0.001887\n[2023-11-03 23:33:30.737571] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000939\n[2023-11-03 23:33:31.309192] Train Epoch: 1 [170000/999000 (17%)]\tAverage loss: 0.001886\n[2023-11-03 23:33:31.317431] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000939\n[2023-11-03 23:33:31.880301] Train Epoch: 1 [180000/999000 (18%)]\tAverage loss: 0.001885\n[2023-11-03 23:33:31.888420] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000928\n[2023-11-03 23:33:32.451576] Train Epoch: 1 [190000/999000 (19%)]\tAverage loss: 0.001885\n[2023-11-03 23:33:32.459937] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000938\n[2023-11-03 23:33:33.027064] Train Epoch: 1 [200000/999000 (20%)]\tAverage loss: 0.001884\n[2023-11-03 23:33:33.035381] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000925\n[2023-11-03 23:33:33.597598] Train Epoch: 1 [210000/999000 (21%)]\tAverage loss: 0.001883\n[2023-11-03 23:33:33.605714] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000926\n[2023-11-03 23:33:34.196483] Train Epoch: 1 [220000/999000 (22%)]\tAverage loss: 0.001883\n[2023-11-03 23:33:34.204698] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000937\n[2023-11-03 23:33:34.765844] Train Epoch: 1 [230000/999000 (23%)]\tAverage loss: 0.001882\n[2023-11-03 23:33:34.774061] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000941\n[2023-11-03 23:33:35.337443] Train Epoch: 1 [240000/999000 (24%)]\tAverage loss: 0.001882\n[2023-11-03 23:33:35.345644] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000937\n[2023-11-03 23:33:35.906493] Train Epoch: 1 [250000/999000 (25%)]\tAverage loss: 0.001881\n[2023-11-03 23:33:35.914859] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000927\n[2023-11-03 23:33:36.474249] Train Epoch: 1 [260000/999000 (26%)]\tAverage loss: 0.001881\n[2023-11-03 23:33:36.482513] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000933\n[2023-11-03 23:33:37.045425] Train Epoch: 1 [270000/999000 (27%)]\tAverage loss: 0.001881\n[2023-11-03 23:33:37.053544] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000932\n[2023-11-03 23:33:37.617085] Train Epoch: 1 [280000/999000 (28%)]\tAverage loss: 0.001880\n[2023-11-03 23:33:37.625208] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000930\n[2023-11-03 23:33:38.248374] Train Epoch: 1 [290000/999000 (29%)]\tAverage loss: 0.001880\n[2023-11-03 23:33:38.257292] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000942\n[2023-11-03 23:33:38.850165] Train Epoch: 1 [300000/999000 (30%)]\tAverage loss: 0.001880\n[2023-11-03 23:33:38.859028] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000943\n[2023-11-03 23:33:39.432458] Train Epoch: 1 [310000/999000 (31%)]\tAverage loss: 0.001879\n[2023-11-03 23:33:39.441515] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000945\n[2023-11-03 23:33:40.009133] Train Epoch: 1 [320000/999000 (32%)]\tAverage loss: 0.001879\n[2023-11-03 23:33:40.017498] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000943\n[2023-11-03 23:33:40.579208] Train Epoch: 1 [330000/999000 (33%)]\tAverage loss: 0.001879\n[2023-11-03 23:33:40.587437] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000939\n[2023-11-03 23:33:41.149499] Train Epoch: 1 [340000/999000 (34%)]\tAverage loss: 0.001878\n[2023-11-03 23:33:41.157779] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000941\n[2023-11-03 23:33:41.724740] Train Epoch: 1 [350000/999000 (35%)]\tAverage loss: 0.001878\n[2023-11-03 23:33:41.732899] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000940\n[2023-11-03 23:33:42.302031] Train Epoch: 1 [360000/999000 (36%)]\tAverage loss: 0.001878\n[2023-11-03 23:33:42.310479] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000940\n[2023-11-03 23:33:42.865859] Train Epoch: 1 [370000/999000 (37%)]\tAverage loss: 0.001877\n[2023-11-03 23:33:42.874044] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000935\n[2023-11-03 23:33:43.432028] Train Epoch: 1 [380000/999000 (38%)]\tAverage loss: 0.001877\n[2023-11-03 23:33:43.440461] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000933\n[2023-11-03 23:33:44.029181] Train Epoch: 1 [390000/999000 (39%)]\tAverage loss: 0.001877\n[2023-11-03 23:33:44.040131] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000930\n[2023-11-03 23:33:44.606163] Train Epoch: 1 [400000/999000 (40%)]\tAverage loss: 0.001877\n[2023-11-03 23:33:44.614558] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000940\n[2023-11-03 23:33:45.180252] Train Epoch: 1 [410000/999000 (41%)]\tAverage loss: 0.001876\n[2023-11-03 23:33:45.188695] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000933\n[2023-11-03 23:33:45.752860] Train Epoch: 1 [420000/999000 (42%)]\tAverage loss: 0.001876\n[2023-11-03 23:33:45.761315] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000936\n[2023-11-03 23:33:46.341543] Train Epoch: 1 [430000/999000 (43%)]\tAverage loss: 0.001876\n[2023-11-03 23:33:46.349657] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000927\n[2023-11-03 23:33:46.908567] Train Epoch: 1 [440000/999000 (44%)]\tAverage loss: 0.001876\n[2023-11-03 23:33:46.916872] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000927\n[2023-11-03 23:33:47.480872] Train Epoch: 1 [450000/999000 (45%)]\tAverage loss: 0.001876\n[2023-11-03 23:33:47.489259] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000925\n[2023-11-03 23:33:48.054459] Train Epoch: 1 [460000/999000 (46%)]\tAverage loss: 0.001875\n[2023-11-03 23:33:48.062656] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000930\n[2023-11-03 23:33:48.630026] Train Epoch: 1 [470000/999000 (47%)]\tAverage loss: 0.001875\n[2023-11-03 23:33:48.638164] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000935\n[2023-11-03 23:33:49.208788] Train Epoch: 1 [480000/999000 (48%)]\tAverage loss: 0.001875\n[2023-11-03 23:33:49.217062] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000933\n[2023-11-03 23:33:49.778705] Train Epoch: 1 [490000/999000 (49%)]\tAverage loss: 0.001875\n[2023-11-03 23:33:49.787266] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000935\n[2023-11-03 23:33:50.349769] Train Epoch: 1 [500000/999000 (50%)]\tAverage loss: 0.001875\n[2023-11-03 23:33:50.358192] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000932\n[2023-11-03 23:33:50.922781] Train Epoch: 1 [510000/999000 (51%)]\tAverage loss: 0.001875\n[2023-11-03 23:33:50.931102] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000935\n[2023-11-03 23:33:51.504361] Train Epoch: 1 [520000/999000 (52%)]\tAverage loss: 0.001874\n[2023-11-03 23:33:51.512557] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000938\n[2023-11-03 23:33:52.073920] Train Epoch: 1 [530000/999000 (53%)]\tAverage loss: 0.001874\n[2023-11-03 23:33:52.082210] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000930\n[2023-11-03 23:33:52.647860] Train Epoch: 1 [540000/999000 (54%)]\tAverage loss: 0.001874\n[2023-11-03 23:33:52.656227] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000932\n[2023-11-03 23:33:53.222365] Train Epoch: 1 [550000/999000 (55%)]\tAverage loss: 0.001874\n[2023-11-03 23:33:53.230483] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000928\n[2023-11-03 23:33:53.786062] Train Epoch: 1 [560000/999000 (56%)]\tAverage loss: 0.001874\n[2023-11-03 23:33:53.794234] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000931\n[2023-11-03 23:33:54.373689] Train Epoch: 1 [570000/999000 (57%)]\tAverage loss: 0.001874\n[2023-11-03 23:33:54.381869] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000936\n[2023-11-03 23:33:54.944184] Train Epoch: 1 [580000/999000 (58%)]\tAverage loss: 0.001874\n[2023-11-03 23:33:54.952443] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000920\n[2023-11-03 23:33:55.512900] Train Epoch: 1 [590000/999000 (59%)]\tAverage loss: 0.001873\n[2023-11-03 23:33:55.520931] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000936\n[2023-11-03 23:33:56.083658] Train Epoch: 1 [600000/999000 (60%)]\tAverage loss: 0.001873\n[2023-11-03 23:33:56.092134] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000935\n[2023-11-03 23:33:56.662641] Train Epoch: 1 [610000/999000 (61%)]\tAverage loss: 0.001873\n[2023-11-03 23:33:56.671143] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000932\n[2023-11-03 23:33:57.266563] Train Epoch: 1 [620000/999000 (62%)]\tAverage loss: 0.001873\n[2023-11-03 23:33:57.274906] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000936\n[2023-11-03 23:33:57.856169] Train Epoch: 1 [630000/999000 (63%)]\tAverage loss: 0.001873\n[2023-11-03 23:33:57.864981] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000936\n[2023-11-03 23:33:58.443890] Train Epoch: 1 [640000/999000 (64%)]\tAverage loss: 0.001873\n[2023-11-03 23:33:58.452359] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000927\n[2023-11-03 23:33:59.020108] Train Epoch: 1 [650000/999000 (65%)]\tAverage loss: 0.001873\n[2023-11-03 23:33:59.028400] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.000924\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 90\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 90\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     test(epoch)\n",
            "Cell \u001b[0;32mIn[22], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     51\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     52\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 53\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#         print(output)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#         output = torch.flatten(output)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[22], line 19\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(x, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m--> 276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/resnet.py:93\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     92\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m---> 93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-03T23:01:09.518771Z",
          "iopub.status.idle": "2023-11-03T23:01:09.519220Z",
          "shell.execute_reply.started": "2023-11-03T23:01:09.518988Z",
          "shell.execute_reply": "2023-11-03T23:01:09.519011Z"
        },
        "trusted": true,
        "id": "XQhVi-JKkEey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JcpS0jdVkEey"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}