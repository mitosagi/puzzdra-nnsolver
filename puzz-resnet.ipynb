{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"docker run -p 9000:8080 -p 6006:6006 asia-docker.pkg.dev/colab-images/public/runtime","metadata":{"id":"dFK9SV8FkPcC"}},{"cell_type":"code","source":"# Initialize\n!git clone --recursive https://github.com/mitosagi/puzzdra-nnsolver\n%cd /kaggle/working/puzzdra-nnsolver\n# %cd /content/puzzdra-nnsolver\n!pip install --log=pip_log -e .\n!pip install torchsummary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"84RFF9fTkEev","outputId":"85229caa-836f-463b-b717-83774ab59237","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-11-04T09:40:00.504667Z","iopub.execute_input":"2023-11-04T09:40:00.504960Z","iopub.status.idle":"2023-11-04T09:40:39.952984Z","shell.execute_reply.started":"2023-11-04T09:40:00.504934Z","shell.execute_reply":"2023-11-04T09:40:39.952013Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'puzzdra-nnsolver'...\nremote: Enumerating objects: 311, done.\u001b[K\nremote: Counting objects: 100% (66/66), done.\u001b[K\nremote: Compressing objects: 100% (66/66), done.\u001b[K\nremote: Total 311 (delta 38), reused 0 (delta 0), pack-reused 245\u001b[K\nReceiving objects: 100% (311/311), 8.33 MiB | 22.44 MiB/s, done.\nResolving deltas: 100% (180/180), done.\nSubmodule 'extern/pybind11' (https://github.com/pybind/pybind11) registered for path 'extern/pybind11'\nCloning into '/kaggle/working/puzzdra-nnsolver/extern/pybind11'...\nremote: Enumerating objects: 27240, done.        \nremote: Counting objects: 100% (12/12), done.        \nremote: Compressing objects: 100% (10/10), done.        \nremote: Total 27240 (delta 2), reused 4 (delta 1), pack-reused 27228        \nReceiving objects: 100% (27240/27240), 10.31 MiB | 29.17 MiB/s, done.\nResolving deltas: 100% (19261/19261), done.\nSubmodule path 'extern/pybind11': checked out '8de7772cc72daca8e947b79b83fea46214931604'\n/kaggle/working/puzzdra-nnsolver\nObtaining file:///kaggle/working/puzzdra-nnsolver\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nInstalling collected packages: Puzzpy\n  Running setup.py develop for Puzzpy\nSuccessfully installed Puzzpy-1.0\nCollecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport numpy as np\nfrom puzzpy import PuzzTable\n\ndrop_color = 3\nboard_width = 6\nboard_height = 5\n\nclass bcolors:\n    HEADER = '\\033[95m'\n    OKBLUE = '\\033[94m'\n    OKCYAN = '\\033[96m'\n    OKGREEN = '\\033[92m'\n    WARNING = '\\033[93m'\n    FAIL = '\\033[91m'\n    ENDC = '\\033[0m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'\n    BLACK = '\\033[30m'\n    RED = '\\033[31m'\n    GREEN = '\\033[32m'\n    YELLOW = '\\033[33m'\n    BLUE = '\\033[34m'\n    MAGENTA = '\\033[35m'\n    CYAN = '\\033[36m'\n\ndef npUint8(array):\n    return np.array(array, dtype=np.uint8)\n\ndef np_float(array):\n    return np.array(array, dtype=np.float32)\n\nclass PuzzBoard():\n    def reset(self, finish = False):\n        self.prev_action = 255\n\n        while True:\n            self.table = PuzzTable(\"\".join([str(random.randrange(drop_color)) for i in range(board_width*board_height)]), random.randrange(board_width), random.randrange(board_height), 50) # n色陣　操作時間m秒\n            if self.table.eval_otoshi() == 0:\n                break\n\n        if finish:\n                matrix = npUint8([[7 , 19, 10, 22, 13, 25],\n                         [ 8, 20, 11, 23, 14, 26],\n                         [ 9, 21, 12, 24, 15, 27],\n                         [28, 29, 30, 4, 5, 6],\n                         [1, 2, 3, 16, 17, 18]]).ravel() - 1\n\n                arr = np.sort(npUint8([random.randrange(drop_color) for i in range(board_width*board_height)])).reshape([10, 3]).ravel()[matrix]\n                self.table = PuzzTable(\"\".join([str(n) for n in arr]), random.randrange(board_width), random.randrange(board_height), 50) # n色陣　操作時間m秒\n\n        return npUint8(self.table.get_table())\n\n    def step(self, peek = False, force_action = None, reverse=False):\n        next_tables = self.table.next_tables()\n        valid_actions = [action for action, table in enumerate(next_tables) if table.get_table()[0][0] != 127 and abs(action - self.prev_action) != 2]\n        if reverse and self.prev_action != 255:\n            action_matrix = [2, 3, 0, 1]\n            tmp_perv_action = action_matrix[self.prev_action]\n            self.prev_action = random.choice(valid_actions)\n            self.table = next_tables[self.prev_action]\n            return tmp_perv_action, npUint8([(npUint8(table.get_table()) if action in [(action if action != self.prev_action else tmp_perv_action)  for action in valid_actions] else np.zeros_like(npUint8(table.get_table()))) for action, table in enumerate(next_tables)])\n        else:\n            if not peek:\n                if force_action != None:\n                    if force_action in valid_actions:\n                        self.prev_action = force_action\n                    else:\n                        self.prev_action = random.choice(valid_actions)\n                else:\n                    self.prev_action = random.choice(valid_actions)\n                self.table = next_tables[self.prev_action]\n            return self.prev_action, npUint8([(npUint8(table.get_table()) if action in valid_actions else np.zeros_like(npUint8(table.get_table()))) for action, table in enumerate(next_tables)])\n    def render(self):\n        tcolor = [bcolors.RED, bcolors.BLUE, bcolors.GREEN, bcolors.MAGENTA, bcolors.YELLOW, bcolors.BLACK]\n        start = self.table.get_XY_as_table()\n        table = self.table.get_table()\n        for i in range(board_height):\n            for j in range(board_width):\n                if start[i][j] == 1:\n                    print(tcolor[table[i][j]-1]  +  bcolors.UNDERLINE + \"●\" + bcolors.ENDC, end='')\n                else:\n                    print(tcolor[table[i][j]-1]  + \"●\" + bcolors.ENDC, end='')\n            print('')","metadata":{"id":"8nSDWSShkEex","execution":{"iopub.status.busy":"2023-11-04T09:40:39.955309Z","iopub.execute_input":"2023-11-04T09:40:39.955620Z","iopub.status.idle":"2023-11-04T09:40:39.984666Z","shell.execute_reply.started":"2023-11-04T09:40:39.955593Z","shell.execute_reply":"2023-11-04T09:40:39.983762Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"env = PuzzBoard()\nobs = env.reset(True)\nenv.render()\n\nn_steps = 3\n\nfor step in range(n_steps):\n    print(\"Step {}\".format(step + 1))\n    action, obs = env.step(reverse=True)\n    with np.printoptions(threshold=np.inf):\n        print(\"action: \", action)\n        print(obs)\n        env.render()","metadata":{"id":"j-LdMczrkEex","outputId":"ac59b725-ab83-4ede-de1c-4f6e0b819ee0","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-11-04T09:40:39.985848Z","iopub.execute_input":"2023-11-04T09:40:39.986132Z","iopub.status.idle":"2023-11-04T09:40:40.010025Z","shell.execute_reply.started":"2023-11-04T09:40:39.986107Z","shell.execute_reply":"2023-11-04T09:40:40.009045Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\nStep 1\naction:  0\n[[[1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [3 3 3 1 1 1]\n  [1 1 2 1 2 2]]\n\n [[0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]]\n\n [[1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [3 3 3 1 1 1]\n  [1 1 1 2 2 2]]\n\n [[1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [3 3 1 1 1 1]\n  [1 1 3 2 2 2]]]\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\nStep 2\naction:  2\n[[[0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]]\n\n [[0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]]\n\n [[1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [3 3 3 1 1 1]\n  [1 1 1 2 2 2]]\n\n [[1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [3 3 3 1 1 1]\n  [1 1 2 1 2 2]]]\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\nStep 3\naction:  2\n[[[0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]]\n\n [[0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]\n  [0 0 0 0 0 0]]\n\n [[1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [3 3 3 1 1 1]\n  [1 1 2 1 2 2]]\n\n [[1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [1 2 1 3 2 3]\n  [3 3 3 1 1 1]\n  [1 1 2 2 1 2]]]\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m\u001b[4m●\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"def make_data(num_step, env):\n    end = env.reset(True)\n\n    sample_step = random.randrange(2, num_step)\n\n    for i in range(sample_step):\n        answer, obs = env.step(reverse=True)\n    sample_obs = obs\n    sample_answer = answer\n\n    for i in range(num_step - sample_step):\n        answer, obs = env.step(reverse=True)\n    start = obs[answer]\n\n    return np.concatenate([npUint8([start]),sample_obs,npUint8([end])]), sample_answer\ndef make_data_fast(length):\n    env = PuzzBoard()\n    return [make_data(50, env) for i in range(length)]\n\n# from multiprocessing import Pool\n# process = 10\n# p = Pool(process)\n# %time result = p.map(make_data_fast, [1_000_000 // process  for i in range(process)]) # 100万データ生成に5分22秒かかる\n\n# import itertools\n# sample_data = npUint8([sample[0] for sample in itertools.chain(*result)])\n# sample_labels = npUint8([sample[1] for sample in itertools.chain(*result)])\n# np.save('sample_data_50', sample_data)\n# np.save('sample_labels_50', sample_labels)","metadata":{"id":"HO8nP6WCkEex","outputId":"5a51d76f-2a1e-4762-ed79-bb61e52d5632","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-11-04T09:40:40.012168Z","iopub.execute_input":"2023-11-04T09:40:40.012429Z","iopub.status.idle":"2023-11-04T09:40:40.020205Z","shell.execute_reply.started":"2023-11-04T09:40:40.012406Z","shell.execute_reply":"2023-11-04T09:40:40.019466Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"sample_data = np.load('/kaggle/input/puzz-data-reverse/sample_data_50.npy')\nsample_labels = np.load('/kaggle/input/puzz-data-reverse/sample_labels_50.npy')\nfrom torch.utils.data import Dataset\nclass PuzzDataSet(Dataset):\n    def __init__(self, x, y):\n        self.data = np.array(x, dtype=np.float32)\n        self.labels = np.array(np.identity(4)[y], dtype=np.float32) # 4 for actions\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.labels[idx]\n\ndataset = PuzzDataSet(sample_data[0:len(sample_data) - 1_000],sample_labels[0:len(sample_labels) - 1_000])\nprint(\"dataset: \", dataset.__len__())\nprint(\"dataset: \", dataset.__getitem__(6))\ntestset = PuzzDataSet(sample_data[len(sample_data) - 1_000:],sample_labels[len(sample_labels) - 1_000:])\nprint(\"testset: \", testset.__len__())","metadata":{"id":"d1V18BD9kEey","outputId":"8cd24beb-e5a6-489b-cea6-495ec6480041","colab":{"base_uri":"https://localhost:8080/","height":371},"execution":{"iopub.status.busy":"2023-11-04T09:40:40.021254Z","iopub.execute_input":"2023-11-04T09:40:40.021524Z","iopub.status.idle":"2023-11-04T09:40:44.683719Z","shell.execute_reply.started":"2023-11-04T09:40:40.021502Z","shell.execute_reply":"2023-11-04T09:40:44.682830Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"dataset:  999000\ndataset:  (array([[[1., 2., 2., 3., 3., 2.],\n        [1., 3., 3., 1., 1., 3.],\n        [1., 3., 3., 3., 3., 2.],\n        [3., 1., 2., 1., 1., 1.],\n        [1., 1., 3., 2., 2., 2.]],\n\n       [[2., 1., 3., 2., 3., 2.],\n        [1., 3., 3., 1., 1., 3.],\n        [3., 1., 3., 3., 3., 2.],\n        [1., 3., 2., 1., 1., 1.],\n        [1., 1., 3., 2., 2., 2.]],\n\n       [[2., 1., 3., 2., 3., 2.],\n        [1., 3., 3., 3., 1., 3.],\n        [3., 1., 3., 1., 3., 2.],\n        [1., 3., 2., 1., 1., 1.],\n        [1., 1., 3., 2., 2., 2.]],\n\n       [[0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0.]],\n\n       [[2., 1., 3., 1., 3., 2.],\n        [1., 3., 3., 2., 1., 3.],\n        [3., 1., 3., 3., 3., 2.],\n        [1., 3., 2., 1., 1., 1.],\n        [1., 1., 3., 2., 2., 2.]],\n\n       [[1., 2., 1., 3., 2., 3.],\n        [1., 3., 1., 3., 2., 3.],\n        [1., 3., 2., 3., 2., 3.],\n        [3., 3., 3., 1., 1., 1.],\n        [1., 1., 1., 2., 2., 2.]]], dtype=float32), array([1., 0., 0., 0.], dtype=float32))\ntestset:  1000\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchsummary import summary\nfrom torchvision.models import resnet18, resnet34, resnet50, resnext50_32x4d\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        num_input_channel = 6\n        num_classes = 4\n        resnet = resnet18()\n        resnet.conv1 = nn.Conv2d(num_input_channel, 64, kernel_size=7, stride=2, padding=3,bias=False)\n        resnet.fc = nn.Linear(512, num_classes) # resnet18 or 34\n#         resnet.fc = nn.Linear(2048, num_classes) # resnet50\n        self.resnet = resnet\n    def forward(self, x):\n        x = F.interpolate(x, size=None, scale_factor=2, mode='nearest')\n        x = self.resnet(x)\n        return x\n\nmodel = Net()\n# for i, param in enumerate(model.parameters()):\n#     param.requires_grad = True if i >= 0 else False\n# #     param.requires_grad = True if i >= 45 else False\n#     print(len(param), param.requires_grad)\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(\"device: \", device)\nmodel = model.to(device)\n# print(summary(model, (6, 5, 6)))\n\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=200, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(testset, batch_size=200, shuffle=True)\n\ncriterion = nn.CrossEntropyLoss()\n# optimizer = optim.SGD(model.parameters(), lr=0.01)\n# optimizer = optim.SGD(model.parameters(), lr=0.01,\n#                       momentum=0.9, weight_decay=0.0001)\noptimizer = optim.Adam(model.parameters())\n\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\n\nimport datetime\n\ndef train(epoch):\n    total_loss = 0\n    total_size = 0\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        total_loss += loss.item()\n        total_size += data.size(0)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 100 == 0:\n            now = datetime.datetime.now()\n            print('[{}] Train Epoch: {} [{}/{} ({:.0f}%)]\\tAverage loss: {:.6f}'.format(\n                now,\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), total_loss / total_size))\n            writer.add_scalar('Loss/train', total_loss / total_size, epoch)\ndef test(epoch):\n    total_loss = 0\n    total_size = 0\n    model.eval()\n    for batch_idx, (data, target) in enumerate(test_loader):\n        data, target = data.to(device), target.to(device)\n        output = model(data)\n        loss = criterion(output, target)\n        total_loss += loss.item()\n        total_size += data.size(0)\n        if batch_idx % 100 == 0:\n            now = datetime.datetime.now()\n            print('[{}] Test Epoch: {} [{}/{} ({:.0f}%)]\\tAverage loss: {:.6f}'.format(\n                now,\n                epoch, batch_idx * len(data), len(test_loader.dataset),\n                100. * batch_idx / len(test_loader), total_loss / total_size))\n            writer.add_scalar('Loss/test', total_loss / total_size, epoch)\n            break\n\nfor epoch in range(1, 10 + 1):\n    train(epoch)\n    test(epoch)","metadata":{"id":"JyXo_fAOkEey","outputId":"f789fc07-ffbb-4cdf-89ba-bc38d386830d","execution":{"iopub.status.busy":"2023-11-04T09:40:44.684757Z","iopub.execute_input":"2023-11-04T09:40:44.685120Z","iopub.status.idle":"2023-11-04T09:49:14.296960Z","shell.execute_reply.started":"2023-11-04T09:40:44.685094Z","shell.execute_reply":"2023-11-04T09:49:14.295822Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"device:  cuda\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"[2023-11-04 09:41:04.348088] Train Epoch: 1 [0/999000 (0%)]\tAverage loss: 0.007879\n[2023-11-04 09:41:13.634095] Train Epoch: 1 [20000/999000 (2%)]\tAverage loss: 0.004611\n[2023-11-04 09:41:22.960701] Train Epoch: 1 [40000/999000 (4%)]\tAverage loss: 0.004416\n[2023-11-04 09:41:32.303521] Train Epoch: 1 [60000/999000 (6%)]\tAverage loss: 0.004324\n[2023-11-04 09:41:41.629967] Train Epoch: 1 [80000/999000 (8%)]\tAverage loss: 0.004252\n[2023-11-04 09:41:50.959323] Train Epoch: 1 [100000/999000 (10%)]\tAverage loss: 0.004212\n[2023-11-04 09:42:00.288648] Train Epoch: 1 [120000/999000 (12%)]\tAverage loss: 0.004171\n[2023-11-04 09:42:09.611418] Train Epoch: 1 [140000/999000 (14%)]\tAverage loss: 0.004135\n[2023-11-04 09:42:18.936466] Train Epoch: 1 [160000/999000 (16%)]\tAverage loss: 0.004100\n[2023-11-04 09:42:28.253949] Train Epoch: 1 [180000/999000 (18%)]\tAverage loss: 0.004073\n[2023-11-04 09:42:37.584780] Train Epoch: 1 [200000/999000 (20%)]\tAverage loss: 0.004049\n[2023-11-04 09:42:46.911004] Train Epoch: 1 [220000/999000 (22%)]\tAverage loss: 0.004025\n[2023-11-04 09:42:56.228862] Train Epoch: 1 [240000/999000 (24%)]\tAverage loss: 0.004002\n[2023-11-04 09:43:05.550418] Train Epoch: 1 [260000/999000 (26%)]\tAverage loss: 0.003979\n[2023-11-04 09:43:14.880564] Train Epoch: 1 [280000/999000 (28%)]\tAverage loss: 0.003957\n[2023-11-04 09:43:24.213377] Train Epoch: 1 [300000/999000 (30%)]\tAverage loss: 0.003937\n[2023-11-04 09:43:33.530172] Train Epoch: 1 [320000/999000 (32%)]\tAverage loss: 0.003918\n[2023-11-04 09:43:42.840226] Train Epoch: 1 [340000/999000 (34%)]\tAverage loss: 0.003902\n[2023-11-04 09:43:52.157580] Train Epoch: 1 [360000/999000 (36%)]\tAverage loss: 0.003888\n[2023-11-04 09:44:01.469486] Train Epoch: 1 [380000/999000 (38%)]\tAverage loss: 0.003874\n[2023-11-04 09:44:10.787222] Train Epoch: 1 [400000/999000 (40%)]\tAverage loss: 0.003861\n[2023-11-04 09:44:20.119150] Train Epoch: 1 [420000/999000 (42%)]\tAverage loss: 0.003848\n[2023-11-04 09:44:29.467560] Train Epoch: 1 [440000/999000 (44%)]\tAverage loss: 0.003835\n[2023-11-04 09:44:38.837500] Train Epoch: 1 [460000/999000 (46%)]\tAverage loss: 0.003831\n[2023-11-04 09:44:48.188754] Train Epoch: 1 [480000/999000 (48%)]\tAverage loss: 0.003822\n[2023-11-04 09:44:57.545428] Train Epoch: 1 [500000/999000 (50%)]\tAverage loss: 0.003811\n[2023-11-04 09:45:06.905021] Train Epoch: 1 [520000/999000 (52%)]\tAverage loss: 0.003802\n[2023-11-04 09:45:16.257882] Train Epoch: 1 [540000/999000 (54%)]\tAverage loss: 0.003792\n[2023-11-04 09:45:25.613328] Train Epoch: 1 [560000/999000 (56%)]\tAverage loss: 0.003783\n[2023-11-04 09:45:34.974208] Train Epoch: 1 [580000/999000 (58%)]\tAverage loss: 0.003774\n[2023-11-04 09:45:44.314409] Train Epoch: 1 [600000/999000 (60%)]\tAverage loss: 0.003767\n[2023-11-04 09:45:53.648415] Train Epoch: 1 [620000/999000 (62%)]\tAverage loss: 0.003757\n[2023-11-04 09:46:02.994291] Train Epoch: 1 [640000/999000 (64%)]\tAverage loss: 0.003750\n[2023-11-04 09:46:12.328569] Train Epoch: 1 [660000/999000 (66%)]\tAverage loss: 0.003741\n[2023-11-04 09:46:21.666900] Train Epoch: 1 [680000/999000 (68%)]\tAverage loss: 0.003733\n[2023-11-04 09:46:31.002536] Train Epoch: 1 [700000/999000 (70%)]\tAverage loss: 0.003726\n[2023-11-04 09:46:40.345070] Train Epoch: 1 [720000/999000 (72%)]\tAverage loss: 0.003718\n[2023-11-04 09:46:49.686717] Train Epoch: 1 [740000/999000 (74%)]\tAverage loss: 0.003710\n[2023-11-04 09:46:59.028289] Train Epoch: 1 [760000/999000 (76%)]\tAverage loss: 0.003703\n[2023-11-04 09:47:08.350954] Train Epoch: 1 [780000/999000 (78%)]\tAverage loss: 0.003697\n[2023-11-04 09:47:17.699350] Train Epoch: 1 [800000/999000 (80%)]\tAverage loss: 0.003690\n[2023-11-04 09:47:27.042851] Train Epoch: 1 [820000/999000 (82%)]\tAverage loss: 0.003684\n[2023-11-04 09:47:36.360066] Train Epoch: 1 [840000/999000 (84%)]\tAverage loss: 0.003680\n[2023-11-04 09:47:45.678744] Train Epoch: 1 [860000/999000 (86%)]\tAverage loss: 0.003674\n[2023-11-04 09:47:55.005397] Train Epoch: 1 [880000/999000 (88%)]\tAverage loss: 0.003669\n[2023-11-04 09:48:04.329296] Train Epoch: 1 [900000/999000 (90%)]\tAverage loss: 0.003664\n[2023-11-04 09:48:13.644937] Train Epoch: 1 [920000/999000 (92%)]\tAverage loss: 0.003659\n[2023-11-04 09:48:22.958005] Train Epoch: 1 [940000/999000 (94%)]\tAverage loss: 0.003655\n[2023-11-04 09:48:32.280983] Train Epoch: 1 [960000/999000 (96%)]\tAverage loss: 0.003650\n[2023-11-04 09:48:41.589300] Train Epoch: 1 [980000/999000 (98%)]\tAverage loss: 0.003646\n[2023-11-04 09:48:50.454783] Test Epoch: 1 [0/1000 (0%)]\tAverage loss: 0.003278\n[2023-11-04 09:48:50.547146] Train Epoch: 2 [0/999000 (0%)]\tAverage loss: 0.003365\n[2023-11-04 09:48:59.862359] Train Epoch: 2 [20000/999000 (2%)]\tAverage loss: 0.003371\n[2023-11-04 09:49:09.192755] Train Epoch: 2 [40000/999000 (4%)]\tAverage loss: 0.003382\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 88\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     test(epoch)\n","Cell \u001b[0;32mIn[6], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     51\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m---> 53\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     54\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     55\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(data)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"torch.save(model, 'model_puzz_ressnet.pth')","metadata":{"id":"M9jgIDCafcTb","execution":{"iopub.status.busy":"2023-11-04T09:49:17.919987Z","iopub.execute_input":"2023-11-04T09:49:17.920368Z","iopub.status.idle":"2023-11-04T09:49:18.016739Z","shell.execute_reply.started":"2023-11-04T09:49:17.920338Z","shell.execute_reply":"2023-11-04T09:49:18.015764Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/kaggle/input/puzz-resnet-weight/model_puzz_ressnet.pth', map_location=torch.device('cpu'))","metadata":{"id":"aQLxwe-jfcTb","execution":{"iopub.status.busy":"2023-11-04T09:49:14.299461Z","iopub.status.idle":"2023-11-04T09:49:14.299819Z","shell.execute_reply.started":"2023-11-04T09:49:14.299629Z","shell.execute_reply":"2023-11-04T09:49:14.299645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.special import softmax\nmodel.eval()\n\ninfer_board = PuzzBoard()\ntmp_board = infer_board.reset().ravel()\nstart = tmp_board.reshape([5,6])\nmatrix = npUint8([[7 , 19, 10, 22, 13, 25],\n                         [ 8, 20, 11, 23, 14, 26],\n                         [ 9, 21, 12, 24, 15, 27],\n                         [28, 29, 30, 4, 5, 6],\n                         [1, 2, 3, 16, 17, 18]]).ravel() - 1\nend = np.sort(tmp_board)[matrix].reshape([5,6])\nprint(start)\nprint(end)\ninfer_board.render()\nfor i in range(500):\n\n    data = np_float([np_float(np.concatenate([npUint8([start]),infer_board.step(peek=True)[1],npUint8([end])]))])\n    action = model(torch.from_numpy(data).to(device)).tolist()[0]\n    np.set_printoptions(suppress=True, precision=2, floatmode=\"fixed\")\n#     print(softmax(action))\n#     print(action.index(max(action)))\n    infer_board.step(force_action = action.index(max(action)))\n\nprint(\"step: \", i)\ninfer_board.render()","metadata":{"id":"JcpS0jdVkEey","outputId":"3844a6cf-480f-43c2-8a8b-6e5287c90f2f","execution":{"iopub.status.busy":"2023-11-04T09:53:44.946413Z","iopub.execute_input":"2023-11-04T09:53:44.946798Z","iopub.status.idle":"2023-11-04T09:53:46.662223Z","shell.execute_reply.started":"2023-11-04T09:53:44.946766Z","shell.execute_reply":"2023-11-04T09:53:46.661286Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[[2 3 2 1 1 2]\n [1 2 3 2 2 3]\n [2 2 3 1 3 1]\n [2 1 2 1 3 2]\n [3 3 2 2 1 3]]\n[[1 2 2 3 2 3]\n [1 2 2 3 2 3]\n [2 2 2 3 2 3]\n [3 3 3 1 1 1]\n [1 1 1 2 2 2]]\n\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\n\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\n\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\nstep:  499\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n\u001b[34m●\u001b[0m\u001b[32m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\u001b[31m●\u001b[0m\n\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"3gEB-_MTfcTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}