{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Initialize\n!git clone --recursive https://github.com/mitosagi/puzzdra-nnsolver\n%cd /kaggle/working/puzzdra-nnsolver\n!pip install --log=pip_log -e .","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-03T15:45:27.093747Z","iopub.execute_input":"2023-11-03T15:45:27.094194Z","iopub.status.idle":"2023-11-03T15:45:56.010772Z","shell.execute_reply.started":"2023-11-03T15:45:27.094144Z","shell.execute_reply":"2023-11-03T15:45:56.009638Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Cloning into 'puzzdra-nnsolver'...\nremote: Enumerating objects: 290, done.\u001b[K\nremote: Counting objects: 100% (45/45), done.\u001b[K\nremote: Compressing objects: 100% (45/45), done.\u001b[K\nremote: Total 290 (delta 26), reused 0 (delta 0), pack-reused 245\u001b[K\nReceiving objects: 100% (290/290), 8.30 MiB | 21.14 MiB/s, done.\nResolving deltas: 100% (168/168), done.\nSubmodule 'extern/pybind11' (https://github.com/pybind/pybind11) registered for path 'extern/pybind11'\nCloning into '/kaggle/working/puzzdra-nnsolver/puzzdra-nnsolver/puzzdra-nnsolver/extern/pybind11'...\nremote: Enumerating objects: 27236, done.        \nremote: Counting objects: 100% (8/8), done.        \nremote: Compressing objects: 100% (6/6), done.        \nremote: Total 27236 (delta 1), reused 4 (delta 1), pack-reused 27228        \nReceiving objects: 100% (27236/27236), 10.39 MiB | 21.98 MiB/s, done.\nResolving deltas: 100% (19162/19162), done.\nSubmodule path 'extern/pybind11': checked out '8de7772cc72daca8e947b79b83fea46214931604'\n/kaggle/working/puzzdra-nnsolver\nObtaining file:///kaggle/working/puzzdra-nnsolver\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nInstalling collected packages: Puzzpy\n  Attempting uninstall: Puzzpy\n    Found existing installation: Puzzpy 1.0\n    Uninstalling Puzzpy-1.0:\n      Successfully uninstalled Puzzpy-1.0\n  Running setup.py develop for Puzzpy\nSuccessfully installed Puzzpy-1.0\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"('multichannel_resnet.py', <http.client.HTTPMessage at 0x7e423df1b250>)"},"metadata":{}}]},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-11-03T17:47:19.344836Z","iopub.execute_input":"2023-11-03T17:47:19.345816Z","iopub.status.idle":"2023-11-03T17:47:31.121356Z","shell.execute_reply.started":"2023-11-03T17:47:19.345770Z","shell.execute_reply":"2023-11-03T17:47:31.120336Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport numpy as np\nfrom puzzpy import PuzzTable\n\ndrop_color = 3\nboard_width = 6\nboard_height = 5\n\nclass bcolors:\n    HEADER = '\\033[95m'\n    OKBLUE = '\\033[94m'\n    OKCYAN = '\\033[96m'\n    OKGREEN = '\\033[92m'\n    WARNING = '\\033[93m'\n    FAIL = '\\033[91m'\n    ENDC = '\\033[0m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'\n    BLACK = '\\033[30m'\n    RED = '\\033[31m'\n    GREEN = '\\033[32m'\n    YELLOW = '\\033[33m'\n    BLUE = '\\033[34m'\n    MAGENTA = '\\033[35m'\n    CYAN = '\\033[36m'\n\ndef npUint8(array):\n    return np.array(array, dtype=np.uint8)\n\nclass PuzzBoard():        \n    def reset(self):\n        self.prev_action = 255\n        \n        while True:\n            self.table = PuzzTable(\"\".join([str(random.randrange(drop_color)) for i in range(board_width*board_height)]), random.randrange(board_width), random.randrange(board_height), 50) # n色陣　操作時間m秒\n            if self.table.eval_otoshi() == 0:\n                break\n\n        return npUint8(self.table.get_table())\n    \n    def step(self):\n        next_tables = self.table.next_tables()\n        valid_actions = [action for action, table in enumerate(next_tables) if table.get_table()[0][0] != 127 and abs(action - self.prev_action) != 2]\n        self.prev_action = random.choice(valid_actions)\n        self.table = next_tables[self.prev_action]\n        \n        return self.prev_action, npUint8([(npUint8(table.get_table()) if action in valid_actions else np.zeros_like(npUint8(table.get_table()))) for action, table in enumerate(next_tables)])\n    def render(self):\n        tcolor = [bcolors.RED, bcolors.BLUE, bcolors.GREEN, bcolors.MAGENTA, bcolors.YELLOW, bcolors.BLACK]\n        start = self.table.get_XY_as_table()\n        table = self.table.get_table()\n        for i in range(board_height):\n            for j in range(board_width):\n                if start[i][j] == 1:\n                    print(tcolor[table[i][j]-1]  +  bcolors.UNDERLINE + \"●\" + bcolors.ENDC, end='')\n                else:\n                    print(tcolor[table[i][j]-1]  + \"●\" + bcolors.ENDC, end='')\n            print('')","metadata":{"execution":{"iopub.status.busy":"2023-11-03T15:03:25.146486Z","iopub.execute_input":"2023-11-03T15:03:25.146790Z","iopub.status.idle":"2023-11-03T15:03:25.167912Z","shell.execute_reply.started":"2023-11-03T15:03:25.146762Z","shell.execute_reply":"2023-11-03T15:03:25.167175Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"env = PuzzBoard()\nobs = env.reset()\nenv.render()\n\nn_steps = 3\n\nfor step in range(n_steps):\n    print(\"Step {}\".format(step + 1))\n    action, obs = env.step()\n    with np.printoptions(threshold=np.inf):\n        print(\"action: \", action)\n#         print(obs)\n        env.render()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T15:03:25.169153Z","iopub.execute_input":"2023-11-03T15:03:25.169410Z","iopub.status.idle":"2023-11-03T15:03:25.199413Z","shell.execute_reply.started":"2023-11-03T15:03:25.169387Z","shell.execute_reply":"2023-11-03T15:03:25.198455Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m\u001b[4m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\nStep 1\naction:  1\n\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m\u001b[4m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\nStep 2\naction:  1\n\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\nStep 3\naction:  2\n\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\n\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\n\u001b[31m●\u001b[0m\u001b[31m\u001b[4m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[32m●\u001b[0m\n\u001b[32m●\u001b[0m\u001b[34m●\u001b[0m\u001b[31m●\u001b[0m\u001b[32m●\u001b[0m\u001b[32m●\u001b[0m\u001b[31m●\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# %%timeit # num_step=50のとき1_000サンプル生成に3.41sかかる。目標の100_000サンプル生成は６分弱。\ndef make_data(num_step):\n    env = PuzzBoard()\n    start = env.reset()\n\n    sample_step = random.randrange(1, num_step + 1)\n\n    for i in range(sample_step):\n        answer, obs = env.step()\n    sample_obs = obs\n\n    for i in range(num_step - sample_step):\n        answer, obs = env.step()\n    end = obs[answer]\n        \n    return np.concatenate([npUint8([start]),sample_obs,npUint8([end])]), answer\n\nfrom torch.utils.data import Dataset\n\nclass PuzzDataSet(Dataset):\n    def __init__(self, length):\n        samples = [make_data(10) for i in range(length)]\n        self.data = np.array(([sample[0] for sample in samples]), dtype=np.float32)\n        self.labels = np.array(([sample[1] for sample in samples]), dtype=np.float32)\n        \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        return self.data[idx], self.labels[idx]\n\nclass RandomPuzzDataSet(Dataset):        \n    def __len__(self):\n        return 1_000_000\n    \n    def __getitem__(self, idx):\n        data, label = make_data(10)\n        return np.array(data, dtype=np.float32),np.array(label, dtype=np.float32)\n\n%time dataset = PuzzDataSet(100_000)\n# dataset = RandomPuzzDataSet()\ntestset = PuzzDataSet(1_000)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T17:28:07.499071Z","iopub.execute_input":"2023-11-03T17:28:07.500028Z","iopub.status.idle":"2023-11-03T17:32:17.729433Z","shell.execute_reply.started":"2023-11-03T17:28:07.499990Z","shell.execute_reply":"2023-11-03T17:32:17.728540Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"CPU times: user 4min 7s, sys: 118 ms, total: 4min 7s\nWall time: 4min 7s\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchsummary import summary\nimport multichannel_resnet\nfrom multichannel_resnet import get_arch as Resnet\nfrom torchvision.models import resnet18\n\nclass CNN(nn.Module):\n    \n    def __init__(self):\n        super(CNN, self).__init__()\n        \n        self.convlayer1 = nn.Sequential(\n            nn.Conv2d(6, 32, 3,padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.convlayer2 = nn.Sequential(\n            nn.Conv2d(32,64,3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.fc1 = nn.Linear(256,600)\n        self.drop = nn.Dropout2d(0.25)\n        self.fc2 = nn.Linear(600, 120)\n        self.fc3 = nn.Linear(120, 1)\n        \n    def forward(self, x):\n        x = F.interpolate(x, size=None, scale_factor=2, mode='nearest')\n        x = self.convlayer1(x)\n        x = self.convlayer2(x)\n        x = x.view(-1,64*2*2)\n        x = self.fc1(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.fc3(x)\n        \n        return x\n\n    \nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        num_input_channel = 6\n        num_classes = 1\n        resnet = resnet50()\n        resnet.conv1 = nn.Conv2d(num_input_channel, 64, kernel_size=7, stride=2, padding=3,bias=False)\n        resnet.fc = nn.Linear(512 * 4, num_classes)\n        self.resnet = resnet\n    def forward(self, x):\n        x = self.resnet(F.interpolate(x, size=None, scale_factor=2, mode='nearest'))\n        return x\n# model = Net()\nmodel = CNN()\ndevice = torch.device('cuda')\nmodel = model.to(device)\nprint(summary(model, (6, 5, 6)))\n\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=200, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(testset, batch_size=200, shuffle=True)\n\ncriterion = nn.MSELoss()\n# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\noptimizer = optim.SGD(model.parameters(), lr=0.0005)\n\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\n\nimport datetime\n\ndef train(epoch):\n    total_loss = 0\n    total_size = 0\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        output = torch.flatten(output)\n        loss = criterion(output, target)\n        total_loss += loss.item()\n        total_size += data.size(0)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 100 == 0:\n            now = datetime.datetime.now()\n            print('[{}] Train Epoch: {} [{}/{} ({:.0f}%)]\\tAverage loss: {:.6f}'.format(\n                now,\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), total_loss / total_size))\n            writer.add_scalar('Loss/train', total_loss / total_size, epoch)\ndef test(epoch):\n    total_loss = 0\n    total_size = 0\n    model.eval()\n    for batch_idx, (data, target) in enumerate(test_loader):\n        data, target = data.to(device), target.to(device)\n        output = model(data)\n        output = torch.flatten(output)\n        loss = criterion(output, target)\n        total_loss += loss.item()\n        total_size += data.size(0)\n        if batch_idx % 100 == 0:\n            now = datetime.datetime.now()\n            print('[{}] Test Epoch: {} [{}/{} ({:.0f}%)]\\tAverage loss: {:.6f}'.format(\n                now,\n                epoch, batch_idx * len(data), len(test_loader.dataset),\n                100. * batch_idx / len(test_loader), total_loss / total_size))\n            writer.add_scalar('Loss/test', total_loss / total_size, epoch)\n            break\n    \nfor epoch in range(1, 50 + 1):\n    train(epoch)\n    test(epoch)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:07:26.082358Z","iopub.execute_input":"2023-11-03T18:07:26.083097Z","iopub.status.idle":"2023-11-03T18:07:26.282179Z","shell.execute_reply.started":"2023-11-03T18:07:26.083065Z","shell.execute_reply":"2023-11-03T18:07:26.280823Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 32, 10, 12]           1,760\n       BatchNorm2d-2           [-1, 32, 10, 12]              64\n              ReLU-3           [-1, 32, 10, 12]               0\n         MaxPool2d-4             [-1, 32, 5, 6]               0\n            Conv2d-5             [-1, 64, 3, 4]          18,496\n       BatchNorm2d-6             [-1, 64, 3, 4]             128\n              ReLU-7             [-1, 64, 3, 4]               0\n         MaxPool2d-8             [-1, 64, 1, 2]               0\n            Linear-9                  [-1, 600]         154,200\n        Dropout2d-10                  [-1, 600]               0\n           Linear-11                  [-1, 120]          72,120\n           Linear-12                    [-1, 1]             121\n================================================================\nTotal params: 246,889\nTrainable params: 246,889\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.12\nParams size (MB): 0.94\nEstimated Total Size (MB): 1.07\n----------------------------------------------------------------\nNone\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[97], line 119\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 119\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     test(epoch)\n","Cell \u001b[0;32mIn[97], line 86\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     84\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     85\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(output)\n\u001b[0;32m---> 86\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     88\u001b[0m total_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3292\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (200) at non-singleton dimension 0"],"ename":"RuntimeError","evalue":"The size of tensor a (100) must match the size of tensor b (200) at non-singleton dimension 0","output_type":"error"}]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir logs","metadata":{"execution":{"iopub.status.busy":"2023-11-03T16:55:21.945931Z","iopub.execute_input":"2023-11-03T16:55:21.946933Z","iopub.status.idle":"2023-11-03T16:55:29.474311Z","shell.execute_reply.started":"2023-11-03T16:55:21.946895Z","shell.execute_reply":"2023-11-03T16:55:29.473271Z"},"trusted":true},"execution_count":60,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n      <iframe id=\"tensorboard-frame-d23cd20efc70a86e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-d23cd20efc70a86e\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}