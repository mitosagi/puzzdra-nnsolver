{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "puzz.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOrHwyqp3F6ITe03KgPn63E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitosagi/puzzdra-nnsolver/blob/master/puzz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrk7ju8ZSpq1"
      },
      "source": [
        "## 初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-syCb8S5ijR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1982b7d-fe7e-4ea7-c4f4-bb90ad7dabac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MinijqIGMKzp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1845433-65ff-499e-ebe7-2e94cda7b595"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/User/python/puzzdra-nnsolver /content/puzzdra-nnsolver\n",
        "%cd /content/puzzdra-nnsolver\n",
        "!pip install --log=pip_log -e .\n",
        "!python puzz_test.py"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/puzzdra-nnsolver\n",
            "Obtaining file:///content/puzzdra-nnsolver\n",
            "Installing collected packages: Puzzpy\n",
            "  Running setup.py develop for Puzzpy\n",
            "Successfully installed Puzzpy\n",
            "512621\n",
            "215133\n",
            "432116\n",
            "125133\n",
            "523161\n",
            "[[5, 1, 2, 6, 2, 1], [2, 5, 1, 1, 3, 3], [4, 3, 2, 1, 1, 6], [1, 2, 5, 1, 3, 3], [5, 2, 3, 1, 6, 1]]\n",
            "[[0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
            "[[5, 1, 5, 6, 2, 1], [2, 1, 2, 1, 3, 3], [4, 3, 2, 1, 1, 6], [1, 2, 5, 1, 3, 3], [5, 2, 3, 1, 6, 1]]\n",
            "[[0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
            "[[5, 1, 2, 6, 2, 1], [2, 1, 2, 1, 3, 3], [4, 3, 5, 1, 1, 6], [1, 2, 5, 1, 3, 3], [5, 2, 3, 1, 6, 1]]\n",
            "[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
            "[[5, 1, 2, 6, 2, 1], [2, 1, 1, 5, 3, 3], [4, 3, 2, 1, 1, 6], [1, 2, 5, 1, 3, 3], [5, 2, 3, 1, 6, 1]]\n",
            "[[0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
            "10\n",
            "164434\n",
            "512634\n",
            "246665\n",
            "123313\n",
            "256254\n",
            "<class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3eBhEr5u8xf",
        "outputId": "d07c120b-84e5-4615-c63a-3f1252231723",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install git+https://github.com/DLR-RM/stable-baselines3"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/DLR-RM/stable-baselines3\n",
            "  Cloning https://github.com/DLR-RM/stable-baselines3 to /tmp/pip-req-build-rsnzlrws\n",
            "  Running command git clone -q https://github.com/DLR-RM/stable-baselines3 /tmp/pip-req-build-rsnzlrws\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.1.0a11) (0.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.1.0a11) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.1.0a11) (1.9.0+cu102)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.1.0a11) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.1.0a11) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.1.0a11) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->stable-baselines3==1.1.0a11) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->stable-baselines3==1.1.0a11) (1.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->stable-baselines3==1.1.0a11) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3==1.1.0a11) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3==1.1.0a11) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.1.0a11) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.1.0a11) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.1.0a11) (2.4.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->stable-baselines3==1.1.0a11) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->stable-baselines3==1.1.0a11) (1.15.0)\n",
            "Building wheels for collected packages: stable-baselines3\n",
            "  Building wheel for stable-baselines3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stable-baselines3: filename=stable_baselines3-1.1.0a11-cp37-none-any.whl size=160811 sha256=b01c29df8a774074d8634a8c4a06460807e64e954e8c5b87a511248378052551\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-75kq94fm/wheels/cf/89/6b/cd4b89427eb5ff0858bcba73911088d606c59eb3a97290b1bb\n",
            "Successfully built stable-baselines3\n",
            "Installing collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-1.1.0a11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivAHcGIGSmEM"
      },
      "source": [
        "## サンプルの実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwK7sQOIOe67"
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "\n",
        "class GoLeftEnv(gym.Env):\n",
        "  \"\"\"\n",
        "  Gymのインターフェースに従うカスタム環境\n",
        "  エージェントが常に左に行くことを学ぶ環境\n",
        "  \"\"\"\n",
        "  # ColabのためGUIを実装できない\n",
        "  metadata = {'render.modes': ['console']}\n",
        "\n",
        "  # 定数を定義\n",
        "  LEFT = 0\n",
        "  RIGHT = 1\n",
        "\n",
        "  def __init__(self, grid_size=10):\n",
        "    super(GoLeftEnv, self).__init__()\n",
        "\n",
        "    # 1Dグリッドのサイズ\n",
        "    self.grid_size = grid_size\n",
        "\n",
        "    # グリッドの右側でエージェントを初期化\n",
        "    self.agent_pos = grid_size - 1\n",
        "\n",
        "    # 行動空間と状態空間を定義\n",
        "    # gym.spacesオブジェクトでなければならない\n",
        "    # 離散行動を使用する場合の例には、左と右の2つがある\n",
        "    n_actions = 2\n",
        "    self.action_space = spaces.Discrete(n_actions)\n",
        "\n",
        "    # 状態はエージェントの座標になる\n",
        "    # Discrete空間とBox空間の両方で表現できる\n",
        "    self.observation_space = spaces.Box(low=0, high=self.grid_size,\n",
        "                                       shape=(1,), dtype=np.float32)\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"\n",
        "    【重要】観測はnumpy配列でなければならない\n",
        "    :return: (np.array)\n",
        "    \"\"\"\n",
        "    # グリッドの右側でエージェントを初期化\n",
        "    self.agent_pos = self.grid_size - 1\n",
        "\n",
        "    # float32に変換してより一般的なものにします（連続行動を使用する場合）\n",
        "    return np.array(self.agent_pos).astype(np.float32)\n",
        "\n",
        "  def step(self, action):\n",
        "    if action == self.LEFT:\n",
        "      self.agent_pos -= 1\n",
        "    elif action == self.RIGHT:\n",
        "      self.agent_pos += 1\n",
        "    else:\n",
        "      raise ValueError(\"Received invalid action={} which is not part of the action space\".format(action))\n",
        "\n",
        "    # グリッドの境界を表現\n",
        "    self.agent_pos = np.clip(self.agent_pos, 0, self.grid_size)\n",
        "\n",
        "    # グリッドの左側にいるか\n",
        "    done = self.agent_pos == 0\n",
        "\n",
        "    # ゴールを除くすべての場所で0の報酬\n",
        "    reward = 1 if self.agent_pos == 0 else 0\n",
        "\n",
        "    # 必要に応じて情報を渡すことができるが、現在は未使用\n",
        "    info = {}\n",
        "\n",
        "    return np.array(self.agent_pos).astype(np.float32), reward, done, info\n",
        "\n",
        "  def render(self, mode='console', close=False):\n",
        "    if mode != 'console':\n",
        "      raise NotImplementedError()\n",
        "\n",
        "    # エージェントは「x」、残りは「.」として表現\n",
        "    print(\".\" * self.agent_pos, end=\"\")\n",
        "    print(\"x\", end=\"\")\n",
        "    print(\".\" * (self.grid_size - self.agent_pos))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlrpB6VxS_Z0",
        "outputId": "2389d909-4385-43d8-cdba-dd926a82dd96"
      },
      "source": [
        "env = GoLeftEnv(grid_size=10)\n",
        "\n",
        "obs = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "GO_LEFT = 0\n",
        "\n",
        "# ハードコードされた最高のエージェント：常に左に行く\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  obs, reward, done, info = env.step(GO_LEFT)\n",
        "  print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render()\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".........x.\n",
            "Box(0.0, 10.0, (1,), float32)\n",
            "Discrete(2)\n",
            "0\n",
            "Step 1\n",
            "obs= 8.0 reward= 0 done= False\n",
            "........x..\n",
            "Step 2\n",
            "obs= 7.0 reward= 0 done= False\n",
            ".......x...\n",
            "Step 3\n",
            "obs= 6.0 reward= 0 done= False\n",
            "......x....\n",
            "Step 4\n",
            "obs= 5.0 reward= 0 done= False\n",
            ".....x.....\n",
            "Step 5\n",
            "obs= 4.0 reward= 0 done= False\n",
            "....x......\n",
            "Step 6\n",
            "obs= 3.0 reward= 0 done= False\n",
            "...x.......\n",
            "Step 7\n",
            "obs= 2.0 reward= 0 done= False\n",
            "..x........\n",
            "Step 8\n",
            "obs= 1.0 reward= 0 done= False\n",
            ".x.........\n",
            "Step 9\n",
            "obs= 0.0 reward= 1 done= True\n",
            "x..........\n",
            "Goal reached! reward= 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIbo58d5TBwn"
      },
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "# 環境の生成\n",
        "env = GoLeftEnv(grid_size=10)\n",
        "\n",
        "# 環境のラップ\n",
        "env = Monitor(env, filename=None, allow_early_resets=True)\n",
        "env = DummyVecEnv([lambda: env])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTgpCUYXTPis",
        "outputId": "98afb86d-c5f9-4872-a081-8a907b7ccbf5"
      },
      "source": [
        "# エージェントの訓練\n",
        "model = PPO('MlpPolicy', env, verbose=1).learn(5000)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 99.2     |\n",
            "|    ep_rew_mean     | 1        |\n",
            "| time/              |          |\n",
            "|    fps             | 901      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 63.3        |\n",
            "|    ep_rew_mean          | 1           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 688         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 5           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018118575 |\n",
            "|    clip_fraction        | 0.214       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.677      |\n",
            "|    explained_variance   | -1.2        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0412     |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.016      |\n",
            "|    value_loss           | 0.011       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 28.9       |\n",
            "|    ep_rew_mean          | 1          |\n",
            "| time/                   |            |\n",
            "|    fps                  | 657        |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 9          |\n",
            "|    total_timesteps      | 6144       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02103132 |\n",
            "|    clip_fraction        | 0.375      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.621     |\n",
            "|    explained_variance   | 0.32       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0785    |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.0475    |\n",
            "|    value_loss           | 0.0151     |\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR69cZGVTQ00",
        "outputId": "6342d1ac-ccaa-4ebe-d9cc-933207f29cfb"
      },
      "source": [
        "# 訓練済みエージェントのテスト\n",
        "obs = env.reset()\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  action, _ = model.predict(obs, deterministic=True)\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  print(\"Action: \", action)\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render(mode='console')\n",
        "  if done:\n",
        "    # VecEnvは、エピソード完了に遭遇すると自動的にリセットされることに注意\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1\n",
            "Action:  [0]\n",
            "obs= [[8.]] reward= [0.] done= [False]\n",
            "........x..\n",
            "Step 2\n",
            "Action:  [0]\n",
            "obs= [[7.]] reward= [0.] done= [False]\n",
            ".......x...\n",
            "Step 3\n",
            "Action:  [0]\n",
            "obs= [[6.]] reward= [0.] done= [False]\n",
            "......x....\n",
            "Step 4\n",
            "Action:  [0]\n",
            "obs= [[5.]] reward= [0.] done= [False]\n",
            ".....x.....\n",
            "Step 5\n",
            "Action:  [0]\n",
            "obs= [[4.]] reward= [0.] done= [False]\n",
            "....x......\n",
            "Step 6\n",
            "Action:  [0]\n",
            "obs= [[3.]] reward= [0.] done= [False]\n",
            "...x.......\n",
            "Step 7\n",
            "Action:  [0]\n",
            "obs= [[2.]] reward= [0.] done= [False]\n",
            "..x........\n",
            "Step 8\n",
            "Action:  [0]\n",
            "obs= [[1.]] reward= [0.] done= [False]\n",
            ".x.........\n",
            "Step 9\n",
            "Action:  [0]\n",
            "obs= [[9.]] reward= [1.] done= [ True]\n",
            ".........x.\n",
            "Goal reached! reward= [1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdUISRWiX4kM"
      },
      "source": [
        "## 実際の処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI2D4A-cXnQI",
        "outputId": "82d0a89d-098e-4dda-93d1-3eef83de8bc3"
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "\n",
        "from puzzpy import PuzzTable\n",
        "table = PuzzTable(10)\n",
        "table.show_table()\n",
        "for a in table.next_tables():\n",
        "    print(a.get_table())\n",
        "    print(a.get_XY_as_table())\n",
        "\n",
        "class PuzzEnv(gym.Env):\n",
        "  \"\"\"\n",
        "  パズドラの環境\n",
        "  \"\"\"\n",
        "  # ColabのためGUIを実装できない\n",
        "  metadata = {'render.modes': ['console']}\n",
        "\n",
        "  # 定数を定義\n",
        "  LEFT = 0\n",
        "  RIGHT = 1\n",
        "\n",
        "  def __init__(self):\n",
        "    super(PuzzEnv, self).__init__()\n",
        "\n",
        "    self.action_space = spaces.Discrete(5)\n",
        "\n",
        "    # 状態はエージェントの座標になる\n",
        "    # Discrete空間とBox空間の両方で表現できる\n",
        "    self.observation_space = spaces.Dict({'table': spaces.Box(low=0, high=5,\n",
        "                                       shape=(5,6), dtype=np.float32),\n",
        "                                       'start': spaces.Box(low=0, high=1,\n",
        "                                       shape=(5,6), dtype=np.float32),\n",
        "                                       'turn': spaces.Box(low=1, high=155,\n",
        "                                       shape=(1,), dtype=np.float32)})\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"\n",
        "    【重要】観測はnumpy配列でなければならない\n",
        "    :return: (np.array)\n",
        "    \"\"\"\n",
        "    self.table = PuzzTable(155)\n",
        "\n",
        "    return {'table': np.array(self.table.get_table()).astype(np.float32),\n",
        "              'start': np.array(self.table.get_XY_as_table()).astype(np.float32),\n",
        "              'turn': self.table.get_turn()}\n",
        "  def step(self, action):\n",
        "    if action == 4:\n",
        "      return {'table': np.array(self.table.get_table()).astype(np.float32),\n",
        "              'start': np.array(self.table.get_XY_as_table()).astype(np.float32),\n",
        "              'turn': self.table.get_turn()}, self.table.eval_otoshi(), True, {}\n",
        "\n",
        "    next_table = self.table.next_tables()[action]\n",
        "\n",
        "    if next_table.get_table()[0][0] == 127:\n",
        "      return {'table': np.array(self.table.get_table()).astype(np.float32),\n",
        "              'start': np.array(self.table.get_XY_as_table()).astype(np.float32),\n",
        "              'turn': self.table.get_turn()}, self.table.eval_otoshi(), True, {}\n",
        "\n",
        "    self.table = next_table\n",
        "\n",
        "    if self.table.get_turn() <= 0:\n",
        "      return {'table': np.array(self.table.get_table()).astype(np.float32),\n",
        "              'start': np.array(self.table.get_XY_as_table()).astype(np.float32),\n",
        "              'turn': self.table.get_turn()}, self.table.eval_otoshi(), True, {}\n",
        "\n",
        "    return {'table': np.array(self.table.get_table()).astype(np.float32),\n",
        "              'start': np.array(self.table.get_XY_as_table()).astype(np.float32),\n",
        "              'turn': self.table.get_turn()}, 0, False, {}\n",
        "\n",
        "  def render(self, mode='console', close=False):\n",
        "    if mode != 'console':\n",
        "      raise NotImplementedError()\n",
        "\n",
        "    self.table.show_table()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 6, 6, 6, 2, 5], [1, 2, 1, 5, 4, 5], [1, 5, 5, 5, 3, 1], [2, 2, 2, 1, 4, 3], [4, 4, 5, 4, 5, 6]]\n",
            "[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0]]\n",
            "[[2, 6, 6, 6, 2, 5], [1, 2, 1, 5, 4, 5], [1, 5, 5, 5, 3, 1], [2, 2, 2, 5, 4, 3], [4, 4, 4, 1, 5, 6]]\n",
            "[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
            "[[127, 6, 6, 6, 2, 5], [1, 2, 1, 5, 4, 5], [1, 5, 5, 5, 3, 1], [2, 2, 2, 1, 4, 3], [4, 4, 4, 5, 5, 6]]\n",
            "[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
            "[[2, 6, 6, 6, 2, 5], [1, 2, 1, 5, 4, 5], [1, 5, 5, 5, 3, 1], [2, 2, 2, 1, 4, 3], [4, 4, 4, 5, 5, 6]]\n",
            "[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Z9SliEfKci",
        "outputId": "25a9c1f6-c14b-4dd9-edf9-f242c2c25df4"
      },
      "source": [
        "env = PuzzEnv()\n",
        "\n",
        "obs = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  obs, reward, done, info = env.step(env.action_space.sample())\n",
        "  print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render()\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dict(start:Box(0.0, 1.0, (5, 6), float32), table:Box(0.0, 5.0, (5, 6), float32), turn:Box(1.0, 155.0, (1,), float32))\n",
            "Discrete(5)\n",
            "0\n",
            "Step 1\n",
            "obs= {'table': array([[3., 1., 5., 6., 5., 6.],\n",
            "       [3., 3., 5., 3., 3., 3.],\n",
            "       [3., 5., 4., 5., 4., 2.],\n",
            "       [4., 5., 4., 4., 1., 5.],\n",
            "       [3., 5., 1., 3., 3., 4.]], dtype=float32), 'start': array([[0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 1.],\n",
            "       [0., 0., 0., 0., 0., 0.]], dtype=float32), 'turn': 155} reward= 3 done= True\n",
            "Goal reached! reward= 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiOiIdZ_gvP3"
      },
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.envs.multi_input_envs import SimpleMultiObsEnv\n",
        "\n",
        "# 環境の生成\n",
        "env = PuzzEnv()\n",
        "\n",
        "# 環境のラップ\n",
        "env = Monitor(env, filename=None, allow_early_resets=True)\n",
        "#env = DummyVecEnv([lambda: env])\n",
        "env = SimpleMultiObsEnv()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_qAMMmQnTtw",
        "outputId": "becb820a-7213-4833-e27e-17d6e1e7c49e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# エージェントの訓練\n",
        "model = PPO('MultiInputPolicy', env, verbose=1).learn(100000)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 48.7     |\n",
            "|    ep_rew_mean     | -4.09    |\n",
            "| time/              |          |\n",
            "|    fps             | 652      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 43.7        |\n",
            "|    ep_rew_mean          | -3.55       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 481         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018520754 |\n",
            "|    clip_fraction        | 0.164       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | 0.00697     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.198       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.021      |\n",
            "|    value_loss           | 0.517       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 41        |\n",
            "|    ep_rew_mean          | -3.3      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 441       |\n",
            "|    iterations           | 3         |\n",
            "|    time_elapsed         | 13        |\n",
            "|    total_timesteps      | 6144      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0158609 |\n",
            "|    clip_fraction        | 0.201     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.34     |\n",
            "|    explained_variance   | 0.25      |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.269     |\n",
            "|    n_updates            | 20        |\n",
            "|    policy_gradient_loss | -0.0209   |\n",
            "|    value_loss           | 0.812     |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 27.9         |\n",
            "|    ep_rew_mean          | -1.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0091434335 |\n",
            "|    clip_fraction        | 0.101        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.488        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.34         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0113      |\n",
            "|    value_loss           | 0.828        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 27.9        |\n",
            "|    ep_rew_mean          | -1.92       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017299717 |\n",
            "|    clip_fraction        | 0.112       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.738       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.528       |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00798    |\n",
            "|    value_loss           | 0.811       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 29.9         |\n",
            "|    ep_rew_mean          | -2.15        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 411          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072749043 |\n",
            "|    clip_fraction        | 0.065        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.704        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.341        |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00327     |\n",
            "|    value_loss           | 1.05         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.3        |\n",
            "|    ep_rew_mean          | -1.97       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 408         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011389463 |\n",
            "|    clip_fraction        | 0.0921      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.26       |\n",
            "|    explained_variance   | 0.743       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.516       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00629    |\n",
            "|    value_loss           | 1.15        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.5        |\n",
            "|    ep_rew_mean          | -1.78       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 405         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009622964 |\n",
            "|    clip_fraction        | 0.0809      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.24       |\n",
            "|    explained_variance   | 0.77        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.546       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00331    |\n",
            "|    value_loss           | 1.19        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 29.9         |\n",
            "|    ep_rew_mean          | -2.16        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 402          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 45           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064792186 |\n",
            "|    clip_fraction        | 0.0821       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.21        |\n",
            "|    explained_variance   | 0.735        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.584        |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00413     |\n",
            "|    value_loss           | 1.38         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 29           |\n",
            "|    ep_rew_mean          | -2.08        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 401          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 51           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060494933 |\n",
            "|    clip_fraction        | 0.0684       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.19        |\n",
            "|    explained_variance   | 0.714        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.554        |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00372     |\n",
            "|    value_loss           | 1.38         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 31.4        |\n",
            "|    ep_rew_mean          | -2.34       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 400         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 56          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010288607 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.17       |\n",
            "|    explained_variance   | 0.671       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.01        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00866    |\n",
            "|    value_loss           | 1.47        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 27.9        |\n",
            "|    ep_rew_mean          | -1.94       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 399         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 61          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005403267 |\n",
            "|    clip_fraction        | 0.0304      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.718       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.643       |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | 0.000648    |\n",
            "|    value_loss           | 1.42        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.4        |\n",
            "|    ep_rew_mean          | -2          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 398         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 66          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010016544 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.11       |\n",
            "|    explained_variance   | 0.72        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.11        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00325    |\n",
            "|    value_loss           | 1.42        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 27.8         |\n",
            "|    ep_rew_mean          | -1.95        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 397          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 72           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041671693 |\n",
            "|    clip_fraction        | 0.0349       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.15        |\n",
            "|    explained_variance   | 0.652        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.02         |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | 0.000223     |\n",
            "|    value_loss           | 1.48         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 24.9        |\n",
            "|    ep_rew_mean          | -1.62       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 396         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007908506 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.11       |\n",
            "|    explained_variance   | 0.695       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.766       |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00697    |\n",
            "|    value_loss           | 1.44        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 29.7         |\n",
            "|    ep_rew_mean          | -2.15        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 395          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 82           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0117490655 |\n",
            "|    clip_fraction        | 0.0903       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.06        |\n",
            "|    explained_variance   | 0.686        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.703        |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00392     |\n",
            "|    value_loss           | 1.53         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 33.7         |\n",
            "|    ep_rew_mean          | -2.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 395          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 88           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076515516 |\n",
            "|    clip_fraction        | 0.0641       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.06        |\n",
            "|    explained_variance   | 0.615        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.922        |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00152     |\n",
            "|    value_loss           | 1.53         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 37.5        |\n",
            "|    ep_rew_mean          | -3.02       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 394         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 93          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008209687 |\n",
            "|    clip_fraction        | 0.0847      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0.635       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.02        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00227    |\n",
            "|    value_loss           | 1.61        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30.9         |\n",
            "|    ep_rew_mean          | -2.28        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 394          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 98           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061109914 |\n",
            "|    clip_fraction        | 0.0581       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.01        |\n",
            "|    explained_variance   | 0.458        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.672        |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00116     |\n",
            "|    value_loss           | 1.69         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 24.1        |\n",
            "|    ep_rew_mean          | -1.53       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 393         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 103         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008783661 |\n",
            "|    clip_fraction        | 0.121       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.975      |\n",
            "|    explained_variance   | 0.714       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.883       |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.00671    |\n",
            "|    value_loss           | 1.46        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 31.5       |\n",
            "|    ep_rew_mean          | -2.36      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 393        |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 109        |\n",
            "|    total_timesteps      | 43008      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01030731 |\n",
            "|    clip_fraction        | 0.086      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.972     |\n",
            "|    explained_variance   | 0.704      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.469      |\n",
            "|    n_updates            | 200        |\n",
            "|    policy_gradient_loss | 0.000254   |\n",
            "|    value_loss           | 1.49       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 35.5         |\n",
            "|    ep_rew_mean          | -2.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 392          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 114          |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055624903 |\n",
            "|    clip_fraction        | 0.0558       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.02        |\n",
            "|    explained_variance   | 0.573        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.01         |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.000814    |\n",
            "|    value_loss           | 1.61         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.2        |\n",
            "|    ep_rew_mean          | -2          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 392         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 119         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008315541 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.931      |\n",
            "|    explained_variance   | 0.635       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.626       |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.00555    |\n",
            "|    value_loss           | 1.48        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 29.1        |\n",
            "|    ep_rew_mean          | -2.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 392         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 125         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009193789 |\n",
            "|    clip_fraction        | 0.0747      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1          |\n",
            "|    explained_variance   | 0.643       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.763       |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0016     |\n",
            "|    value_loss           | 1.52        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30          |\n",
            "|    ep_rew_mean          | -2.19       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 392         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 130         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004653169 |\n",
            "|    clip_fraction        | 0.0611      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.939      |\n",
            "|    explained_variance   | 0.599       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.855       |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.000251   |\n",
            "|    value_loss           | 1.5         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 37.7         |\n",
            "|    ep_rew_mean          | -3.06        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 391          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 135          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045597097 |\n",
            "|    clip_fraction        | 0.0582       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.895       |\n",
            "|    explained_variance   | 0.55         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.571        |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00227     |\n",
            "|    value_loss           | 1.67         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 32.1        |\n",
            "|    ep_rew_mean          | -2.43       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 391         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 141         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011571568 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.899      |\n",
            "|    explained_variance   | 0.495       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.02        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00737    |\n",
            "|    value_loss           | 1.61        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.4        |\n",
            "|    ep_rew_mean          | -1.35       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 391         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 146         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004389343 |\n",
            "|    clip_fraction        | 0.047       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.743      |\n",
            "|    explained_variance   | 0.617       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.829       |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.00071    |\n",
            "|    value_loss           | 1.62        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30.8        |\n",
            "|    ep_rew_mean          | -2.29       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 390         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 151         |\n",
            "|    total_timesteps      | 59392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008492105 |\n",
            "|    clip_fraction        | 0.0771      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.828      |\n",
            "|    explained_variance   | 0.696       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.659       |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.00409    |\n",
            "|    value_loss           | 1.43        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 26.7         |\n",
            "|    ep_rew_mean          | -1.84        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 390          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 157          |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077707246 |\n",
            "|    clip_fraction        | 0.0738       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.743       |\n",
            "|    explained_variance   | 0.566        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.978        |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00321     |\n",
            "|    value_loss           | 1.65         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 27.1        |\n",
            "|    ep_rew_mean          | -1.87       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 390         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 162         |\n",
            "|    total_timesteps      | 63488       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004724659 |\n",
            "|    clip_fraction        | 0.0676      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.68       |\n",
            "|    explained_variance   | 0.627       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.27        |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.00396    |\n",
            "|    value_loss           | 1.57        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 27.3         |\n",
            "|    ep_rew_mean          | -1.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 390          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 167          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059963977 |\n",
            "|    clip_fraction        | 0.04         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.771       |\n",
            "|    explained_variance   | 0.622        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.965        |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00036     |\n",
            "|    value_loss           | 1.58         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 32           |\n",
            "|    ep_rew_mean          | -2.42        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 389          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 173          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058090645 |\n",
            "|    clip_fraction        | 0.0428       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.7         |\n",
            "|    explained_variance   | 0.686        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.798        |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.000889    |\n",
            "|    value_loss           | 1.44         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 29.8         |\n",
            "|    ep_rew_mean          | -2.17        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 389          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 178          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016911217 |\n",
            "|    clip_fraction        | 0.0323       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.702       |\n",
            "|    explained_variance   | 0.577        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.573        |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00201     |\n",
            "|    value_loss           | 1.6          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 34.8        |\n",
            "|    ep_rew_mean          | -2.73       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 389         |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 183         |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001609694 |\n",
            "|    clip_fraction        | 0.0176      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.731      |\n",
            "|    explained_variance   | 0.581       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.826       |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | 0.000417    |\n",
            "|    value_loss           | 1.55        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 33.8         |\n",
            "|    ep_rew_mean          | -2.62        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 389          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 189          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036678938 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.655       |\n",
            "|    explained_variance   | 0.503        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.697        |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00119     |\n",
            "|    value_loss           | 1.58         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 28.8         |\n",
            "|    ep_rew_mean          | -2.07        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 389          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 194          |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040223845 |\n",
            "|    clip_fraction        | 0.0458       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.548       |\n",
            "|    explained_variance   | 0.551        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.853        |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00204     |\n",
            "|    value_loss           | 1.62         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.9        |\n",
            "|    ep_rew_mean          | -1.75       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 389         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 200         |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002342774 |\n",
            "|    clip_fraction        | 0.0306      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.605      |\n",
            "|    explained_variance   | 0.646       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.818       |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.00128    |\n",
            "|    value_loss           | 1.55        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 26.5         |\n",
            "|    ep_rew_mean          | -1.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 389          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 205          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047978573 |\n",
            "|    clip_fraction        | 0.0453       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.62        |\n",
            "|    explained_variance   | 0.664        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.829        |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.00204     |\n",
            "|    value_loss           | 1.57         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 33.1         |\n",
            "|    ep_rew_mean          | -2.54        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 210          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024454894 |\n",
            "|    clip_fraction        | 0.0329       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.548       |\n",
            "|    explained_variance   | 0.656        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.722        |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00125     |\n",
            "|    value_loss           | 1.56         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 28.8         |\n",
            "|    ep_rew_mean          | -2.06        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 215          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020912385 |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.655       |\n",
            "|    explained_variance   | 0.447        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.625        |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00131     |\n",
            "|    value_loss           | 1.64         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 24.9        |\n",
            "|    ep_rew_mean          | -1.63       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 388         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 221         |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002269571 |\n",
            "|    clip_fraction        | 0.033       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.569      |\n",
            "|    explained_variance   | 0.652       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.08        |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.00193    |\n",
            "|    value_loss           | 1.53        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 23.1         |\n",
            "|    ep_rew_mean          | -1.43        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 226          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016358838 |\n",
            "|    clip_fraction        | 0.0202       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.463       |\n",
            "|    explained_variance   | 0.662        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.871        |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.000257    |\n",
            "|    value_loss           | 1.49         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 26.4         |\n",
            "|    ep_rew_mean          | -1.79        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 231          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034379656 |\n",
            "|    clip_fraction        | 0.0322       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.454       |\n",
            "|    explained_variance   | 0.668        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.404        |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.000506    |\n",
            "|    value_loss           | 1.47         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 34.8         |\n",
            "|    ep_rew_mean          | -2.74        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 237          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019218454 |\n",
            "|    clip_fraction        | 0.0273       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.345       |\n",
            "|    explained_variance   | 0.677        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.712        |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.00046     |\n",
            "|    value_loss           | 1.46         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 36.2        |\n",
            "|    ep_rew_mean          | -2.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 388         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 242         |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001597109 |\n",
            "|    clip_fraction        | 0.012       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.394      |\n",
            "|    explained_variance   | 0.507       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.591       |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.000532   |\n",
            "|    value_loss           | 1.59        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 32.6         |\n",
            "|    ep_rew_mean          | -2.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 247          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027448381 |\n",
            "|    clip_fraction        | 0.0329       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.435       |\n",
            "|    explained_variance   | 0.512        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.711        |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00302     |\n",
            "|    value_loss           | 1.58         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 35.6         |\n",
            "|    ep_rew_mean          | -2.83        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 252          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028817998 |\n",
            "|    clip_fraction        | 0.0308       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.428       |\n",
            "|    explained_variance   | 0.574        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.984        |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00081     |\n",
            "|    value_loss           | 1.59         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 37.7         |\n",
            "|    ep_rew_mean          | -3.06        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 258          |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016690339 |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.539       |\n",
            "|    explained_variance   | 0.516        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.884        |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00189     |\n",
            "|    value_loss           | 1.6          |\n",
            "------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBVijrNbnUjI",
        "outputId": "0e296726-1a7d-4fac-c9c8-2d9f10e57dcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 訓練済みエージェントのテスト\n",
        "obs = env.reset()\n",
        "n_steps = 155\n",
        "for step in range(n_steps):\n",
        "  action, _ = model.predict(obs, deterministic=True)\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  print(\"Action: \", action)\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render(mode='console')\n",
        "  if done:\n",
        "    # VecEnvは、エピソード完了に遭遇すると自動的にリセットされることに注意\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1\n",
            "Action:  2\n",
            "obs= {'vec': array([0.96241857, 0.89193342, 0.4916087 , 0.59320882, 0.0225464 ]), 'img': array([[[163],\n",
            "        [ 31],\n",
            "        [ 21],\n",
            "        ...,\n",
            "        [ 49],\n",
            "        [239],\n",
            "        [ 94]],\n",
            "\n",
            "       [[ 81],\n",
            "        [ 71],\n",
            "        [  5],\n",
            "        ...,\n",
            "        [149],\n",
            "        [ 22],\n",
            "        [111]],\n",
            "\n",
            "       [[106],\n",
            "        [ 61],\n",
            "        [ 35],\n",
            "        ...,\n",
            "        [ 72],\n",
            "        [ 92],\n",
            "        [ 48]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 39],\n",
            "        [  1],\n",
            "        [ 48],\n",
            "        ...,\n",
            "        [ 64],\n",
            "        [  8],\n",
            "        [196]],\n",
            "\n",
            "       [[188],\n",
            "        [120],\n",
            "        [123],\n",
            "        ...,\n",
            "        [252],\n",
            "        [ 71],\n",
            "        [158]],\n",
            "\n",
            "       [[225],\n",
            "        [ 74],\n",
            "        [246],\n",
            "        ...,\n",
            "        [ 63],\n",
            "        [214],\n",
            "        [166]]], dtype=int32)} reward= 1 done= True\n",
            "Went right in state 14, got to state 15\n",
            "Goal reached! reward= 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a245ytFhwGg3"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}